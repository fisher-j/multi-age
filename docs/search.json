[
  {
    "objectID": "analysis-index.html",
    "href": "analysis-index.html",
    "title": "Multiaged experiment – 10-year analysis",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "analysis-index.html#abstract",
    "href": "analysis-index.html#abstract",
    "title": "Multiaged experiment – 10-year analysis",
    "section": "Abstract",
    "text": "Abstract\nThis is an analysis of the 10-year re-measure of the Redwood multi-age experiment. It was started by Dr. Pascal Berrill, professor of silviculture at Cal-Poly Humboldt. The experiment is located in the Jackson Demonstration State Forest in Mendocino County, California. The multi-age experiment explores the regeneration response of several species following different harvesting techniques including group selection, aggregated retention, and high/low dispersed retention. The 10-year re-measure data includes surface fuel characterization.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "analysis-index.html#acknowledgements",
    "href": "analysis-index.html#acknowledgements",
    "title": "Multiaged experiment – 10-year analysis",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nI would like to thank my advisor Pascal Berrill and my other committee memebers, Jeffrey Kane, and Rosanna Overholser.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "analysis/fuel_data_description.html",
    "href": "analysis/fuel_data_description.html",
    "title": "1  Fuel data description",
    "section": "",
    "text": "1.1 Data entry\nData was entered using Excel and exported as a UTF-8 csv. The file format (Figure 1.3) was defined to resemble the physical datasheets as closely as possible, while maintaining data integretity and facilitating ease of input. There is one file for each macro plot (or replicate = site + treatment combination).\nEach file includes sections for different tables, and these are separated by a line that contains only a single hashtag (e.g., “#duff_litter_fbd”) in lowercase letters with underscores for spaces. In Excel, the #hashtag should go in the first cell of a row, with nothing esle in the row. There should be no blank rows before or after hashtags. The table sections used don’t correlate 1:1 with physical datasheet tables. For instance, columns for “metermeark1” and “metermark2” were added to reflect the fact that initially we sampled duff, litter and vegetation density (transect stations) at 5 and 10 m, but later we moved the stations to 5 and 9 m. The “1” and “2” following repeated variable names refers to one of these locations along the transect. The function used to wrangle these data matches rows based on transect number and columns based on column names. Thus, it is possible to rearrage the rows or columns within each section as long as column names are kept consistent and data for each transect have the same transect number. Following are the section and column labels used for each section of the plot data entry form with any notes regarding their format. A complete description of the data varialbes can be found in Section 1.3.\nAn R function is used to parse this file into individual tables. As part of this process, all the table sections whose rows have a 1:1 relationship with transects are combined into one wide table, based on the transect column.\nCode\nsource(\"./scripts/test_funs.r\")\n\n# file &lt;- \"../data/1_fuel_camp6_gs.csv\"\n\n# This function processess one datasheet and returns three tables that can\n# be combined with corresponding tables from other data sheets\nwrangle_datasheet &lt;- function(file) {\n  con &lt;- file(file, encoding = \"UTF-8\")\n  lines &lt;- readLines(con)\n  close(con)\n\n  # Remove BOM if it exists &lt;https://stackoverflow.com/a/67906611&gt;\n  lines[1] &lt;- gsub(\"\\\\xef\\\\xbb\\\\xbf\", \"\", lines[1], useBytes = TRUE)\n\n  # These are the sections I want to extract\n  to_get &lt;- c(\n    \"site_data\", \"transects\", \"duff_litter_fbd\", \"vegetation\",\n    \"woody_species\", \"coarse_woody_debris\"\n  )\n  # sections are defined by line with only a hashtage (#section)\n  section_pattern &lt;- \"^#(\\\\w+).*$\"\n\n  # find hashtags and get the data from the next line to the line\n  # before the next hashtag\n  section_breaks &lt;- grep(section_pattern, lines)\n  section_start &lt;- section_breaks + 1\n  section_end &lt;- c(section_breaks[-1], length(lines)) - 1\n  section_names &lt;- gsub(section_pattern, \"\\\\1\", lines[section_breaks])\n\n  sections &lt;- purrr::map2(section_start, section_end, \\(x, y) c(x, y)) |&gt;\n    setNames(section_names) |&gt;\n    (`[`)(to_get) |&gt;\n    purrr::map(\\(x) lines[seq.int(x[1], x[2])]) |&gt;\n    # collapse sections to strings so they can be read as if they were files\n    purrr::map(\\(x) paste(x, collapse = \"\\n\")) |&gt;\n    # leave empty column names so they can be removed\n    purrr::map(\\(x)\n      readr::read_csv(x,\n        show_col_types = FALSE,\n        name_repair = \"minimal\",\n        progress = FALSE\n      )\n    ) |&gt;\n    # Remove empty columns\n    purrr::map(\\(x) x[!names(x) %in% \"\"])\n\n  # I'm going to combine these into a wide table because each row is a transect.\n  # Further data wrangling will require expanding the stations within transecs.\n  # also need to make sure the rows have site data and transect ids for the\n  # coarse woody debris.\n  transect_data &lt;- c(\n    \"transects\", \"duff_litter_fbd\", \"vegetation\", \"woody_species\"\n  )\n\n  transects &lt;- sections |&gt;\n    (`[`)(transect_data) |&gt;\n    purrr::reduce(dplyr::left_join, by = \"transect\") |&gt;\n    # differentiate between transect lenghts and particle counts\n    dplyr::rename_with(\\(x) paste0(x, \"_count\"), ends_with(\"hr\")) |&gt;\n    dplyr::mutate(\n      sections$site_data[c(\"phase\", \"site\", \"treatment\")],\n      .before = corner\n    ) |&gt;\n    dplyr::select(-transect)\n\n  coarse_woody_debris &lt;- sections$coarse_woody_debris |&gt;\n    dplyr::mutate(\n      sections$site_data[c(\"phase\", \"site\", \"treatment\")],\n      .after = transect\n    ) |&gt;\n    dplyr::left_join(\n      sections$transects[c(\"transect\", \"corner\", \"azi\")]\n    ) |&gt;\n    dplyr::select(c(phase, site, treatment, corner, azi, dia, decay))\n  \n  \n  plots &lt;- sections$site_data |&gt;\n    # differentiate between transect lenghts and particle counts\n    dplyr::rename_with(\\(x) paste0(x, \"_length\"), ends_with(\"hr\"))\n\n  # I'll add a check to make sure that all transects and plots are unique\n  warn_duplicates(transects, phase, site, treatment, corner, azi)\n  warn_duplicates(plots, phase, site, treatment)\n\n  # Final output with three tables. These will be combined with corresponding\n  # tables from other datasheets.\n  list(\n    plots = plots,\n    transects = transects,\n    coarse_woody = coarse_woody_debris\n  )\n}\n\n# Here I hard code the source directory for the input csvs\ndata_dir &lt;- \"../data\"\n\n# Combine fuels data for each plot\n#\n# This function expects all fuel datasheets to begin with \"fuel\" and end with\n# \"csv\". It loads all matching files in a given folder and returns the same\n# tables as `wrangle_datasheet`, but for all plots combined.\ncombine_fuels_datasheets &lt;- function(data_dir) {\n  files &lt;- list.files(data_dir, pattern = \"^\\\\d_fuel.*csv$\", full.names = TRUE)\n  sheets_list &lt;- purrr::map(files, wrangle_datasheet)\n  table_names &lt;- purrr::set_names(names(sheets_list[[1]]))\n  purrr::map(table_names, \\(x) purrr::list_rbind(purrr::map(sheets_list, x)))\n}\n\n\n# this is how to pivot station data to longer format\n# d |&gt;\n#   tidyr::pivot_longer(\n#     cols = !c(site, treatment, corner, azi),\n#     names_to = \".value\",\n#     names_pattern = \"(\\\\w+)[12]$\"\n#   )\nThe resulting data looks like this:\nwrangle_datasheet(\"../data/1_fuel_waldon_gs.csv\")\n\nJoining with `by = join_by(transect)`\n\n\n$plots\n# A tibble: 1 × 10\n  site   treatment date   onehr_length tenhr_length hundhr_length thoushr_length\n  &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;         &lt;dbl&gt;        &lt;dbl&gt;         &lt;dbl&gt;          &lt;dbl&gt;\n1 waldon gs        3/15/…            2            2             4             10\n# ℹ 3 more variables: trans_count &lt;dbl&gt;, notes &lt;chr&gt;, phase &lt;chr&gt;\n\n$transects\n# A tibble: 8 × 35\n  phase  site   treatment corner   azi fwd_crew veg_crew slope metermark1\n  &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n1 prepct waldon gs        n        135 jf       ac           4          5\n2 prepct waldon gs        n        248 jf       ac          19          5\n3 prepct waldon gs        w         45 dr       dr           8          5\n4 prepct waldon gs        w        135 dr       dr          20          5\n5 prepct waldon gs        s         45 dr       jf           5          5\n6 prepct waldon gs        s        315 dr       jf           5          5\n7 prepct waldon gs        e        225 dr       jf           8          5\n8 prepct waldon gs        e        315 dr       jf          13          5\n# ℹ 26 more variables: metermark2 &lt;dbl&gt;, notes &lt;chr&gt;, timestamp &lt;lgl&gt;,\n#   onehr_count &lt;dbl&gt;, tenhr_count &lt;dbl&gt;, hundhr_count &lt;dbl&gt;,\n#   duff_litter1 &lt;dbl&gt;, pct_litter1 &lt;dbl&gt;, fbd1 &lt;dbl&gt;, duff_litter2 &lt;dbl&gt;,\n#   pct_litter2 &lt;dbl&gt;, fbd2 &lt;dbl&gt;, live_woody1 &lt;dbl&gt;, dead_woody1 &lt;dbl&gt;,\n#   avg_w_ht1 &lt;dbl&gt;, live_herb1 &lt;dbl&gt;, dead_herb1 &lt;dbl&gt;, avg_h_ht1 &lt;dbl&gt;,\n#   live_woody2 &lt;dbl&gt;, dead_woody2 &lt;dbl&gt;, avg_w_ht2 &lt;dbl&gt;, live_herb2 &lt;dbl&gt;,\n#   dead_herb2 &lt;dbl&gt;, avg_h_ht2 &lt;dbl&gt;, species1 &lt;chr&gt;, species2 &lt;chr&gt;\n\n$coarse_woody\n# A tibble: 20 × 7\n   phase  site   treatment corner   azi   dia decay\n   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 prepct waldon gs        n        135     9     5\n 2 prepct waldon gs        n        135    13     2\n 3 prepct waldon gs        n        248    48     3\n 4 prepct waldon gs        n        248    10     5\n 5 prepct waldon gs        w         45    16     5\n 6 prepct waldon gs        w         45    15     5\n 7 prepct waldon gs        w         45    14     5\n 8 prepct waldon gs        w         45    14     5\n 9 prepct waldon gs        w        135    32     3\n10 prepct waldon gs        w        135    12     4\n11 prepct waldon gs        w        135    30     5\n12 prepct waldon gs        s         45    28     4\n13 prepct waldon gs        s         45    42     5\n14 prepct waldon gs        s        315    26     3\n15 prepct waldon gs        e        225    15     4\n16 prepct waldon gs        e        225    13     3\n17 prepct waldon gs        e        225    18     5\n18 prepct waldon gs        e        225    34     3\n19 prepct waldon gs        e        315    26     4\n20 prepct waldon gs        e        315    12     5\nWhile the wide format for the transect data is not ideal, it is convenient because it reduces the number of tables we are dealing with. This will require extra work at analysis time to expand the data variables which are followed by a “1” or “2”, which represent different stations (Section 1.3) on the same transect. To analze these data, they will first need to be pivoted into a longer format, where the station (1 or 2) becomes an explicit column.",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Fuel data description</span>"
    ]
  },
  {
    "objectID": "analysis/fuel_data_description.html#sec-data-entry",
    "href": "analysis/fuel_data_description.html#sec-data-entry",
    "title": "1  Fuel data description",
    "section": "",
    "text": "#site_info site treatment\n\ndate\nonehr\ntenhr\nhundhr\nthoushr\ntrans_count notes (site level notes, should not contain commas)\nphase\n\n#transects\n\ntransect (number 1 through 8, corresponds with transect column in other sections)\ncorner\nazi\nfwd_crew\nveg_crew (moved from vegetation table to here)\nslope\nmetermark1 (location along transect of first station)\nmetermark2 (location along transect of second station)\nnotes (transect specific notes)\ntimestamp\n\n#duff_litter_fbd\n\ntransect (number 1 through 8)\nonehr\ntenhr\nhundhr\nduff_litter1\npct_litter1\nfbd1\nduff_litter2\npct_litter2\nfbd2\n\n#vegetation\n\ntransect (number 1 though 8)\nlive_woody1\ndead_woody1\navg_w_ht1\nlive_herb1\ndead_herb1\navg_h_ht1\nlive_woody2\ndead_woody2\navg_w_ht2\nlive_herb2\ndead_herb2\navg_h_ht2\n\n#woody_species\n\ntransect\nspecies1 (space-delimited list of ‘significant’ species)\nspecies2 (space-delimited list of ‘significant’ species)\n\n#coarse_woody_debris\n\ntransect\ndia\ndecay\n\n\n\n\n\n\n\n\nFigure 1.3: Screenshot of an examle of the datasheet entry format. Each section, defined by a begining hashtag is parsed by an r function as a seperate table.",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Fuel data description</span>"
    ]
  },
  {
    "objectID": "analysis/fuel_data_description.html#data-variable-descriptions",
    "href": "analysis/fuel_data_description.html#data-variable-descriptions",
    "title": "1  Fuel data description",
    "section": "1.2 Data variable descriptions",
    "text": "1.2 Data variable descriptions\nThe following is a descripton of the data variables for each of the tables in the data list. So, the $plots heading refers to the table found in data$plots. This data structure is subject to change, but for now, has 3 tables. $plots has plot level data including the lengths of transects (which are the same across all transects, but included for clarity). $transects contains all the fuel data associated with a given transect, including both sampling stations, in wide format (one row for each transect). Finally, $coarse_woody contains coarse woody debris in a long format (multiple rows for each transect).",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Fuel data description</span>"
    ]
  },
  {
    "objectID": "analysis/fuel_data_description.html#sec-sampling-cylinder",
    "href": "analysis/fuel_data_description.html#sec-sampling-cylinder",
    "title": "1  Fuel data description",
    "section": "1.3 Station sampling cylinder",
    "text": "1.3 Station sampling cylinder\nReference is made the station sampling cylinder below. It is an imaginary, vertical cylinder with a radius of 1 meter and a variable height equal to the maxiumm height of sprout or shrub vegetation within the cylinders radius. There are two sampling cylinders on each transect and their centers are defined by the transects’ two metermarks. Duff, litter, and fuel bed depth in addition to the vegetation measurements, are all recorded within these cylinders.",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Fuel data description</span>"
    ]
  },
  {
    "objectID": "analysis/fuel_data_description.html#plots",
    "href": "analysis/fuel_data_description.html#plots",
    "title": "1  Fuel data description",
    "section": "1.4 $plots",
    "text": "1.4 $plots\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nsite\n\n\n\ntreatment\n\n\n\ndate\n\n\n\nonehr\nDistance from end of transect for which 1-hr fuels were counted\n\n\ntenhr\nDistance from end of transect for which 10-hr fuels were counted\n\n\nhundhr\nDistance from end of transect for which 100-hr fuels were counted\n\n\nthoushr\nDistance from end of transect for which 1000-hr fuels were counted\n\n\ntrans_count\nnumber of transects on macro plot\n\n\nnotes\n\n\n\nphase\nPhase of experiment: prepct or postpct",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Fuel data description</span>"
    ]
  },
  {
    "objectID": "analysis/fuel_data_description.html#transects",
    "href": "analysis/fuel_data_description.html#transects",
    "title": "1  Fuel data description",
    "section": "1.5 $transects",
    "text": "1.5 $transects\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nphase\nsame as for plots\n\n\nsite\nOne of four different sites: whiskey, waldon, waldos, and camp6\n\n\ntreatment\nOne of HD=High density, dispersed retention, LD=Low density dispersed retention, MD=Medium densty dispersed retention, HA=High density aggreagated retention, GS=Group selection opening (1 ha, centered on plot)\n\n\ncorner\nOne of n,s,e,w for “diamond” plost and one of ne, nw, se, sw for “square” plots\n\n\nazi\nactual azimuth from corner to end of fuel transect, deg\n\n\nfwd_crew\nInitials of person performing fuel counts and measuring litter, duff, and FBD\n\n\nveg_crew\nInitials of person estimating vegetation cover\n\n\nslope\nslope in percent, measured with clinometer\n\n\nmetermark1\nlocantion along transect of first veg. station m\n\n\nmetermark2\nlocantion along transect of first veg. station m\n\n\nnotes\nTransect specific notes\n\n\nonehr\nCount of down woody fuels &lt;0.6 cm for the lenght of the 1-hr transect, redwood leaflets less than about 2 mm were not counted as one hour fuels\n\n\ntenhr\nCount of down woody fuels &gt;= 0.6 and &lt; 2.5 cm\n\n\nhundhr\nCount of down woody fuels &gt;= 2.5 and &lt; 8 cm\n\n\nduff_litter1\nCombined duff and litter depth from a representative location within a 1-meter radius circle centered at metermark, cm\n\n\npct_litter1\nPercent of duff_litter depth compose of litter: percent\n\n\nfbd1\nEstimated average height of litter and downed woody debris within the sampling cylinder, 1 m radius, centered at metermark\n\n\nduff_litter2\n\n\n\npct_litter2\n\n\n\nfbd2\n\n\n\nlive_woody1\nTotal projected ground cover of all live woody plant parts within 1-meter-radius sampling cylinder of height equal to the height of the shrub or sprout vegetaion within the cylinders radius, 0-100 percent\n\n\ndead_woody1\nTotal projected ground cover of all dead woody plant parts connected to live or standing dead plants, within the sampling cylinder 0-100 percent\n\n\navg_w_ht1\nAverage maximum height of all live and dead woody plants in sampling cylinder (see Estimating Height in Firemon protocol)\n\n\nlive_herb1\nTotal projected ground cover of live herbs in the sampling cylinder\n\n\ndead_herb1\nTotal projected ground cover of dead herbs in the sampling cylinder\n\n\navg_h_ht1\nAverage maximum height of live and dead herbs in the sampling cylinder\n\n\nlive_woody2\n\n\n\ndead_woody2\n\n\n\navg_w_ht2\n\n\n\nlive_herb2\n\n\n\ndead_herb2\n\n\n\navg_h_ht2\n\n\n\nspecies1\nDominant woody species within sampling cylinder, each species is assumed to occupy an equal portion of volume, under-represented species are ignored\n\n\nspecies2",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Fuel data description</span>"
    ]
  },
  {
    "objectID": "analysis/fuel_data_description.html#coarse_woody",
    "href": "analysis/fuel_data_description.html#coarse_woody",
    "title": "1  Fuel data description",
    "section": "1.6 $coarse_woody",
    "text": "1.6 $coarse_woody\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nsite\n\n\n\ntreatment\n\n\n\ncorner\n\n\n\nazi\n\n\n\ndia\n\n\n\ndecay\nDecay class 1-5, 1=Fine branches still present, 2=Some branches and bark missing, 3=most branches and much bark missing potentially minor decay, 4=Significant decay, 5=Almost completely rotten",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Fuel data description</span>"
    ]
  },
  {
    "objectID": "analysis/calculate_fuel_loading.html",
    "href": "analysis/calculate_fuel_loading.html",
    "title": "2  Calculate fuel loading",
    "section": "",
    "text": "2.1 Load data from datasheets\nData in quasi-csv format, described in Section 1.1. I’m ommitting the medium density dispersed plot (MD), which only exists at one site.\n# load data and ensure unique transects\nsource(\"./scripts/process_datasheets.r\")\nsource(\"./scripts/test_funs.r\")\n\nd &lt;- combine_fuels_datasheets(\"../data\") |&gt;\n  map(\\(x) filter(x, treatment != \"md\"))\n\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\nJoining with `by = join_by(transect)`\n\nwarn_duplicates(d$transects, phase, site, treatment, corner, azi)",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Calculate fuel loading</span>"
    ]
  },
  {
    "objectID": "analysis/calculate_fuel_loading.html#fine-woody-debris",
    "href": "analysis/calculate_fuel_loading.html#fine-woody-debris",
    "title": "2  Calculate fuel loading",
    "section": "2.2 Fine woody debris",
    "text": "2.2 Fine woody debris\nThe above information will allow us to calculate fuel loading for fine and coarse woody debris. First we’ll load our data and get the FWD (and the fuel particle parameters) in a long format for easier calculations.\nTwo transects are missing slope. I’m giving them a slope of 0 for now.\n\n\nCode\n# use this to reduce the amount of typing when referring to transects\ntransectid &lt;- c(\"phase\", \"site\", \"treatment\", \"corner\", \"azi\")\n\nfwd &lt;- d$transects |&gt;\n  select(all_of(transectid), slope, matches(\"one|ten|hun\")) |&gt;\n  mutate(slope = if_else(is.na(slope), 0, slope)) |&gt;\n  left_join(select(d$plots, phase, site, treatment, matches(\"one|ten|hun\"))) |&gt;\n  # move onehr, tenhr, etc to new column and create new columns for transect\n  # length and particle counts\n  pivot_longer(\n    matches(\"count|len\"),\n    names_to = c(\"class\", \".value\"),\n    names_sep = \"_\"\n  ) |&gt; \n  left_join(get_particle_params(source = \"glebocki\")) |&gt;\n  mutate(\n    load = simple_load(\n      sum_d2 = count * d2,\n      l = length,\n      percent_slope = slope,\n      G = G,\n      a = a\n    )\n  ) |&gt;\n  select(-c(G, a))",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Calculate fuel loading</span>"
    ]
  },
  {
    "objectID": "analysis/calculate_fuel_loading.html#coarse-woody-debris",
    "href": "analysis/calculate_fuel_loading.html#coarse-woody-debris",
    "title": "2  Calculate fuel loading",
    "section": "2.3 Coarse woody debris",
    "text": "2.3 Coarse woody debris\nCoarse woody debris is already in a long format so we don’t need to pivot longer, but we will summarize the data for each transect by getting the sum of squared diameters. This differs from the fine woody data because we have actual diameters instead of counts, each diameter corresponds to a single observation.\nWe only have parameters for “sound” and “rotten” particles, so anything over decay class 3 will be considered “rotten”. Finally, we need to join in transect slopes, and transect lengths.\nI’m setting a couple of missing slope to zero.\n\ncwd &lt;- d$coarse_woody |&gt;\n  mutate(class = if_else(decay &gt; 3, \"thoushr_r\", \"thoushr_s\")) |&gt;\n  group_by(phase, site, treatment, corner, azi, class) |&gt;\n  # named count to match fwd table, but these are actually summed d^2\n  summarize(\n    sum_d2 = sum(dia^2),\n    count = n(),\n    med_d = median(dia),\n    .groups = \"drop\"\n  ) |&gt;\n  left_join(d$transects[c(transectid, \"slope\")]) |&gt;\n  mutate(slope = if_else(is.na(slope), 0, slope)) |&gt;\n  left_join(d$plots[c(\"phase\", \"site\", \"treatment\", \"thoushr_length\")]) |&gt;\n  left_join(get_particle_params(source = \"glebocki\")) |&gt;\n  mutate(\n    load = simple_load(\n      sum_d2 = sum_d2,\n      l = thoushr_length,\n      percent_slope = slope,\n      G = G,\n      a = a\n    )\n  ) |&gt;\n  select(-c(G, a, d2), length = thoushr_length)",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Calculate fuel loading</span>"
    ]
  },
  {
    "objectID": "analysis/calculate_fuel_loading.html#duff-and-litter",
    "href": "analysis/calculate_fuel_loading.html#duff-and-litter",
    "title": "2  Calculate fuel loading",
    "section": "2.4 Duff and litter",
    "text": "2.4 Duff and litter\nWe measured total duff/litter depth, and then estimated a percent of this depth that would be classified as litter. Litter is any leaf material not classified as a 1-hr fuel, that has not yet begun to break down. Particles that were very dark in color and that were broken into smaller pieces than when they had originally fallen were classified as duff.\nDuff and litter were measured at two locations along each transect, for a total of 16 measurements per plot.\nTo convert these depths to load values we use a depth to load equation. Finney and Martin (1993) found a wide variability in the bulk densities of samples, suggesting that simply using the average bulk density should be sufficient, as opposed to calculating bulk densities based on strata depth or differentiating between duff and litter.\n\n\n\n\nTable 2.2: Average depth to load multiplier from different sources in the literature.\n\n\n\n\n\n\n\n\n\n\n\nSource\nDescription\nLoad Mg ha-1 cm-1\n\n\n\n\nFinney and Martin (1993)\nAnnadel SP & Humboldt Redwoods SP (rw dbh &lt;= 60 in)\n7.15\n\n\nKittredge (1940)\nplantation redwoods\n6.80\n\n\nStuart, J.D. 1985, Unpubl. in Finney and Martin (1993)\nRedwoods SP, (mean of duff & litter)\n9.25\n\n\nJan W. Van Wagtendonk, Benedict, and Sydoriak (1998)\nAvg. for Sierra Nevada conifers\n16.24\n\n\nNives (1989)\nRedwood NP, Lost Man Cr., Redwood Cr.\n2.42\n\n\nKrieger et al. (2020)\nNo ref. cited, 2.75 and 5.5 lbs/ft3 litter and duff resp.\n6.60\n\n\nValachovic et al. (2011)\nTanoak-Douglas-fir, litter only, Humboldt County\n0.93\n\n\n\n\n\n\n\n\nOn average, we have about 50% litter and a depth of about 6.2 cm. If we use the mean of the first 3 rows in Table 2.2, an average depth to load multiplier for redwood forests (with 50% litter) is 7.73 Mg ha-1 cm-1.\n\ndufflitter |&gt;\n  group_by(treatment) |&gt;\n  summarize(\n    avg_pct_litter = mean(\n      litter_depth / (duff_depth + litter_depth),\n      na.rm = TRUE\n    ),\n    avg_total_depth = mean(duff_depth + litter_depth),\n)\n\n# A tibble: 4 × 3\n  treatment avg_pct_litter avg_total_depth\n  &lt;chr&gt;              &lt;dbl&gt;           &lt;dbl&gt;\n1 gs                 0.689           14.2 \n2 ha                 0.695            7.94\n3 hd                 0.610           10.4 \n4 ld                 0.613           12.4 \n\ndufflitter &lt;- dufflitter |&gt;\n  mutate(\n    load = (duff_depth + litter_depth) * 7.73\n  )",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Calculate fuel loading</span>"
    ]
  },
  {
    "objectID": "analysis/calculate_fuel_loading.html#vegetation",
    "href": "analysis/calculate_fuel_loading.html#vegetation",
    "title": "2  Calculate fuel loading",
    "section": "2.5 Vegetation",
    "text": "2.5 Vegetation\nWe based our data collection on the Firemon protocol, which determines vegetative fuel loading by multiplying estimated percent cover by height by a constant bulk densities of 8 and 18 t/ha/m for herbaceous and shrub components, respectively.\nHere I want to standardize the data so that heights are all zero (instead of NA), if percent cover for live and dead were both zero. Also, I want total percent cover, with total proportion dead.\nTheoretically, with the Firemon protocol, total percent cover could be greater than 100, because live and dead percent covers are assessed separately. In practice, sum of live and dead cover was over 100 percent.\n\n\nveg_match &lt;- \"woody|herb|avg_w_ht|avg_h_ht|species\"\n\nveg &lt;- d$transects |&gt;\n  select(all_of(transectid), slope, matches(veg_match)) |&gt;\n  pivot_longer(\n    !c(any_of(transectid), slope),\n    names_to = c(\".value\", \"station\"),\n    names_pattern = \"(\\\\w+)([12])\"\n  ) |&gt; \n  # there was some inconsistency in whether heights were zero or blank if no veg\n  # was present, here I sort that out.\n  # We are interested in total load, but the dead component has implications for\n  # fuel moisture. We recorded percent cover of live and dead separately, so\n  # here i calulate a total and proportion dead.\n  mutate(\n    woody_ht = if_else(live_woody == 0 & dead_woody == 0, 0, avg_w_ht),\n    herb_ht = if_else(live_herb == 0 & dead_herb == 0, 0, avg_h_ht),\n    woody_load = ((live_woody + dead_woody) / 100) * woody_ht * 18,\n    woody_p_dead = if_else(\n      woody_load == 0, 0, dead_woody / (live_woody + dead_woody)\n    ),\n    herb_load = ((live_herb + dead_herb) / 100) * herb_ht * 8,\n    herb_p_dead = if_else(\n      herb_load == 0, 0, dead_herb / (live_herb + dead_herb)\n    )\n  ) |&gt;\n  select(!matches(\"live_|dead_|avg_\"), woody_ht, herb_ht) |&gt;\n  pivot_longer(\n    matches(\"woody|herb\"),\n    names_to = c(\"class\", \".value\"),\n    names_pattern = \"(woody|herb)_(.*)\"\n  )",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Calculate fuel loading</span>"
    ]
  },
  {
    "objectID": "analysis/calculate_fuel_loading.html#sec-total-load",
    "href": "analysis/calculate_fuel_loading.html#sec-total-load",
    "title": "2  Calculate fuel loading",
    "section": "2.6 Total load",
    "text": "2.6 Total load\nNow we can join results for fine woody debris, coarse woody debris, litter, and duff into a single dataframe.\nVegetation and duff/litter first need to be summarized to the transect level.\n\ndufflitter_load &lt;- dufflitter |&gt;\n  group_by(pick(all_of(transectid))) |&gt;\n  summarize(class = \"dufflitter\", load = mean(load))\n\nveg_load &lt;- veg |&gt;\n  group_by(pick(all_of(transectid)), class) |&gt;\n  summarize(load = mean(load))\n\nfwd_load &lt;- fwd |&gt; select(all_of(transectid), class, load)\ncwd_load &lt;- cwd |&gt; select(all_of(transectid), class, load)\n\ntotal_load &lt;- bind_rows(dufflitter_load, veg_load, fwd_load, cwd_load) |&gt;\n  ungroup()\n\nJohn Stuart measured old-growth forest fuels in in Bull Creek Drainage of Humboldt Redwood State Park, approximately 30 km inland from the coast. Overstory BA was about 66 m2ha-1. Plots were classifed based on their overstory/understory species as one of:\n\nredwood-Douglas-fir/tanoak-evergreen huckleberry\nredwood-Douglas-fir/evergreen huckleberry-tanoak\nDouglas-fir-redwood/evergreen huckleberry\n\nFinney and Martin (1993) measured fuels at two loacations. In Annadel SP with 30-40% slopes and 45 - 60 m2ha-1 of trees approximate 120 years old. At RW SP, BA was between 20 and 60 m2ha-1 that sprouted after harvest and were around 90 years old.\nKittredge (1940) studied duff and litter in redwood plantations with an average total depth of 4 cm.\nValachovic et al. (2011) measured surface fuels in Douglas-fir-tanoak forests from Sonoma to northern Humboldt counteis. The values shown are from across this range.\n\n\n\nTable 2.3: Summary of fuel loading metrics for this and other studies.\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\nsource\nlow\nhigh\n\n\n\n\nlitter\nvalachovic\n2.9\n4.7\n\n\ndufflitter\nthisstudy\n40.2\n55.0\n\n\nfinney\n29.0\n55.0\n\n\nkittredge\n24.0\n24.0\n\n\nstuart\n30.9\n73.6\n\n\nonehr\nthisstudy\n0.6\n1.2\n\n\nvalachovic\n2.0\n3.4\n\n\nstuart\n0.9\n2.1\n\n\ntenhr\nthisstudy\n2.9\n3.7\n\n\nvalachovic\n2.5\n6.1\n\n\nstuart\n3.5\n6.4\n\n\nhundhr\nthisstudy\n9.5\n11.8\n\n\nvalachovic\n3.1\n7.6\n\n\nstuart\n2.8\n7.5\n\n\nonetenhundhr\nthisstudy\n13.4\n16.1\n\n\nfinney\n9.0\n20.0\n\n\nvalachovic\n9.0\n15.5\n\n\nstuart\n8.0\n13.4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\nsource\nlow\nhigh\n\n\n\n\nthoushr_s\nthisstudy\n27.4\n72.4\n\n\nvalachovic\n4.9\n76.7\n\n\nstuart\n5.0\n117.4\n\n\nthoushr_r\nthisstudy\n23.0\n59.0\n\n\nvalachovic\n3.1\n35.2\n\n\nstuart\n0.5\n46.7\n\n\nthoushr\nthisstudy\n45.1\n60.6\n\n\nfinney\n0.0\n264.0\n\n\nvalachovic\n18.3\n85.9\n\n\nstuart\n5.6\n126.3\n\n\nveg_woody\nthisstudy\n12.4\n37.8\n\n\nstuart\n0.1\n5.6\n\n\nveg_herb\nthisstudy\n0.2\n0.5",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Calculate fuel loading</span>"
    ]
  },
  {
    "objectID": "analysis/calculate_fuel_loading.html#simplifying-variables",
    "href": "analysis/calculate_fuel_loading.html#simplifying-variables",
    "title": "2  Calculate fuel loading",
    "section": "2.7 Simplifying variables",
    "text": "2.7 Simplifying variables\nI want to reduce the number of variables that I have to deal with. I will combine the woody and herbaceous veg and also the sound and rotten 1,000-hr fuels.\n\n# To reduce the number of variables, combine sound and rotten coarse wood and\n# combine woody and herbaceous veg\ntl &lt;- total_load |&gt;\n  pivot_wider(names_from = class, values_from = load) |&gt;\n  mutate(\n    thoushr = rowSums(pick(c(thoushr_s, thoushr_r)), na.rm = TRUE),\n    veg = rowSums(pick(c(woody, herb)), na.rm = TRUE),\n    .keep = \"unused\"\n  ) |&gt;\n  mutate(\n    treatment = forcats::fct_relevel(treatment, c(\"gs\", \"ld\", \"ha\", \"hd\"))\n  )",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Calculate fuel loading</span>"
    ]
  },
  {
    "objectID": "analysis/calculate_fuel_loading.html#post-pct",
    "href": "analysis/calculate_fuel_loading.html#post-pct",
    "title": "2  Calculate fuel loading",
    "section": "2.8 Post-pct",
    "text": "2.8 Post-pct\nin order to make comparisons, I want to know if any transects had different azimuths in the pre and post pct measure. It looks like there are 11 transects that were measured on a different azimuth. This is about 9% of the data.\n\ntl |&gt; select(phase, site, treatment, corner, azi) |&gt;\n  group_by(site, treatment, corner, azi) |&gt;\n  mutate(n = n()) |&gt;\n  filter(n == 1) |&gt;\n  arrange(site, treatment, corner, phase) |&gt;\n  print(n = Inf)\n\n# A tibble: 22 × 6\n# Groups:   site, treatment, corner, azi [22]\n   phase   site    treatment corner   azi     n\n   &lt;chr&gt;   &lt;chr&gt;   &lt;fct&gt;     &lt;chr&gt;  &lt;dbl&gt; &lt;int&gt;\n 1 postpct camp6   gs        e          0     1\n 2 prepct  camp6   gs        e        225     1\n 3 postpct camp6   gs        w         39     1\n 4 prepct  camp6   gs        w         45     1\n 5 postpct camp6   hd        w         42     1\n 6 prepct  camp6   hd        w         48     1\n 7 postpct waldon  gs        n        262     1\n 8 prepct  waldon  gs        n        248     1\n 9 postpct waldon  ha        ne       290     1\n10 prepct  waldon  ha        ne       274     1\n11 postpct waldon  ha        sw        35     1\n12 prepct  waldon  ha        sw         6     1\n13 postpct waldos  gs        ne       168     1\n14 prepct  waldos  gs        ne       180     1\n15 postpct waldos  ha        ne       178     1\n16 prepct  waldos  ha        ne       180     1\n17 postpct waldos  hd        se       287     1\n18 prepct  waldos  hd        se       270     1\n19 postpct waldos  hd        sw       356     1\n20 prepct  waldos  hd        sw         0     1\n21 postpct whiskey hd        s         36     1\n22 prepct  whiskey hd        s         42     1\n\n\nFor the post pct data, one variable that I would like to analyze is the difference between pre and post vegetation. The difference represents the resulting slash. This should only be calculated for transects that were measured on the same azimuth before and after pct\n\ntl2 &lt;- tl |&gt;\n  group_by(site, treatment, corner, azi) |&gt;\n  arrange(site, treatment, corner, azi, phase) |&gt;\n  mutate(veg_diff = lead(veg) - veg)",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Calculate fuel loading</span>"
    ]
  },
  {
    "objectID": "analysis/calculate_fuel_loading.html#summary",
    "href": "analysis/calculate_fuel_loading.html#summary",
    "title": "2  Calculate fuel loading",
    "section": "2.9 Summary",
    "text": "2.9 Summary\nOur combined duff-litter depths were comparable to other studies, resulting in comparable loading for litter and duff.\nOnehr fuels were lower than then other redwood study and that found in Douglas-fir/tanoak forests, which is somewhat supprising.\nHundhr fuels were higher in our stands. This makes sense given the logging.\nTotal fine fuel loading (onetenhundhr) was similar to other studies, but apprently with more hundhr particles.\nThoushr fuels are notoriously variable. Those on our sites were more consistent and within the middle of the range of other reported values.\nWoody vegetation was much higher than in the one other reported study. That study was in old-growth redwoods. Our values include tree sprout vegetation, which can be several times taller than evergreen huckleberry and much bushier than understory tanoak saplings. Stuart did mention the presence of “nearly inpenetrable [evergreen huckleberry] thickets.” Stuart (1985) found good correlation of live fuels (which included leaves and “twigs”) with basal diamter for both huckleberry and tanoak saplings. The simple scaling factor and/or the occular estimates we used may be biased.",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Calculate fuel loading</span>"
    ]
  },
  {
    "objectID": "analysis/calculate_fuel_loading.html#save-data",
    "href": "analysis/calculate_fuel_loading.html#save-data",
    "title": "2  Calculate fuel loading",
    "section": "2.10 Save data",
    "text": "2.10 Save data\nI’ll Save this data so it can be used in subsequent analysis.\n\ndufflitter, fwd, cwd, and veg, represent mostly raw data in a long format\n\nthis includes two stations per transect for classes for veg and dufflitter\n\ntotal_load is the summarized loading for all classes by transect.\n\n\ntotal_load &lt;- tl2\n\nsave(dufflitter, fwd, cwd, veg, total_load, file = \"calculate_fuel_load.rda\")\n\n\n\n\n\nBrown, James K. 1974. “Handbook for Inventorying Downed Woody Material.” Gen. Tech. Rep. INT-16. Ogden, UT: US Department of Agriculture, Forest Service, Intermountain Forest and Range Experiment Station. 24 p. 16.\n\n\nFinney, Mark A., and Robert E. Martin. 1993. “Fuel Loading, Bulk Density, and Depth of Forest Floor in Coast Redwood Stands.” Forest Science 39 (3): 617–22.\n\n\nGlebocki, Radoslaw. 2015. “Fuel Loading and Moisture Dynamics in Thinned Coast Redwood Forests in Headwaters Forest Reserve, California.” Master’s thesis, Humboldt State University. https://scholarworks.calstate.edu/concern/theses/ws859j014.\n\n\nKittredge, Joseph. 1940. “A Comparison of Forest Floors from Plantations of the Same Age and Environment.” Journal of Forestry 38 (9): 729–31. https://doi.org/10.1093/jof/38.9.729.\n\n\nKrieger, Raven M., Brian E. Wall, Cody W. Kidd, and John-Pascal Berrill. 2020. “Chronosequence of Fuel Loading and Fuel Depth Following Forest Rehabilitation Frill Treatment of Tanoak to Release Douglas-Fir: A Case Study from Northern California.” Forests 11 (6): 691. https://doi.org/10.3390/f11060691.\n\n\nNives, Sherryl L. 1989. “Fire Behavior on the Forest Floor in Coastal Redwood Forests, Redwood National Park.” PhD thesis, Humboldt State University.\n\n\nStuart, John. 1985. “Redwood Fire Ecology: Final Report Submitted to California Department of Parks and Recreation.” Forestry Department, Humboldt State University.\n\n\nValachovic, Yana S., Christopher A. Lee, Hugh Scanlon, J. Morgan Varner, Radoslaw Glebocki, Bradley D. Graham, and David M. Rizzo. 2011. “Sudden Oak Death-Caused Changes to Surface Fuel Loading and Potential Fire Behavior in Douglas-fir-tanoak Forests.” Forest Ecology and Management 261 (11): 1973–86. https://doi.org/10.1016/j.foreco.2011.02.024.\n\n\nVan Wagner, C. E. 1982. “Practical Aspects of the Line Intersect Method.” PI-X-12. Chalk River, Ontario, Canada: Petawawa National Forestry Institute, Canadian Forestry Service.\n\n\nVan Wagtendonk, J. W., J. M. Benedict, and W. M. Sydoriak. 1996. “Physical Properties of Woody Fuel Particles of Sierra Nevada Conifers.” International Journal of Wildland Fire 6 (3): 117–23. https://doi.org/10.1071/wf9960117.\n\n\nVan Wagtendonk, Jan W., James M. Benedict, and Walter M. Sydoriak. 1998. “Fuel Bed Characteristics of Sierra Nevada Conifers.” Western Journal of Applied Forestry 13 (3): 73–84. https://doi.org/10.1093/wjaf/13.3.73.",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Calculate fuel loading</span>"
    ]
  },
  {
    "objectID": "analysis/fuel_data_exploration.html",
    "href": "analysis/fuel_data_exploration.html",
    "title": "3  Fuel data exploration",
    "section": "",
    "text": "3.1 Basic Summary\nCode\n# function to access mostly raw data, but with combined veg and thoushr fuels.\n# and select the output variables (`...`)\nload2 &lt;- function(shape = \"wide\", pct = c(\"pre\", \"post\", \"both\"), ...) {\n  pct &lt;- pct[1]\n  pct_filter &lt;- switch(pct,\n    pre = \"prepct\", post = \"postpct\", both = \"prepct|postpct\"\n  )\n  tl &lt;- filter(total_load, phase == pct_filter)\n  load_vars &lt;- c(\"onehr\", \"tenhr\", \"hundhr\", \"dufflitter\", \"thoushr\", \"veg\", \"veg_diff\")\n  # TODO: if(pct == \"post\")\n  if (!missing(...)) tl &lt;- select(tl, ...)\n  if (shape == \"long\") {\n    tl &lt;- pivot_longer(tl,\n      -any_of(c(\"phase\", \"site\", \"treatment\", \"corner\", \"azi\")),\n      names_to = \"class\",\n      values_to = \"load\"\n    )\n    load_vars &lt;- load_vars[load_vars %in% tl$class]\n    tl &lt;- mutate(tl, class = factor(class, levels = load_vars)) |&gt;\n      filter(!is.na(load))\n  }\n  tl\n}\nFigure 3.1 seems to indicate that, pre-pct, there is slightly higher 1-hr fuel load for HA and HD, compared to GS and LD. Ten years after harvest, we would expect 1-hr fuels to be dominated by twigs and branches falling from live crowns and there is ostensibly a greater crown volume in the HA and HD treatments. Duff and litter may be slightly higher in the HD treatment, compared to the others. For live fuels, there appears to be a decreasing trend from GS &gt; LD &gt; HA & HD. Most of live fuel is due to regenerating sprouts. The difference in sprout growth in high vs. low light environments was readily apparent in the field.\nTen-hr and 100-hr, and 1000-hr fuels do not reveal an obvious trend. I’m not sure why this is at the moment.\nPost-pct\nload2(\"long\", \"pre\") |&gt;\n  # filter(!(load &gt; 190 & class == \"veg\" | load &gt; 400 & class == \"thoushr\")) |&gt;\n  ggplot(aes(treatment, load)) +\n  geom_boxplot() +\n  facet_wrap(~class, scales = \"free\")\n\nload2(\"long\", \"post\", -dufflitter) |&gt;\n  # filter(!(load &gt; 190 & class == \"veg\" | load &gt; 400 & class == \"thoushr\")) |&gt;\n  ggplot(aes(treatment, load)) +\n  geom_boxplot() +\n  facet_wrap(~class, scales = \"free\")\n\n\n\n\n\n\n\n\n\n\n(a) Pre-pct data\n\n\n\n\n\n\n\n\n\n\n\n(b) Post-pct data, “dufflitter” data is not valid for this phase of the experiment. 1-hr fuels do not included suspended leaves\n\n\n\n\n\n\nFigure 3.1: Histograms of raw data Pre- and post-pct.\nHere is a table summary of our raw data.\nspf &lt;- \"%.1f\"\nload2(\"long\", \"pre\") |&gt;\n  group_by(class, treatment) |&gt;\n  summarize(\n    avg_load = mean(load),\n    sd_load = sd(load)\n  ) |&gt;\n  mutate(\n    load = paste0(sprintf(spf, avg_load), \" (\", sprintf(spf, sd_load), \")\"),\n    .keep = \"unused\"\n  ) |&gt;\n  pivot_wider(names_from = treatment, values_from = load) |&gt;\n  knitr::kable()\n\n`summarise()` has grouped output by 'class'. You can override using the\n`.groups` argument.\n\n\n\n\nTable 3.1: Average (sd) transect level load (Mg ha-1) for six fuel class categories in four different overstory harvest techniques.\n\n\n\n\n\n\nclass\ngs\nld\nha\nhd\n\n\n\n\nonehr\n0.6 (0.6)\n0.7 (0.5)\n1.2 (0.8)\n1.0 (0.6)\n\n\ntenhr\n3.7 (2.8)\n3.4 (2.0)\n3.2 (3.2)\n2.9 (1.6)\n\n\nhundhr\n11.8 (8.6)\n9.5 (8.5)\n9.7 (9.0)\n9.5 (7.6)\n\n\ndufflitter\n48.4 (31.1)\n44.9 (18.3)\n40.2 (22.0)\n55.0 (28.9)\n\n\nthoushr\n44.9 (57.0)\n35.3 (52.4)\n41.6 (105.6)\n39.5 (45.1)\n\n\nveg\n38.2 (42.3)\n21.2 (16.0)\n12.9 (14.6)\n17.3 (16.1)",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fuel data exploration</span>"
    ]
  },
  {
    "objectID": "analysis/fuel_data_exploration.html#outliers",
    "href": "analysis/fuel_data_exploration.html#outliers",
    "title": "3  Fuel data exploration",
    "section": "3.2 Outliers",
    "text": "3.2 Outliers\n\ncleavland_plot &lt;- function(data, title, load_var = load) {\n  data |&gt;\n    group_by(site, treatment) |&gt;\n    mutate(replicate_mean_load = mean({{load_var}}, na.rm = TRUE)) |&gt;\n    ggplot(\n      aes(\n        {{load_var}},\n        fct_reorder(\n          interaction(site, treatment, sep = \" \"),\n          {{load_var}},\n          .na_rm = TRUE\n        ),\n        color = treatment\n      )\n    ) +\n    geom_jitter(width = 0, height = 0.2) +\n    labs(x = expression(Load~(Mg%.%ha^-1)), y = \"Data order\", title = title)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n(a) One hour fuels\n\n\n\n\n\n\n\n\n\n\n\n(b) Ten hour fuels\n\n\n\n\n\n\n\n\n\n\n\n(c) Hundred hour fuels\n\n\n\n\n\n\nFigure 3.2: Data distribution of loading for fine woody debris classes. Data are sorted by mean loading within each replicate. Jitter has been added to aid in visual interpretation.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.3: Sum of coarse woody (&gt;7.64 cm, sound and rotten wood combined) fuel loading for transects. The y-axis is sorted by mean CWD loading for each replicate.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.4: Combined duff and litter loading at each station along trancects. Y-axis is sorted as in Figure 3.3.\n\n\n\n\n\n\n\nWarning: Removed 1 rows containing missing values (`geom_point()`).\nRemoved 1 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n(a) Woody vegetation\n\n\n\n\n\n\n\n\n\n\n\n(b) herbaceous vegetation\n\n\n\n\n\n\nFigure 3.5: Vegetation fuel loading for each station along transects, including live and dead fuels attached to live vegetation. Y-axis is sorted as in Figure 3.3.",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fuel data exploration</span>"
    ]
  },
  {
    "objectID": "analysis/fuel_data_exploration.html#sec-Normality",
    "href": "analysis/fuel_data_exploration.html#sec-Normality",
    "title": "3  Fuel data exploration",
    "section": "3.3 Normality",
    "text": "3.3 Normality\nFor further testing, I will summarize the data somewhat, by combining vegetation loading (woody and herb), and coarse woody loading (sound and rotten) into just two loading metrics. Now we have the following response variables:\n\ndufflitter\nonehr\ntenhr\nhundhr\nthoushr\nveg\n\nWhen using manova to test for difference between groups with multiple response variables, it is important that the response variables are multivariate normally distributed. Unfortunately, it would appear that we have a probelem with normality. The raw data for each loading variable is clearly not normally distributed Figure 3.6.\n\nmyqqplot &lt;- function(data, var) {\n  data |&gt;\n  ggplot(aes(sample = {{ var }})) +\n  stat_qq() +\n  stat_qq_line() +\n  facet_grid(class ~ treatment, scales = \"free\") +\n  labs(\n    x = \"Theoretical quantiles\", y = \"Sample quantiles\",\n    title = \"Normal Q-Q Plot\"\n  )\n}\n\nload2(\"long\", \"pre\") |&gt;\n  myqqplot(load)\n\n\n\n\n\n\n\nFigure 3.6: Naive qq plot of loading variables. This doesn’t take into the fact that our data is nested. You could say this is based on a simple model where all observations are independent.\n\n\n\n\n\n\n# This code creates a dataframe with nested columns that include the original\n# data and calculated coordinates of a superimposed normal distribution.\n# TODO: why does this inlcude site corner azi?\nbins &lt;- 16\nhist_dat &lt;- load2(\"long\", \"pre\", all_of(treatment_load_vars)) |&gt;\n  drop_na() |&gt;\n  # Facet grid each column (class) has same scale, find limits to calculate bin\n  # width, limits are either implied by the constructed normal curce, or the raw\n  # data\n  group_by(class) |&gt;\n  mutate(\n    xmin = min(c(mean(load) - 3 * sd(load), load)),\n    xmax = max(c(mean(load) + 3 * sd(load), load))\n  ) |&gt;\n  group_by(treatment, class) |&gt;\n  nest(data = load) |&gt;\n  # generate data for a normal curve with mean and sd from observed data to\n  # cover 3 sd.\n  mutate(\n    norm_x = map(data, function(d) {\n      seq(\n        from = mean(d$load) - 3 * sd(d$load),\n        to = mean(d$load) + 3 * sd(d$load),\n        length.out = 100\n      )\n    }),\n    # scale curve to expected binwidth based on plot layout (same x scale across\n    # all fuel classes) multiplied by the number of observations. The histogram\n    # and normal curve should represent the same total area.\n    norm_y = map(data, function (d) {\n      dens &lt;- dnorm(unlist(norm_x), mean = mean(d$load), sd = sd(d$load))\n      dens * ((xmax - xmin) / bins) * nrow(d)\n    })\n  )\n\n# # here is the code to plot the above data. I decided not to use this after all,\n# # but it was a lot of work, so I'm keeping it for posterity\n# ggplot(filter(hist_dat, class %in% load_vars[1:3] )) +\n#   geom_histogram(data = \\(x) unnest(x, data), aes(x = load), bins = bins) +\n#   geom_line(data = \\(x) unnest(x, c(norm_x, norm_y)), aes(norm_x, norm_y)) +\n#   facet_grid(treatment ~ class, scales = \"free\") +\n#   labs(y = \"count\", x = \"Load Mg/ha\")\n#\n# ggplot(filter(hist_dat, class %in% load_vars[4:6] )) +\n#   geom_histogram(data = \\(x) unnest(x, data), aes(x = load), bins = bins) +\n#   geom_line(data = \\(x) unnest(x, c(norm_x, norm_y)), aes(norm_x, norm_y)) +\n#   facet_grid(treatment ~ class, scales = \"free\") +\n#   labs(y = \"count\", x = \"Load Mg/ha\")\n\n\n\nCode\nwalk(list(c(1:3), c(4:6)),\n  function(x) {\n    p &lt;- load2(\"long\", \"pre\") |&gt;\n      filter(class %in% load_vars[x]) |&gt;\n      ggplot(aes(load)) +\n      geom_histogram(bins = 16) +\n      facet_grid(treatment ~ class, scales = \"free\") +\n      labs(y = \"count\", x = \"Load Mg/ha\")\n    print(p)\n  }\n)\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\nFigure 3.7: Histotrams for the fuel loading response variables.\n\n\n\n\n\n3.3.1 Box-Cox transformation\nI would like to look at the effect of this transformation on the response data.\n\nboxcox &lt;- function(y, lambda1, lambda2) {\n  if (lambda1 == 0) {\n    log(y + lambda2)\n  } else {\n    ((y + lambda2)^lambda1 - 1) / lambda1\n  }\n}\n\nload2(\"long\", \"pre\", all_of(treatment_load_vars)) |&gt;\n  group_by(class) |&gt; nest() |&gt; rowwise() |&gt;\n  mutate(\n    lambda = list(suppressMessages(geoR::boxcoxfit(data$load, lambda2 = TRUE)$lambda)),\n    load_bc = list(boxcox(data$load, lambda[1], lambda[2]))\n  ) |&gt;\n  unnest(c(data, load_bc)) |&gt; ungroup() |&gt;\n  myqqplot(load_bc)\n\n\n\n\n\n\n\n\nWhile, this looks somewhat more normal, the zeros end up being a little strange. I applied a separte transformation for each fuel class, but all treatments within a fuel class have the same transformation.\nFor MANOVA we are concered with the within group multivariate normality, the assumption does not appear to be met here either (Figure 3.8). The code output below indicates the rows with the greatest deviation from normal.\n\ntl &lt;- load2(\"wide\", \"pre\", all_of(treatment_load_vars))\nload_mod &lt;- lm(as.matrix(tl[-1]) ~ treatment, data = tl)\nm_dist &lt;- heplots::cqplot(load_mod)\n\nload2(\"wide\", \"pre\", everything())[order(m_dist, decreasing = TRUE)[1:10], ]\n\n# A tibble: 10 × 12\n   phase  site    treatment corner   azi dufflitter onehr  tenhr hundhr thoushr\n   &lt;chr&gt;  &lt;chr&gt;   &lt;fct&gt;     &lt;chr&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n 1 prepct waldos  ha        nw        90       23.2 1.27  10.7    21.2    593. \n 2 prepct waldos  gs        ne       270      131.  1.72   6.46   16.1     36.3\n 3 prepct whiskey ha        n        225       27.1 2.76  13.3    45.2     32.1\n 4 prepct waldos  gs        se       270       54.1 0.504 11.6    34.8    280. \n 5 prepct whiskey gs        n        225       27.1 0.124  2.09    8.56     0  \n 6 prepct waldos  ha        se       270      112.  2.32   0.930   2.54     0  \n 7 prepct waldos  ha        se         0       15.5 3.34   6.53   13.7     17.7\n 8 prepct waldos  gs        se         0       38.7 1.08   7.31   37.3     17.6\n 9 prepct waldon  gs        e        225      112.  0.711  8.98   14.7     89.6\n10 prepct whiskey ld        s        315       77.3 0.390  5.38   31.9     59.8\n# ℹ 2 more variables: veg &lt;dbl&gt;, veg_diff &lt;dbl&gt;\n\ntreatments &lt;- c(\"gs\", \"ha\", \"ld\", \"hd\")\npar(mfrow = c(2, 2))\ninvisible(lapply(treatments, \n  \\(x) heplots::cqplot(filter(tl, treatment == x)[-1], main = x)\n))\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\nFigure 3.8: Plot A assessed the multivariate normality of residuals given the model where all loading variabels are a function of the treatment group.\n\n\n\n\nA number of different tests of multivariate normaliy also confirm the lack of evidence for meeting this assumption (Table 3.2).\n\nall_mvn_tests &lt;- function(data) {\n  c(\"mardia\", \"hz\", \"royston\", \"dh\", \"energy\") |&gt;\n  map(\\(x) MVN::mvn(data = data, subset = \"treatment\", mvnTest = x)) |&gt;\n  map(\\(x) x$multivariateNormality) |&gt;\n  map(\\(x) bind_rows(x, .id = \"treatment\")) |&gt;\n  map_dfr(\\(x) \n    filter(x, Test != \"MVN\") |&gt; \n    mutate( across(where(is.factor), \\(f) as.numeric(as.character(f)))) |&gt; \n    select(1:2, statistic = 3, `p value`, Result = last_col())\n  )\n}\n\nall_mvn_tests(load2(\"wide\", \"pre\", all_of(treatment_load_vars))) |&gt;\n  knitr::kable(digits = 4)\n\n\n\nTable 3.2: Several different tests of multivariate normality indicate a lack of evidence to support this assumption.\n\n\n\n\n\n\ntreatment\nTest\nstatistic\np value\nResult\n\n\n\n\ngs\nMardia Skewness\n156.2386\n0.0000\nNO\n\n\ngs\nMardia Kurtosis\n4.1306\n0.0000\nNO\n\n\nld\nMardia Skewness\n122.0012\n0.0000\nNO\n\n\nld\nMardia Kurtosis\n3.2534\n0.0011\nNO\n\n\nha\nMardia Skewness\n198.9055\n0.0000\nNO\n\n\nha\nMardia Kurtosis\n5.8903\n0.0000\nNO\n\n\nhd\nMardia Skewness\n85.1671\n0.0072\nNO\n\n\nhd\nMardia Kurtosis\n0.7268\n0.4673\nYES\n\n\ngs\nHenze-Zirkler\n1.1979\n0.0000\nNO\n\n\nld\nHenze-Zirkler\n1.1036\n0.0001\nNO\n\n\nha\nHenze-Zirkler\n1.2792\n0.0000\nNO\n\n\nhd\nHenze-Zirkler\n1.0978\n0.0001\nNO\n\n\ngs\nRoyston\n79.7755\n0.0000\nNO\n\n\nld\nRoyston\n65.9480\n0.0000\nNO\n\n\nha\nRoyston\n105.5921\n0.0000\nNO\n\n\nhd\nRoyston\n51.6106\n0.0000\nNO\n\n\ngs\nDoornik-Hansen\n45.8165\n0.0000\nNO\n\n\nld\nDoornik-Hansen\n38.4513\n0.0001\nNO\n\n\nha\nDoornik-Hansen\n57.3566\n0.0000\nNO\n\n\nhd\nDoornik-Hansen\n67.3211\n0.0000\nNO\n\n\ngs\nE-statistic\n1.9038\n0.0000\nNO\n\n\nld\nE-statistic\n1.7881\n0.0000\nNO\n\n\nha\nE-statistic\n2.1409\n0.0000\nNO\n\n\nhd\nE-statistic\n1.6312\n0.0000\nNO\n\n\n\n\n\n\n\n\n\n\n3.3.2 Other distributions\nIf our data is not normally distributed, then what distribution is it? I’m going to assume what we are interested in the distribution of data within groups (treatments).\nI attemped to model the distribution of our conditional response data (fuel size class by treatment), but it mostly didn’t work.\nOur data is non-negative (contains zeros) continuous (for the most part) and highly variable in terms of skew and kurtosis. The presence of zeros, makes using the Gamma distribution more difficult. One possibility is a hurdle gamma, or Zero-adjusted Gamma.\nThe following show where our data lies in terms of kurtosis and skewness compared to other common distributions. It looks somewhat Gamma-ish?\nd &lt;- load2(\"long\", \"pre\", treatment, all_of(load_vars)) |&gt;\n  split(~class) |&gt; map(~split(.x, ~treatment))\n\n# imap_dfr(d, \\(x, y) tibble(class = y, treatment = names(x) )) |&gt;\n#   with(paste0(\"Treatment \", treatment, \", fuel class \", class)) |&gt;\n#   cat(sep = \"\\n\")\n\n# par(mfrow = c(2,2))\nwalk(d, ~ walk(.x, \\(x) fitdistrplus::descdist(x$load, boot = 111)))\n\n\n\n\n\n\n\n\n\n\n\n(a) Treatment gs, fuel class onehr\n\n\n\n\n\n\n\n\n\n\n\n(b) Treatment ha, fuel class onehr\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Treatment hd, fuel class onehr\n\n\n\n\n\n\n\n\n\n\n\n(d) Treatment ld, fuel class onehr\n\n\n\n\n\n\n\n\n\n\n\n\n\n(e) Treatment gs, fuel class tenhr\n\n\n\n\n\n\n\n\n\n\n\n(f) Treatment ha, fuel class tenhr\n\n\n\n\n\n\n\n\n\n\n\n\n\n(g) Treatment hd, fuel class tenhr\n\n\n\n\n\n\n\n\n\n\n\n(h) Treatment ld, fuel class tenhr\n\n\n\n\n\n\n\n\n\n\n\n\n\n(i) Treatment gs, fuel class hundhr\n\n\n\n\n\n\n\n\n\n\n\n(j) Treatment ha, fuel class hundhr\n\n\n\n\n\n\n\n\n\n\n\n\n\n(k) Treatment hd, fuel class hundhr\n\n\n\n\n\n\n\n\n\n\n\n(l) Treatment ld, fuel class hundhr\n\n\n\n\n\n\n\n\n\n\n\n\n\n(m) Treatment gs, fuel class dufflitter\n\n\n\n\n\n\n\n\n\n\n\n(n) Treatment ha, fuel class dufflitter\n\n\n\n\n\n\n\n\n\n\n\n\n\n(o) Treatment hd, fuel class dufflitter\n\n\n\n\n\n\n\n\n\n\n\n(p) Treatment ld, fuel class dufflitter\n\n\n\n\n\n\n\n\n\n\n\n\n\n(q) Treatment gs, fuel class thoushr\n\n\n\n\n\n\n\n\n\n\n\n(r) Treatment ha, fuel class thoushr\n\n\n\n\n\n\n\n\n\n\n\n\n\n(s) Treatment hd, fuel class thoushr\n\n\n\n\n\n\n\n\n\n\n\n(t) Treatment ld, fuel class thoushr\n\n\n\n\n\n\n\n\n\n\n\n\n\n(u) Treatment gs, fuel class veg\n\n\n\n\n\n\n\n\n\n\n\n(v) Treatment ha, fuel class veg\n\n\n\n\n\n\n\n\n\n\n\n\n\n(w) Treatment hd, fuel class veg\n\n\n\n\n\n\n\n\n\n\n\n(x) Treatment ld, fuel class veg\n\n\n\n\n\n\n\nFigure 3.9: Skewness and kurtosis for fuel classes within treatments.\n\n\n\n\n\n3.3.3 Zero-adjusted Gamma\nI’ll try using the gamlss package, which fits models “where all the parameters of the assumed distribution for the response can be modelled as additive functions of the explanatory variables.”\nI’m not really sure how it works, but I know if will allow me to fit a model assuming a gamma distribution, while modeling the zeros separately. First I fit a model, then I get the estimated distribution parameters, then I plot the density curve over a histrogram (scaled to density). This looks promising to me.\n\n# Zero adjusted Gamma distribution fit to histograms\nplot_zaga &lt;- function(i, d) {\n  m1 &lt;- gamlss::gamlssML(d, family = gamlss.dist::ZAGA())\n  hist(d, prob = TRUE, main = i, breaks = 20)\n  curve(gamlss.dist::dZAGA(x, mu = m1$mu, sigma = m1$sigma, nu = m1$nu), from = min(d), to = max(d), add = TRUE)\n}\n\nplot_zaga_class &lt;- function(data, class_name) {\n  if(missing(class_name)) {\n    class_name &lt;- as.character(substitute(data))\n    class_name &lt;- class_name[length(class_name)]\n  }\n  par(mfrow = c(2,2))\n  iwalk(data, ~plot_zaga(.y, .x))\n  mtext(class_name, cex = 1.6, side = 3, line = -2, outer = TRUE)\n}\n\nd2 &lt;- d |&gt; map(~ map(.x, \"load\"))\niwalk(d2, ~plot_zaga_class(.x, .y))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.3.4 Poisson fit of count data\nAll of the woody debris can be viewed as count data, and mean diameter. The mean diameter implies a distribution, which we actually have for coarse woody, but not for FWD.\nI wonder If I can model these counts as a Poisson process.\n\ncwd_counts &lt;- cwd |&gt; \n  group_by(site, treatment, corner, azi) |&gt;\n  summarize(count = sum(count), .groups = \"drop\")\n\npar(mfrow = c(2,2))\ncwd_counts |&gt;\n  group_by(treatment) |&gt;\n  group_walk( function (data, group) {\n    n &lt;- data$count\n    hist(n, main = group, prob = TRUE)\n    lines(0:max(n), dpois(0:max(n), mean(n)))\n  })\n\n\n\n\n\n\n\n\nThat didn’t look so great, so I also tried using a Zero-inflated Poisson distribution, but the model fit an extremely small value for the parameter that controls the probability of zero (referred to here as sigma) and so was effectively the same as the Poisson fit.\n\npar(mfrow = c(2,2))\ncwd_counts |&gt; \n  group_by(treatment) |&gt; nest() |&gt;\n  transmute(\n    sigma = map_dbl(data, \n      ~gamlss::gamlssML(.x$count, family = gamlss.dist::ZIP())$sigma\n    )\n  )\n\n# A tibble: 4 × 2\n# Groups:   treatment [4]\n  treatment    sigma\n  &lt;chr&gt;        &lt;dbl&gt;\n1 gs        2.96e-10\n2 ha        2.01e-10\n3 hd        3.39e-10\n4 ld        3.68e-10",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fuel data exploration</span>"
    ]
  },
  {
    "objectID": "analysis/fuel_data_exploration.html#sec-homogeneity-of-variance",
    "href": "analysis/fuel_data_exploration.html#sec-homogeneity-of-variance",
    "title": "3  Fuel data exploration",
    "section": "3.4 Homogeneity of variance",
    "text": "3.4 Homogeneity of variance\nThere seem to be some pretty big differences in the variance between treatments. This is likely to do with outliers. For linear regression, it is recommended that maximum variance ration should be below 4.\n\nmax_var &lt;- load2(\"long\", \"pre\") |&gt;\n  group_by(class, treatment) |&gt;\n  summarize(var = sd(load)^2, load = max(load), .groups = \"drop_last\") |&gt;\n  summarize(\n    max_var_rat = paste(\"Max. var. ratio: \", round(max(var) / min(var))),\n    x = 1.1, y = max(load) * 1.1, .groups = \"drop\")\n\nload2(\"long\", \"pre\") |&gt;\n  ggplot(aes(treatment, load)) +\n  geom_boxplot() +\n  geom_text(data = max_var, aes(x, y, label = max_var_rat, hjust = \"inward\")) +\n  facet_wrap(~class, scales = \"free\")",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fuel data exploration</span>"
    ]
  },
  {
    "objectID": "analysis/fuel_data_exploration.html#zeros",
    "href": "analysis/fuel_data_exploration.html#zeros",
    "title": "3  Fuel data exploration",
    "section": "3.5 Zeros",
    "text": "3.5 Zeros\nWe do have zeros, which is important if we want to employ a glm like Gamma, which is only defined for positive values.\n\nload2(\"long\", \"pre\") |&gt;\n  group_by(class, treatment) |&gt;\n  summarize(zeros = sum(load == 0), percent = zeros / n(), .groups = \"drop\") |&gt;\n  ggplot(aes(treatment, percent)) +\n  geom_col() +\n  geom_text(\n    aes(label = if_else(zeros == 0, NA, zeros), y = percent / 2),\n    color = \"gray70\", na.rm = TRUE\n  ) +\n  facet_wrap(~class) +\n  scale_y_continuous(labels = scales::percent)",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fuel data exploration</span>"
    ]
  },
  {
    "objectID": "analysis/fuel_data_exploration.html#correlation-of-response-variables",
    "href": "analysis/fuel_data_exploration.html#correlation-of-response-variables",
    "title": "3  Fuel data exploration",
    "section": "3.6 Correlation of response variables",
    "text": "3.6 Correlation of response variables\nI’m not sure if it’s important, but I was curious if the various fuel loading classes were correlated with each other. Either across the board, or within a given treatment.\n\nsuppressMessages(GGally::ggpairs(load2(\"wide\", \"pre\", all_of(load_vars))))\n\n\n\n\n\n\n\nFigure 3.10: Correlation among the response variables (fuel classes).",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fuel data exploration</span>"
    ]
  },
  {
    "objectID": "analysis/fuel_data_exploration.html#independence",
    "href": "analysis/fuel_data_exploration.html#independence",
    "title": "3  Fuel data exploration",
    "section": "3.7 Independence",
    "text": "3.7 Independence\nBecause of how are data were collected they are not independent. The current data is summarized at the transect level. At that level. We have two transects at each corner. Because of spatial autocorrelation, these may be correlated with each other. Corners (and thus transects) are nested within plots, and plots are within treatments. Each plot received a different treatment. What I’m not clear about is: should I include a random variable for plots, if I’m including a fixed effect for treatment?\nThere are also question about at what level to summarize/model the data. I’ve already averaged stations within transects for several variable that were collected at the station level (two within each transect). What are the trade-offs for either averaging at the corner level, or alternatively, analyzing our raw station data instead of averaging.\n\n\n\n\nZuur, Alain F., Elena N. Ieno, and Chris S. Elphick. 2010. “A Protocol for Data Exploration to Avoid Common Statistical Problems.” Methods in Ecology and Evolution 1 (1): 3–14. https://doi.org/10.1111/j.2041-210X.2009.00001.x.",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fuel data exploration</span>"
    ]
  },
  {
    "objectID": "analysis/fuel_data_modeling.html",
    "href": "analysis/fuel_data_modeling.html",
    "title": "4  Fuel modeling",
    "section": "",
    "text": "5 Setup\nCode\nload(\"./calculate_fuel_load.rda\")\nsource(\"./scripts/get_fuel_data.r\")\ntransectid &lt;- c(\"site\", \"treatment\", \"corner\", \"azi\")\n\nload_quiet(\nlibrary(glmmTMB),\nlibrary(ggdist),\nlibrary(bayesplot),\nlibrary(brms),\nlibrary(tidybayes),\nlibrary(DHARMa),\nlibrary(tidyverse)\n)",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Fuel modeling</span>"
    ]
  },
  {
    "objectID": "analysis/fuel_data_modeling.html#frequentist-approach",
    "href": "analysis/fuel_data_modeling.html#frequentist-approach",
    "title": "4  Fuel modeling",
    "section": "5.1 Frequentist approach",
    "text": "5.1 Frequentist approach\nExploration of frequentist and Bayesian approaches can lead to more robust conclusions.\n\n5.1.1 Manova and multiple anovas\nThe often recommended Pillai’s Trace Test is robust to the normality assumption. Follow up with linear discriminant analysis, or multiple one-way anovas dependidng on research question. Using a Bonferroni correction for rejecting the null of alpha / m, for m hypothesis, we get an alpha of 0.008 for an alpha of 0.05 and 6 tests.\nThis suggests that it is unlikely that all treatemnts are equal.\n\n\nCode\nload_vars &lt;- c(\"onehr\", \"tenhr\", \"hundhr\", \"dufflitter\", \"thoushr\", \"veg\")\ntl &lt;- load2(\"wide\", \"pre\", treatment, all_of(load_vars))\nmyexpr &lt;- expr(cbind(!!!syms(load_vars)) ~ treatment)\ntest1 &lt;- do.call(\"manova\", list(myexpr, data = quote(tl)))\nsummary(test1)\n\n\n           Df  Pillai approx F num Df den Df    Pr(&gt;F)    \ntreatment   3 0.35947   2.7454     18    363 0.0001889 ***\nResiduals 124                                             \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n5.1.2 Multiple one-way anovas\nOne way anova (using the welch test) can either assume constant variance or not. A levene test (using median) indicates onehr, tenhr, and veg may all have different variances between groups.\nThe one-way anova test results are the same though between equal and unequal variance assumptions. These tests support the notion that we can’t assume that the mean vegetatvie and onehr fuel loading are equal across all treatments, but there isn’t such evidence for the other fuel loading classes.\n\n\nCode\nd &lt;- load2(\"long\", \"pre\", treatment, all_of(load_vars)) |&gt; group_by(class)\n\nd |&gt; nest() |&gt;\n  rowwise() |&gt;\n  transmute(\n    levene = car::leveneTest(load ~ factor(treatment), data)[[3]][1],\n    welch_uneq_var = oneway.test(load ~ treatment, data)$p.value,\n    welch_eq_var = oneway.test(\n      load ~ treatment, var.equal = TRUE, data = data\n    )$p.value,\n  ) |&gt;\n  knitr::kable(digits = 3)\n\n\n\n\nTable 5.1: Levene tests suggest that variances are unequal across treatments for all fuel loading classes. Welches tests suggest that veg and onehr fuels may have different means among treatments.\n\n\n\n\n\n\nclass\nlevene\nwelch_uneq_var\nwelch_eq_var\n\n\n\n\nonehr\n0.043\n0.001\n0.000\n\n\ntenhr\n0.020\n0.491\n0.596\n\n\nhundhr\n0.937\n0.648\n0.636\n\n\ndufflitter\n0.118\n0.152\n0.136\n\n\nthoushr\n0.955\n0.919\n0.955\n\n\nveg\n0.006\n0.010\n0.001\n\n\n\n\n\n\n\n\nWe can use the Games Howell test for pairwise comparisons to follow up on the welches test for differences between means when there is unequal variance among groups. These p-values provide evidence that for onehr fuels, the mean value of ha is greater than gs and ld, and the mean value for hd is also greater than gs and ld. Also, for vegetation, gs is greater than ha only. While this test is robust to the assumptions of normality, some of our data is highly skewed. Also, because of the nesting of our data, observations are not independent, so our effective sample size is not what is assumed by this test.\n\n\nCode\ngh_test &lt;- d |&gt; rstatix::games_howell_test(load ~ treatment) |&gt;\n  filter(p.adj.signif != \"ns\") |&gt;\n  rstatix::add_y_position(scales = \"free\", step.increase = 0.5)\n\nggpubr::ggboxplot(d, x = \"treatment\", y = \"load\", facet.by = \"class\") +\n  facet_wrap(~class, scales = \"free\") +\n  ggpubr::stat_pvalue_manual(gh_test, label = \"p.adj\") +\n  scale_y_continuous(expand = expansion(mult = c(0.05, 0.1)))\n\n\n\n\n\n\n\n\nFigure 5.1: pair-wise tests using Games-Howell, for unequal variances across groups. This shows many statistically significant differences, but the assumption of independence, which is likely to have a significant effect on our effective sample size.\n\n\n\n\n\n\n\n5.1.3 Multi-level model\nWe have transects nested within plot corners, corners nested within plots, and plots nested within sites. We would like to detect a treatment effect, while accounting for the non-independence of this nested data structure. The following model, I believe, captures this grouping structure.\n\n\nCode\nform &lt;- load ~ treatment + (1 | site/treatment/corner)\n\n\nThis will estimate a group-wise intercept adjustments for each site, plot, and corner, based on modeled variances for each of these grouping levels.\n\n\nCode\nd &lt;- load2(\"long\", \"pre\", site, treatment, corner, all_of(load_vars)) |&gt; \n  group_by(class)\n\nm1 &lt;- d |&gt; nest() |&gt; rowwise() |&gt;\n  transmute(\n    mod = list(lme4::lmer(form, data = data)),\n    emmeans = list(emmeans::emmeans(mod, \"treatment\")),\n    pairs = list(as_tibble(pairs(emmeans, infer = TRUE)))\n  )\n\n\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\n\n\nPairwise comparisons with Tukey adjustment for each of 6 multilevel models representing different fuel loading classes reveals that the only evidence for differences in means among treatments is with vegetation between the gs and ha treatments. Another sizeable difference in means is between gs and ha for the onehr fuels (Figure 5.2).\n\n\nCode\nselect(m1, pairs) |&gt; unnest(pairs) |&gt;\n  filter(p.value &lt;= 0.05) |&gt;\n  knitr::kable(digits = 3)\n\n\nAdding missing grouping variables: `class`\n\n\n\n\nTable 5.2: Pairwise comparisons among treatments with p-values &lt; 0.05 for 6 multilevel models. Only Veg, gs-ha comparison is statistically significant.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass\ncontrast\nestimate\nSE\ndf\nlower.CL\nupper.CL\nt.ratio\np.value\n\n\n\n\nveg\ngs - ha\n25.31\n6.879\n9\n3.835\n46.786\n3.679\n0.022\n\n\n\n\n\n\n\n\n\n\nCode\ngroup_map(m1, ~ plot(.x$emmeans[[1]], comparisons = TRUE) + ggtitle(.x$class)) |&gt;\n  patchwork::wrap_plots()\n\n\n\n\n\n\n\n\nFigure 5.2: 95% confidence intervals and pairwise comparisons of means for 6 mixed models representing different fuel loading classes using package emmeans.\n\n\n\n\n\nHypothesis testing with multi-level models is not as straight forward with multi-level models. The problem, explained here is two fold. For GLMMs and unbalanced experimental designs, the null distribution for the F-statistic may not be F-distributed.\nFor us, we have a balanced design (I think) and so the F-statistic should be F distributed and degrees of freedom should be clear from the details of the design. Because of our balanced design, the Kenward-Rogers approach and “inner-outer” design approach (which is used by nlme::lme) give the same result of 9 DF for all of the pairwise tests.\nUsing the package pbkrtest we can get parametric bootstrap liklihood ratio statistics and test this statistic in a number of different ways. The PBtest should probably be the most reliable, but I’ve included descriptions of the others from the package documentation for reference. I’m also including an F-test in which degrees of freedom are estimated with Kenward-Rogers approach.\n\nLRT\n\nAssuming that LRT has a chi-square distribution.\n\nPBtest\n\nThe fraction of simulated LRT-values that are larger or equal to the observed LRT value.\n\nBartlett\n\nA Bartlett correction is of LRT is calculated from the mean of the simulated LRT-values\n\nGamma\n\nThe reference distribution of LRT is assumed to be a gamma distribution with mean and variance determined as the sample mean and sample variance of the simulated LRT-values.\n\nF\n\nThe LRT divided by the number of degrees of freedom is assumed to be F-distributed, where the denominator degrees of freedom are determined by matching the first moment of the reference distribution.\n\n\n\n\nCode\nd &lt;- load2(\"long\", \"pre\", all_of(c(transectid, load_vars)))\ndd &lt;- ungroup(d) |&gt; split(~class)\n\n\nif(file.exists(\"pmod.rda\")) {\n  load(\"pmod.rda\")\n} else {\n  cluster &lt;- parallel::makeCluster(rep(\"localhost\", parallel::detectCores()))\n\n  pmod &lt;- imap(dd, function(d, i) {\n    form &lt;- load ~ treatment + (1 | site/treatment/corner)\n    amod &lt;- lme4::lmer(form, d, REML = FALSE)\n    nmod &lt;- update(amod, . ~ . -treatment)\n    krtest &lt;- pbkrtest::KRmodcomp(amod, nmod) |&gt;\n      pluck(\"test\", \\(x) slice(x, 1)) |&gt;\n      rename(df = ndf) |&gt;\n      rownames_to_column(\"test\")\n    pbkrtest::PBmodcomp(amod, nmod, cl = cluster) |&gt;\n      pluck(summary, \"test\") |&gt;\n      rownames_to_column(\"test\") |&gt;\n      bind_rows(krtest) |&gt;\n      mutate(class = i, .before = 1) |&gt;\n      relocate(c(df, ddf, F.scaling), .after = stat)\n  }) |&gt; \n    list_rbind() |&gt;\n    filter(test %in% c(\"LRT\", \"PBtest\"))\n \n  parallel::stopCluster(cluster)\n  save(pmod, file = \"pmod.rda\")\n}\n\npmod |&gt; knitr::kable(digits = c(NA, NA, 2, 1, 2, 1, 4))\n\n\n\n\nTable 5.3: Liklihood ratio tests and parametric boot strap tests of model significance: whether the model with treatment, fits the data better than the intercept only model (adjusting for nesting structure).\n\n\n\n\n\n\nclass\ntest\nstat\ndf\nddf\nF.scaling\np.value\n\n\n\n\nonehr\nLRT\n7.48\n3\nNA\nNA\n0.0580\n\n\nonehr\nPBtest\n7.48\nNA\nNA\nNA\n0.1449\n\n\ntenhr\nLRT\n0.77\n3\nNA\nNA\n0.8576\n\n\ntenhr\nPBtest\n0.77\nNA\nNA\nNA\n0.9071\n\n\nhundhr\nLRT\n0.70\n3\nNA\nNA\n0.8725\n\n\nhundhr\nPBtest\n0.70\nNA\nNA\nNA\n0.9021\n\n\ndufflitter\nLRT\n6.05\n3\nNA\nNA\n0.1093\n\n\ndufflitter\nPBtest\n6.05\nNA\nNA\nNA\n0.1109\n\n\nthoushr\nLRT\n0.22\n3\nNA\nNA\n0.9739\n\n\nthoushr\nPBtest\n0.22\nNA\nNA\nNA\n0.9706\n\n\nveg\nLRT\n11.70\n3\nNA\nNA\n0.0085\n\n\nveg\nPBtest\n11.70\nNA\nNA\nNA\n0.0280\n\n\n\n\n\n\n\n\n\n\n5.1.4 Model checking\nTaking a look at residual vs. fitted and qqplots of the model, it looks like our residuals are not normally distributed and there is not constant variance.\n\n\nCode\n# These are functions to plot for each model, residuals vs fitted and normal\n# quantiles. The third function is a wrapper to do both.\nresid_plot &lt;- function(data) {\n  data |&gt;\n    ggplot(aes(fitted, resid)) +\n    geom_point() +\n    facet_wrap(~class, scales = \"free\") +\n    geom_hline(yintercept = 0)\n}\n\nqq_plot &lt;- function(data) {\n  data |&gt;\n    ggplot(aes(sample = resid)) +\n    stat_qq() +\n    stat_qq_line() +\n    facet_wrap(~class, scales = \"free\")\n}\n\nresid_qq_plot &lt;- function(data) {\n  data &lt;- unnest(data, c(resid, fitted))\n  list(\n    a = resid_plot(data),\n    b = qq_plot(data)\n  )\n}\n\nd &lt;- load2(\"long\", \"pre\", all_of(c(transectid, load_vars))) |&gt;\n  group_by(class) |&gt; nest() |&gt; rowwise()\n\n\n\n\nCode\nform &lt;- load ~ treatment + (1 | site/treatment/corner)\n\nmod1 &lt;- d |&gt;\n  mutate(\n    mod = list(lme4::lmer(form, data)),\n    fitted = list(fitted(mod)),\n    resid = list(resid(mod, type = \"pearson\", scaled = TRUE)),\n    .keep = \"unused\"\n  ) \n\n\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\n\n\nCode\nresid_qq_plot(mod1) |&gt; patchwork::wrap_plots(ncol = 1)\n\n\n\n\n\n\n\n\nFigure 5.3: Residual vs fitted and normal quantile-quantile plots for a multi-level model with un-pooled treatment intercepts and partially pooled (random effects) for nested data. Fit using lme4 The residuals are not homogenous.\n\n\n\n\n\nI’ll try to control the variance by refitting the model with nlme::lme and using the weights argument. I’ll be using the pearson residuals which are corrected for heteroscedasticity.\nI had to use the control argument sigma = 1 for the model to fit. I’m not sure why, I read it in the documentation for nlme::varConstProp. I’m modeling variance as a constant proportion of the fitted values of the model. This seems to have cleaned up the variance, but the the model for 1,000-hr fuels is causing a “singular matrix” error. Perhaps this is because of the excess of zeros?\nAdditionaly, residuals are still not normally distributed.\n\n\nCode\nmod2 &lt;- d |&gt;\n  filter(class != \"thoushr\") |&gt;\n  mutate(\n    mod = list(nlme::lme(\n      fixed = load ~ treatment,\n      random = ~ 1 | site/treatment/corner,\n      data = data,\n      weights = nlme::varConstProp(),\n      control = nlme::lmeControl(sigma = 1)\n    )),\n    fitted = list(fitted(mod)),\n    resid = list(resid(mod, type = \"pearson\")),\n    .keep = \"unused\"\n  )\n\npatchwork::wrap_plots(resid_qq_plot(mod2), ncol = 1)\n\n\n\n\n\n\n\n\nFigure 5.4: Same as Figure 5.3 but variance is modeled as a function fitted values, assuming a linear relationship. Fit with nlme. The (scaled) residuals are more homogenous now.\n\n\n\n\n\nfirst, I want to see if the models produced by lme and lmer are equivalent they seem equivalent enough, although the random effects variances estimated by lmer are somewhat smaller.\n\n\nCode\nd |&gt;\n  mutate(\n    mod1 = list(lme4::lmer(form, data)),\n    mod2 = list(nlme::lme(\n      fixed = load ~ treatment,\n      random = ~ 1 | site/treatment/corner,\n      data = data\n    )),\n    .keep = \"unused\"\n  ) |&gt;\n  pivot_longer(-class, names_to = \"model\") |&gt;\n  rowwise() |&gt;\n  mutate(s = list(broom.mixed::tidy(value, effect = \"fixed\"))) |&gt;\n  select(class, model, s) |&gt;\n  unnest(everything()) |&gt;\n  arrange(class, term) |&gt; print(n=48)\n\n\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\n\n\n# A tibble: 48 × 9\n   class      model effect term     estimate std.error statistic    df   p.value\n   &lt;fct&gt;      &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n 1 onehr      mod1  fixed  (Interc…   0.598      0.191     3.13     NA NA       \n 2 onehr      mod2  fixed  (Interc…   0.598      0.191     3.13     64  2.65e- 3\n 3 onehr      mod1  fixed  treatme…   0.603      0.256     2.35     NA NA       \n 4 onehr      mod2  fixed  treatme…   0.603      0.256     2.35      9  4.33e- 2\n 5 onehr      mod1  fixed  treatme…   0.439      0.256     1.71     NA NA       \n 6 onehr      mod2  fixed  treatme…   0.439      0.256     1.71      9  1.21e- 1\n 7 onehr      mod1  fixed  treatme…   0.0697     0.256     0.272    NA NA       \n 8 onehr      mod2  fixed  treatme…   0.0697     0.256     0.272     9  7.92e- 1\n 9 tenhr      mod1  fixed  (Interc…   3.75       0.784     4.78     NA NA       \n10 tenhr      mod2  fixed  (Interc…   3.75       0.784     4.78     64  1.06e- 5\n11 tenhr      mod1  fixed  treatme…  -0.550      1.11     -0.496    NA NA       \n12 tenhr      mod2  fixed  treatme…  -0.550      1.11     -0.496     9  6.32e- 1\n13 tenhr      mod1  fixed  treatme…  -0.828      1.11     -0.747    NA NA       \n14 tenhr      mod2  fixed  treatme…  -0.828      1.11     -0.747     9  4.74e- 1\n15 tenhr      mod1  fixed  treatme…  -0.364      1.11     -0.329    NA NA       \n16 tenhr      mod2  fixed  treatme…  -0.364      1.11     -0.329     9  7.50e- 1\n17 hundhr     mod1  fixed  (Interc…  11.8        2.69      4.39     NA NA       \n18 hundhr     mod2  fixed  (Interc…  11.8        2.69      4.39     64  4.34e- 5\n19 hundhr     mod1  fixed  treatme…  -2.09       3.73     -0.562    NA NA       \n20 hundhr     mod2  fixed  treatme…  -2.09       3.73     -0.562     9  5.88e- 1\n21 hundhr     mod1  fixed  treatme…  -2.34       3.73     -0.627    NA NA       \n22 hundhr     mod2  fixed  treatme…  -2.34       3.73     -0.627     9  5.46e- 1\n23 hundhr     mod1  fixed  treatme…  -2.27       3.73     -0.608    NA NA       \n24 hundhr     mod2  fixed  treatme…  -2.27       3.73     -0.608     9  5.58e- 1\n25 dufflitter mod1  fixed  (Interc…  48.4        5.94      8.14     NA NA       \n26 dufflitter mod2  fixed  (Interc…  48.4        5.94      8.14     64  1.83e-11\n27 dufflitter mod1  fixed  treatme…  -8.15       6.15     -1.33     NA NA       \n28 dufflitter mod2  fixed  treatme…  -8.15       6.15     -1.33      9  2.17e- 1\n29 dufflitter mod1  fixed  treatme…   6.58       6.15      1.07     NA NA       \n30 dufflitter mod2  fixed  treatme…   6.58       6.15      1.07      9  3.12e- 1\n31 dufflitter mod1  fixed  treatme…  -3.50       6.15     -0.570    NA NA       \n32 dufflitter mod2  fixed  treatme…  -3.50       6.15     -0.570     9  5.83e- 1\n33 thoushr    mod1  fixed  (Interc…  44.9       17.1       2.63     NA NA       \n34 thoushr    mod2  fixed  (Interc…  44.9       17.1       2.63     64  1.08e- 2\n35 thoushr    mod1  fixed  treatme…  -3.27      24.2      -0.135    NA NA       \n36 thoushr    mod2  fixed  treatme…  -3.27      24.2      -0.135     9  8.95e- 1\n37 thoushr    mod1  fixed  treatme…  -5.41      24.2      -0.224    NA NA       \n38 thoushr    mod2  fixed  treatme…  -5.41      24.2      -0.224     9  8.28e- 1\n39 thoushr    mod1  fixed  treatme…  -9.65      24.2      -0.399    NA NA       \n40 thoushr    mod2  fixed  treatme…  -9.65      24.2      -0.399     9  6.99e- 1\n41 veg        mod1  fixed  (Interc…  38.2        6.12      6.24     NA NA       \n42 veg        mod2  fixed  (Interc…  38.2        6.12      6.24     64  3.98e- 8\n43 veg        mod1  fixed  treatme… -25.3        6.88     -3.68     NA NA       \n44 veg        mod2  fixed  treatme… -25.3        6.88     -3.68      9  5.08e- 3\n45 veg        mod1  fixed  treatme… -20.9        6.88     -3.04     NA NA       \n46 veg        mod2  fixed  treatme… -20.9        6.88     -3.04      9  1.40e- 2\n47 veg        mod1  fixed  treatme… -17.0        6.88     -2.47     NA NA       \n48 veg        mod2  fixed  treatme… -17.0        6.88     -2.47      9  3.56e- 2\n\n\nNow, lets compare the two lme models using AIC. I’m fitting with REML because I’m not changing the fixed effects structure. I still have to remove 1,000-hr fuels from the mix.\nThis indicates that the model with modeled variance fits the data better than the model without.\n\n\nCode\nmod_c &lt;- d |&gt;\n  filter(class != \"thoushr\") |&gt;\n  mutate(\n    unweighted = list(nlme::lme(\n      fixed = load ~ treatment,\n      random = ~ 1 | site/treatment/corner,\n      data = data,\n    )),\n    weighted = list(nlme::lme(\n      fixed = load ~ treatment,\n      random = ~ 1 | site/treatment/corner,\n      data = data,\n      weights = nlme::varConstProp(),\n      control = nlme::lmeControl(sigma = 1),\n    )),\n    .keep = \"unused\"\n  ) \n\nmod_c |&gt;\n  mutate(aic = list(across(matches(\"weight\"), ~ AIC(.x))))|&gt;\n  select(aic)|&gt; unnest(aic) |&gt; knitr::kable()\n\n\nAdding missing grouping variables: `class`\n\n\n\n\nTable 5.4: Comparison of AIC between multilevel models with and without weights to account for heterogeneity of variance. The models with weights have consistently lower AIC, indicating better fit.\n\n\n\n\n\n\nclass\nunweighted\nweighted\n\n\n\n\nonehr\n251.8197\n220.0447\n\n\ntenhr\n589.9042\n486.1699\n\n\nhundhr\n892.3760\n860.7936\n\n\ndufflitter\n1180.4072\n1177.7730\n\n\nveg\n1171.0855\n1122.1291\n\n\n\n\n\n\n\n\nDoes this change our conclusions about the effect of the treatment?\nNo, it doesn’t seem to make much of a difference.\n\n\nCode\nd &lt;- load2(\"long\", \"pre\", site, treatment, corner, all_of(load_vars))\n\nm2 &lt;- d |&gt; group_by(class) |&gt; nest() |&gt; rowwise() |&gt;\n  filter(class != \"thoushr\") |&gt;\n  transmute(\n    mod = list(nlme::lme(\n      fixed = load ~ treatment,\n      random = ~ 1 | site/treatment/corner,\n      data = data,\n      weights = nlme::varConstProp(),\n      control = nlme::lmeControl(sigma = 1),\n    )),\n    emmeans = list(emmeans::emmeans(mod, \"treatment\")),\n    pairs = list(as_tibble(pairs(emmeans, infer = TRUE)))\n  )\n\n\n\n\nCode\nselect(m2, pairs) |&gt; unnest(pairs) |&gt;\n  filter(p.value &lt;= 0.05) |&gt;\n  knitr::kable(digits = 3)\n\n\nAdding missing grouping variables: `class`\n\n\n\n\nTable 5.5: Pairwise comparisons of treatments (four levels) with p-values &lt; 0.05 for six multilevel models with variance modeled as a linear relationsihp with the fitted value.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass\ncontrast\nestimate\nSE\ndf\nlower.CL\nupper.CL\nt.ratio\np.value\n\n\n\n\nveg\ngs - ha\n25.31\n7.12\n9\n3.083\n47.538\n3.555\n0.026\n\n\n\n\n\n\n\n\n\n\nCode\ngroup_map(m2, ~ plot(.x$emmeans[[1]], comparisons = TRUE) + ggtitle(.x$class)) |&gt;\n  patchwork::wrap_plots()\n\n\n\n\n\n\n\n\nFigure 5.5: 95% confidence intervals and pairwise comparisons of means for 6 mixed models representing different fuel loading classes using a model with variance modeled as a linear relationsihp with the fitted value.\n\n\n\n\n\n\n\n5.1.5 Other random effects structures\nI’m not sure I’m using the correct random effects specification. The somewhat confusing thing is that I have a random effects nested above and below my fixed effect. This means that when I specify my random effect using the nesting notation: 1 | site/treatment/corner, I’m estimating a variance for corner:treatment:site, treatment:site, and site. The interaction of treatment and site here is analagous to a plot effect, of which there are 16.",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Fuel modeling</span>"
    ]
  },
  {
    "objectID": "analysis/fuel_data_modeling.html#trying-glmmtmb",
    "href": "analysis/fuel_data_modeling.html#trying-glmmtmb",
    "title": "4  Fuel modeling",
    "section": "5.2 Trying glmmTMB",
    "text": "5.2 Trying glmmTMB\nThis package also alows fitting flexible models, but unlike the Bayesian approach, it is fast, and familiar as it works in the frequentist paradigm.\n\n\nCode\n# this function will create the model output for each of the fuel classes\nrun_glmmtmb_mod &lt;- function(d, mods) {\n  d |&gt;\n  mutate(\n    mod = select_fuel_mod(class, data, mods),\n    emmeans = list(emmeans::emmeans(mod, \"treatment\", type = \"response\")),\n    pairs = list(as_tibble(pairs(emmeans, infer = TRUE))),\n    aic = AIC(mod),\n    res = list(simulateResiduals(mod, allow.new.levels = TRUE))\n  )\n}\n\n# heres where I'll store model results\nfuel_tmb &lt;- list()\n\n# The pre-pct data\nd &lt;- load2(\"long\", \"pre\", -c(phase, azi)) |&gt; nest(.by = class) |&gt; rowwise()\n\n# The general model formula including random effects\nform &lt;- load ~ treatment + (1 | site/treatment/corner)\n\n# Dufflitter doesn't have any zeros, so i'm using regular gamma. I'm assuming\n# gamma is a good model for all fuel classes (default)\nmods &lt;- alist(\n  dufflitter = glmmTMB(form, data, family = Gamma(link = \"log\")),\n  default = glmmTMB(form, data, family = ziGamma(link = \"log\"), ziformula = ~1)\n)\n\nfuel_tmb$pre &lt;- run_glmmtmb_mod(d, mods)\n\n\n  dufflitter: glmmTMB(form, data, family = Gamma(link = \"log\"))\n       onehr: glmmTMB(form, data, family = ziGamma(link = \"log\"), ziformula = ~1)\n       tenhr: glmmTMB(form, data, family = ziGamma(link = \"log\"), ziformula = ~1)\n      hundhr: glmmTMB(form, data, family = ziGamma(link = \"log\"), ziformula = ~1)\n     thoushr: glmmTMB(form, data, family = ziGamma(link = \"log\"), ziformula = ~1)\n         veg: glmmTMB(form, data, family = ziGamma(link = \"log\"), ziformula = ~1)\n\n\nTODO: interpret these results\n\n\nCode\ngroup_map(fuel_tmb$pre,\n  ~ plot(.x$emmeans[[1]], comparisons = TRUE) + ggtitle(.x$class)) |&gt;\n  patchwork::wrap_plots()\n\n\n\n\n\n\n\n\n\nHere are the (nearly) significant (p &lt;= 0.1) pairwise comparisons in table form\n\n\nCode\nselect(fuel_tmb$pre, class, pairs) |&gt;\n  unnest(pairs) |&gt;\n  filter(p.value &lt;= 0.1) |&gt;\n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass\ncontrast\nratio\nSE\ndf\nasymp.LCL\nasymp.UCL\nnull\nz.ratio\np.value\n\n\n\n\ndufflitter\nha / hd\n0.7355355\n0.0933453\nInf\n0.5308971\n1.0190535\n1\n-2.420308\n0.0732778\n\n\nonehr\ngs / ha\n0.4607889\n0.1128201\nInf\n0.2456568\n0.8643215\n1\n-3.164563\n0.0084498\n\n\nonehr\ngs / hd\n0.5505170\n0.1347705\nInf\n0.2935184\n1.0325380\n1\n-2.438235\n0.0700719\n\n\nonehr\nld / ha\n0.5481210\n0.1340497\nInf\n0.2924250\n1.0273974\n1\n-2.458512\n0.0665849\n\n\nveg\ngs / ha\n2.7236332\n0.8429468\nInf\n1.2298203\n6.0319202\n1\n3.237440\n0.0066198\n\n\n\n\n\nI think these residuals look OK\n\n\nCode\npar(mfrow = c(3, 2))\nfuel_tmb$pre |&gt; group_walk(~ plotResiduals(.x$res[[1]], form = .x$data[[1]]$treatment))\n\n\n\n\n\n\n\n\n\nCode\nfuel_tmb$pre |&gt; group_walk(\\(x, ...){\n  plotResiduals(x$res[[1]], form = x$data[[1]]$treatment)\n  title(sub = x$class)\n})\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(3, 2))\nfuel_tmb$pre |&gt; group_walk(~ plotQQunif(.x$res[[1]], main = .x$class))\n\n\n\n\n\n\n\n\n\n\n5.2.1 Post-pct\nAll fuel classes have zeros, except for dufflitter, but this fuel class is not really valid for post-pct data—we don’t have a depth to load equation suitable for how litter depth was gathered.\nThe veg_diff (pre-pct minus post-pct live vegetation) resulted in some negative values, these are mostly &lt; 2.5 Mg/ha, and I think are attributable to measurement error. I’m simply converting negative values to zero.\nIncluding a model for dispersion (~treatment) only increases aic marginally and only for veg.\n\n\nCode\nd &lt;- load2(\"long\", \"post\", -c(phase, azi, dufflitter)) |&gt;\n  mutate(load = if_else(class == \"veg_diff\" & load &lt;= 0, 0, load)) |&gt;\n  nest(.by = class) |&gt; rowwise()\n\n# same general formula as for pre-pct\nform &lt;- load ~ treatment + (1 | site/treatment/corner)\n\nmods &lt;- alist(\n  default = glmmTMB(form, data, family = ziGamma(link = \"log\"), ziformula = ~1)\n)\n\nmods2 &lt;- alist(\n  default = glmmTMB(form, data, family = ziGamma(link = \"log\"), ziformula = ~1, dispformula = ~ treatment)\n)\n\nfuel_tmb$post &lt;- run_glmmtmb_mod(d, mods)\n\n\n       onehr: glmmTMB(form, data, family = ziGamma(link = \"log\"), ziformula = ~1)\n       tenhr: glmmTMB(form, data, family = ziGamma(link = \"log\"), ziformula = ~1)\n      hundhr: glmmTMB(form, data, family = ziGamma(link = \"log\"), ziformula = ~1)\n     thoushr: glmmTMB(form, data, family = ziGamma(link = \"log\"), ziformula = ~1)\n         veg: glmmTMB(form, data, family = ziGamma(link = \"log\"), ziformula = ~1)\n    veg_diff: glmmTMB(form, data, family = ziGamma(link = \"log\"), ziformula = ~1)\n\n\nCode\n# fuel_tmb$post2 &lt;- run_glmmtmb_mod(d, mods2)\n\n# data.frame(class = fuel_tmb$post$class, no_disp = fuel_tmb$post$aic, disp = fuel_tmb$post2$aic)\n\n\n\n\nCode\ngroup_map(fuel_tmb$post,\n  ~ plot(.x$emmeans[[1]], comparisons = TRUE) + ggtitle(.x$class)) |&gt;\n  patchwork::wrap_plots()\n\n\n\n\n\n\n\n\n\n\n\nCode\nselect(fuel_tmb$post, class, pairs) |&gt;\n  unnest(pairs) |&gt;\n  filter(p.value &lt;= 0.1) |&gt;\n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass\ncontrast\nratio\nSE\ndf\nasymp.LCL\nasymp.UCL\nnull\nz.ratio\np.value\n\n\n\n\nonehr\ngs / ha\n1.9354714\n0.4135687\nInf\n1.1178463\n3.3511311\n1\n3.090394\n0.0107693\n\n\nonehr\nld / ha\n1.9457012\n0.4188951\nInf\n1.1191046\n3.3828411\n1\n3.091711\n0.0107236\n\n\nonehr\nha / hd\n0.5661802\n0.1204280\nInf\n0.3278227\n0.9778459\n1\n-2.674358\n0.0375683\n\n\ntenhr\ngs / ld\n1.6374424\n0.2920732\nInf\n1.0355091\n2.5892749\n1\n2.764652\n0.0291135\n\n\ntenhr\ngs / ha\n2.3365803\n0.4170942\nInf\n1.4771289\n3.6960943\n1\n4.754391\n0.0000118\n\n\ntenhr\ngs / hd\n2.9365721\n0.5249374\nInf\n1.8552261\n4.6481968\n1\n6.026246\n0.0000000\n\n\ntenhr\nld / hd\n1.7933896\n0.3212336\nInf\n1.1319480\n2.8413373\n1\n3.260967\n0.0061109\n\n\nhundhr\ngs / hd\n2.5333426\n0.6226426\nInf\n1.3473307\n4.7633625\n1\n3.782013\n0.0008951\n\n\nhundhr\nld / hd\n1.7743840\n0.4365649\nInf\n0.9430607\n3.3385325\n1\n2.330756\n0.0911211\n\n\nthoushr\nld / hd\n0.3764228\n0.1325121\nInf\n0.1523739\n0.9299110\n1\n-2.775453\n0.0282219\n\n\nthoushr\nha / hd\n0.3838056\n0.1437479\nInf\n0.1466353\n1.0045789\n1\n-2.556834\n0.0516412\n\n\nveg_diff\ngs / ha\n2.7988613\n0.8801525\nInf\n1.2477403\n6.2782492\n1\n3.272868\n0.0058672\n\n\nveg_diff\ngs / hd\n2.5044358\n0.7622966\nInf\n1.1458025\n5.4740663\n1\n3.016190\n0.0136458\n\n\n\n\n\n\n\nCode\npar(mfrow = c(3, 2))\nfuel_tmb$post |&gt; group_walk(\\(x, ...){\n  plotResiduals(x$res[[1]], form = x$data[[1]]$treatment)\n  title(sub = x$class)\n})\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(3, 2))\nfuel_tmb$post |&gt; group_walk(~ plotQQunif(.x$res[[1]], main = .x$class))\n\n\n\n\n\n\n\n\n\nTODO: I should think about looking at different distribution families and comparing AIC.",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Fuel modeling</span>"
    ]
  },
  {
    "objectID": "analysis/fuel_data_modeling.html#bayesian-mode",
    "href": "analysis/fuel_data_modeling.html#bayesian-mode",
    "title": "4  Fuel modeling",
    "section": "5.3 Bayesian mode",
    "text": "5.3 Bayesian mode\nIt has been difficult fitting these models zeros, non-constant variance, and non-normal response. A more flexible approach may be to implement my models in a Bayesian context. This has the added benefits of ease of interpretability of the results and quantified estimates of uncertainty.\nI’ll use brms with the same formula I used for the lmm above. First we’ll reload our data.\nAll the data is nested to facilitate modeling each fuel class separately. We’ll look at the average loading to get an idea of the data.\n\n\nCode\nd &lt;- load2(\"long\", \"pre\", all_of(c(transectid, load_vars))) |&gt;\n  group_by(class) |&gt; nest() |&gt; rowwise()\n\n\n\n5.3.1 Gaussian model\nI started out using a Gaussian model for load, with mostly default priors on the random effects. This was for convenience more than for anything. A model with positive support only, and more approriate priors would improve the model. This parameterization also results in the first treatment level (gs) being interpreted as the global intercept. This implies the unfortunate assumption that the other levels entail more variability as their priors result from the combination of the intercept prior as well as the treatment prior, wheres the prior for the first level only contains the variability in the intercept. Thus, parameterizing the model by removing the intercept for the main effect would allow equivalent interpretations of all four treatment levels. I use this approach below in the Gamma model.\n\n5.3.1.1 Priors\nWe are using mostly uninformative priors for our un-pooled (fixed effect) estimates of treatment intercepts. They are all set as normal distributions, centered at the median of the fuel load with a sd of 2.5 times the sd of the data. While it is not possible to have negative values here, a current limitation of the brms package is that you can’t put bounds on individual coefficients, and we would not want to contstrain our treatment effects to be positive, as they are centered around the mean and will be both positive and negative.\n\n\nCode\n# add calcualted priors to the data\n\nd &lt;- mutate(d, \n  priors = list(\n    brms::set_prior(\n      str_glue(\n        \"normal( {round(median(data$load))}, {round(2.5 * sd(data$load))} )\"\n      ), \n      # lb = 0, \n      class = \"b\", coef = \"Intercept\"\n    ) +\n    brms::set_prior(\n      str_glue(\n        \"normal( 0, {round(1.5 * sd(data$load))} )\"\n      ), \n      class = \"b\"\n    )\n    # brms::set_prior(\"student_t(3, 0, 2.5)\",  lb = 0, class = \"sd\")\n  )\n)\n\n# Plot the priors\nd |&gt;\n  mutate(\n    prior_dist = list(tidybayes::parse_dist(priors) |&gt; \n    rename(dist_class = class))\n  ) |&gt;\n  unnest(prior_dist) |&gt;\n  ggplot(aes(ydist = .dist_obj, color = interaction(coef, dist_class))) +\n    stat_slab(normalize = \"panels\", fill = NA) +\n    stat_pointinterval(position = position_dodge(width = 0.3, preserve = \"single\")) +\n    geom_text(\n      aes(label = format(.dist_obj), y = mean(.dist_obj), x = 0.97, vjust = 0),\n      position = position_dodge(width = 0.3), show.legend = FALSE\n    ) +\n    coord_flip() +\n    facet_wrap(~ class, scales = \"free_x\") +\n    scale_color_hue(name = \"prior\", labels = c(\"treatment\", \"intercept\", \"sd\"))\n\n\n\n\n\n\n\n\nFigure 5.6: Normal priors for the intercept are centered at the median and sd of 2.5 times the sd of the data. For the fixed effect treatment, they are centered at zero with the a standard deviation equal to 1.5 sd of the data. Fixed treatments are relative to the first treatment level (GS) which is used as the intercept.\n\n\n\n\n\n\n\n5.3.1.2 Model fitting\nNow we’ll fit the model.\n\n\nCode\nform &lt;- load ~  0 + Intercept + treatment + (1 | site/treatment/corner)\n\nbf2 &lt;- mutate(d,\n  mod = list(brms::brm(form, data,\n    warmup = 3000,\n    iter = 4000,\n    cores = 4,\n    control = list(adapt_delta = 0.99),\n    prior = priors,\n    sample_prior = TRUE,\n    file = paste0(\"fits/bf2_\", class)\n  ))\n)\n\n\n\n\n5.3.1.3 Prior check\n\n\nCode\n# Plod density of model priors against posterior to get a sense of the\n# informativeness of the prior. Average over all fixed effects.\n\nplot_pri_post &lt;- function(mod) {\n  tidy_draws(mod) |&gt;\n  select(c(matches(\"b_\"), matches(\"sd\"), matches(\"sigma\"), matches(\"hu\"))) |&gt;\n  pivot_longer(everything()) |&gt;\n  mutate(\n    name = if_else(\n      str_starts(name, \"prior\"),\n      name,\n      paste0(\"posterior_\", name)\n    )\n  ) |&gt;\n  separate_wider_regex(name,\n      c(phase = \"prior|posterior\", \"_\", name = \".*\")\n  ) |&gt;\n  mutate(name = str_remove(name, \"__.*\")) |&gt;\n  ggplot(aes(x = value, color = phase, fill = phase)) +\n  stat_slab(normalize = \"panels\", alpha = 3/4) +\n  stat_pointinterval(\n    position = position_dodge(width = 0.3, preserve = \"single\")\n  ) +\n  facet_wrap(~ name, scales = \"free\", labeller = fuel_class_labeller) +\n  labs(x = \"Parameter value\", y = \"Density\") +\n  scale_fill_manual(values = c(\"gray60\", \"gray30\")) +\n  scale_color_manual(values = c(\"gray60\", \"gray30\"))\n}\n\n\n\n\n\n\n\nSampled prior and posterior distributions for Gaussian model variables that have priors, for one fuel class. These include the sd for the random effects as well as sigma: the model residuals, and the fixed effect of treatment. The plots for the other fuel classes look similar.\n\n\n\n\n\n\n5.3.1.4 Posterior Predictive check (Gaussian)\n\n\nCode\nposterior_predictive_check &lt;- function(models) {\n  models &lt;- mutate(models,\n    pred = list(tidybayes::add_predicted_draws(data, mod, ndraws = 15)),\n    lims = list(tibble(\n      xmin = min(\n        quantile(data$load, .001),\n        quantile(pred$.prediction, .001)\n      ),\n      xmax = max(\n        quantile(data$load, .999),\n        quantile(pred$.prediction, .999)\n      ))\n    )\n  )\n  ggplot() + \n  geom_line(\n    data = unnest(models, data),\n    aes(x = load),\n    stat = \"density\", size = 1\n  ) +\n  geom_line(\n    data = unnest(models, pred),\n    aes(x = .prediction, group = .draw),\n    stat = \"density\", alpha = 0.15, size = 1\n  ) +\n  facet_wrap(~class, scales = \"free\", labeller = fuel_class_labeller) +\n  coord_cartesian_panels(\n    panel_limits = unnest(select(models, lims), lims)\n  )\n}\n\n\nHere is a posterior predictive check.\n\n\nCode\nposterior_predictive_check(bf2)\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nAdding missing grouping variables: `class`\n\n\n\n\n\n\n\n\nFigure 5.7: Density of the observed data (y) plotted against 10 random draws from the posterior predictive distribution.\n\n\n\n\n\nThe Gaussian distribution is symmetric and doesn’t capture well the peak near zero and the long right tail of our observed values for most of the fuel classes. It also dramatically overpredicts negative values (which are absent from our data, despite the fact that the density smoothing of the observed values seems to suggest there are some.)\nThe fact that the model predicts negative values suggests that it is not right for our data, and could potentially be biasing comparissons between treatments. A Gamma distribution for the response makes more sense.\n\n\n\n5.3.2 Gamma model\nThe gamma model has support for only postive values, which makes sense for our weight per area data. Initial data exploration also revealed that the gamma appears to be a good fit for our data. This makes sense, as our data is fundamentally transformed count data, and the gamma distribution is the continuous generalization of the negative binomial, which is used for modeling count data.\n\n5.3.2.1 Formula\nI’m assuming the outcome is hurdle gamma distributed.\n\\[\n\\operatorname{HurdleGamma}(y \\mid \\mu, \\text{shape}, \\text{hu}) =\n\\begin{cases}\n\\text{hu}\n  &\\quad\\text{if } y = 0, \\text{ and}\\\\\n(1 - \\text{hu}) \\operatorname{Gamma}(y \\mid \\alpha, \\beta)\n  &\\quad\\text{if } y &gt; 0,\n\\end{cases}\n\\]\nWhere \\(\\mu = \\frac{\\alpha}{\\beta}\\), and \\(\\text{shape} = \\beta\\). This is a mixture model where the proportion of zeros are estimated and the rest of the observations are assumed to be gamma distributed. Because the gamma distribution doesn’t incldue support for zero, we don’t have to worry about any “overlapping” zero predictions from the gamma portion of the model.\nOur model form is as follows:\n\\[  \n\\begin{align*}\ny_i &\\sim \\operatorname{HurdleGamma}(\\mu, \\text{shape}, \\text{hu})\\\\\n\\log(\\mu_i) &= \\bar{\\alpha} +\n  U_{\\text{site}[i]}\\sigma_{u} +\n  V_{\\text{plot}[i]}\\sigma_{v} +\n  W_{\\text{corner}[i]}\\sigma_{w} +\n  \\beta_{treatment[i]}\\\\\n\\bar{\\alpha} &\\sim \\operatorname{normal}(M, S)\\\\\nU_j &\\sim \\operatorname{normal}(0, 1) \\qquad \\text{for } j=1 \\dots 4\\\\\nV_j &\\sim \\operatorname{normal}(0, 1) \\qquad \\text{for } j=1 \\dots 16\\\\\nW_j &\\sim \\operatorname{normal}(0, 1) \\qquad \\text{for } j=1 \\dots 64\\\\\n\\sigma_u &\\sim \\operatorname{normal^+}(0, 1)\\\\\n\\sigma_v &\\sim \\operatorname{normal^+}(0, 1)\\\\\n\\sigma_w &\\sim \\operatorname{normal^+}(0, 1)\\\\\n\\beta_j &\\sim \\operatorname{normal}(0, 1) \\qquad \\text{for } j=1 \\dots 4\\\\\n\\text{shape} &\\sim \\operatorname{Gamma}(0.01, 0.01)\\\\\n\\text{hu} &\\sim \\operatorname{beta}(1, 1)\n\\end{align*}\n\\tag{5.1}\\]\nHere is an interpretation for each line of the above model.\n\nObservations of transects are assumed to be hurdle gamma distributed given the fixed and random intercept, grouping structure.\nThe log fuel loading for a transect is a function of the grand mean plus random effects for site, plot, and corner, and fixed effect of treatment. Each \\(U\\), \\(V\\), and \\(W\\), is accompanied by a \\(\\sigma\\) parameter. This is the non-centered parameterization and is equivalent to just defining a distribution with a scale of \\(\\sigma\\), but factoring out the scale parameter leads to better numerical stability in the Markov-chain Monte Carlos algorithm.\nThe prior for bar-a, the grand mean, is assumed to be normally distributed with mean and SD of \\(M\\) and \\(S\\), repsectively. These are chosen based on the mean and 2.5 times the SD of the data converted to produce a log normal distribution on the log scale. This should be a weakly informative prior.\nEach of the four unique site effects come from a normal distribution centered on zero.\nSame as above for 16 plot\nSame as above for 64 corners.\nThe site effects come from a normal distribution with a SD that is assumed to be from a postive constrained, standard normal distribution. On the response scale, about 95% of the mass of the joint distribution of this line and line 4 (\\(U_j\\sigma_u\\)) is in the interval \\([0.11,8.9]\\), which implies that we would be supprised to see any site with a load more than 9 times any other.\nSame as 7 for plots.\nSame as 7 for corners.\nThe fixed effect of treatment on the log scale is assumed to be from a standard normal distribution. On the response scale, we would be supprised if the effect of any treatment was more than seven times any other.\nThis is the default prior for the shape parameter of the gamma distribution in brms. It is chosen to be minimally informative.\nOur prior assumption about the proportion of zeros is also minimally informative, it is mostly uniform between 0 and 1.\n\nOne problem with these independent prior assumptions is that the multiplicative effect of the terms on the response scale (due to exponentiation) can lead to impossibly large predictiontions, particularly when multiple random or fixed effect parameters are sampled simultaneosly in their upper tails. For instance, if the effects of site, plot, and corner where sampled at 2 (on the log scale) and the effect of treatment, at 1.8, this could lead to a predicted \\(\\mu\\) more than 2,400 times greater than the grand mean.\nA better choice would be to use a joint prior, like the Dirichlet, so a prior could be set on the total variance and the individual component variances would vary (in either a eqaul, or unequally weighted fashioin) in their repsective proportions of that total.\nIn this regard, with either independent, or independet priors, further work could be done on establshing the relative importance of each variance component and setting priors that reflect these differences. For our nesting structure, this means defining the length scale over which fuels are expected to vary most/least, from 10 m to 50 m to &gt; 100 m, to thousands of meters.\n\n\n5.3.2.2 Compute priors\nFirst I’ll set my prior. This is complicated because we are now working with a log link. According to Solomon Kurz, this is how to transform your mean and sd for a normal distribution on the identity scale, to the equivalent normal distribution on the log scale (a lognormal distribution). This is what we’ll use for our prior on the grand mean (\\(\\bar{\\alpha}\\)).\n\n\nCode\nd &lt;- load2(\"long\", \"pre\", all_of(c(transectid, load_vars))) |&gt;\n  group_by(class) |&gt; nest() |&gt; rowwise()\n\nlnp &lt;- function(data) {\n  # Desired values\n  m &lt;- mean(data)\n  s &lt;- 2.5 * sd(data)\n  # use the equations\n  mu    &lt;- log(m / sqrt(s^2 / m^2 + 1))\n  sigma &lt;- sqrt(log(s^2 / m^2 + 1))\n  # output mu and sigma on lognormals own scale\n  list(mu = round(mu, 2), sigma = round(sigma, 2))\n}\n\n\n\n\nCode\n# data frame to plot the priors\npd &lt;- d |&gt;\n  mutate(\n    priors = list(brms::set_prior(\n      str_glue(\"normal({mu}, {sigma})\", .envir = lnp(data$load))\n    )),\n    prior_dist = list(tidybayes::parse_dist(priors)),\n    lims = list(\n      tibble(\n        xmin = quantile(exp(prior_dist$.dist_obj), .01),\n        xmax = quantile(exp(prior_dist$.dist_obj), .99)\n      )\n    )\n  ) |&gt;\n  rename(fuel_class = class)\n\nggplot(data = unnest(pd, prior_dist)) +\n  tidybayes::stat_halfeye(\n    aes(xdist = exp(.dist_obj)),\n    normalize = \"panels\"\n  ) +\n  geom_text(\n    aes(\n      label = format(.dist_obj),\n      x = mean(exp(.dist_obj)),\n      y = 0.97,\n      hjust = 0\n    )\n  ) +\n  facet_wrap(~ fuel_class, scales = \"free_x\", labeller = fuel_class_labeller) +\n  coord_cartesian_panels(panel_limits = unnest(select(pd, lims), lims)) +\n  labs(x = expression(exp(bar(alpha))))\n\n\n\n\n\n\n\n\nFigure 5.8: Normal priors for the grand mean (global intercept) centered at the median and sd of 2.5 times the sd of the data.\n\n\n\n\n\n\n\n5.3.2.3 Prior predictive check\nThe below code ran with very many divergent transitions and the results did not really make sense. This may have to do with a comment I found here: independent priors specified on the log link usually don’t sample.\nAn alternative is refitting the whole model with different priors and comparing the output to infer the prior influence. I’m not going to do that right now.\nI will though, sample from the priors while fitting the model in order to plot those along with the posterior for our variables of interest.\n\n\nCode\n# prior_only_bf4a &lt;- mutate(bf4a, \n#   mod = list(update(mod, \n#     sample_prior = \"only\", \n#     cores = 4,\n#     warmup = 4000,\n#     iter = 5000,\n#     control = list(adapt_delta = .99)\n#   ))\n# )\n\n\n\n\n5.3.2.4 Model fitting\nHere I actually fit several models. They were each explored to some degree in an iterative process of model fitting and checking. For the sake of brevity, I I have focussed on just one of them (bf4a) for displaying final results. This model is the one described mathematically above.\n\n\nCode\nbf4a &lt;- mutate(d,\n  priors = list(\n    set_prior(\n      str_glue(\"normal({mu}, {sigma})\", .envir = lnp(data$load)),\n      nlpar = \"a\", coef = \"Intercept\"\n    ) +\n    set_prior(\"normal(0, 1)\", nlpar = \"a\", class = \"sd\") +\n    set_prior(\"normal(0, 1)\", nlpar = \"b\", coef = \"treatmentgs\") +\n    set_prior(\"normal(0, 1)\", nlpar = \"b\", coef = \"treatmentha\") +\n    set_prior(\"normal(0, 1)\", nlpar = \"b\", coef = \"treatmenthd\") +\n    set_prior(\"normal(0, 1)\", nlpar = \"b\", coef = \"treatmentld\")\n  ),\n  mod = list(brms::brm(\n    brms::bf(\n      load ~ a + b,\n      a ~ 1 + (1 | site/treatment/corner),\n      b ~ 0 + treatment,\n      nl = TRUE),\n    data,\n    warmup = 4000,\n    iter = 5000,\n    cores = 4,\n    control = list(adapt_delta = 0.99),\n    family = brms::hurdle_gamma(),\n    prior = priors,\n    sample_prior = TRUE,\n    # backend = \"cmdstanr\",\n    file = paste0(\"fits/bf4a_\", class)\n  ))\n)\n\n\n\n\nCode\nbf3 &lt;- mutate(d,\n  priors = list(brms::set_prior(\n    str_glue(\"normal({mu}, {sigma})\", .envir = lnp(data$load))\n  )),\n  mod = list(brms::brm(form, data,\n    warmup = 5000,\n    iter = 6000,\n    cores = 4,\n    control = list(adapt_delta = 0.99),\n    family = brms::hurdle_gamma(),\n    prior = priors,\n    file = paste0(\"fits/bf3_\", class)\n  ))\n)\n\nbf4 &lt;- mutate(d,\n  priors = list(\n    set_prior(\n      str_glue(\"normal({mu}, {sigma})\", .envir = lnp(data$load)),\n      nlpar = \"a\", coef = \"Intercept\"\n    ) +\n      set_prior(\"student_t(3, 0, 0.35)\", nlpar = \"a\", class = \"sd\") +\n      set_prior(\"student_t(3, 0, 0.35)\", nlpar = \"b\", coef = \"treatmentgs\") +\n      set_prior(\"student_t(3, 0, 0.35)\", nlpar = \"b\", coef = \"treatmentha\") +\n      set_prior(\"student_t(3, 0, 0.35)\", nlpar = \"b\", coef = \"treatmenthd\") +\n      set_prior(\"student_t(3, 0, 0.35)\", nlpar = \"b\", coef = \"treatmentld\")\n  ),\n  mod = list(brms::brm(\n    brms::bf(\n      load ~ a + b,\n      a ~ 1 + (1 | site / treatment / corner),\n      b ~ 0 + treatment,\n      nl = TRUE\n    ),\n    data,\n    warmup = 4000,\n    iter = 5000,\n    cores = 4,\n    control = list(adapt_delta = 0.99),\n    family = brms::hurdle_gamma(),\n    prior = priors,\n    sample_prior = TRUE,\n    file = paste0(\"fits/bf4_\", class)\n  ))\n)\n\n\nbf5 &lt;- mutate(d,\n  priors = list(brms::set_prior(\n    str_glue(\"normal({mu}, {sigma})\", .envir = lnp(data$load))\n  )),\n  mod = list(brms::brm(\n    brms::bf(load ~ 0 + Intercept + (1 | site / treatment / corner) + (1 | treatment)),\n    data,\n    warmup = 4000,\n    iter = 5000,\n    cores = 4,\n    control = list(adapt_delta = 0.99),\n    family = brms::hurdle_gamma(),\n    prior = priors,\n    file = paste0(\"fits/bf5_\", class)\n  ))\n)\n\n\n\n\n5.3.2.5 Model summaries\n\n\nCode\nmy_summary &lt;- function(mod) {\n  as_draws_df(mod) |&gt;\n    select(starts_with(c(\"b_\", \"sd_\")), shape, hu) |&gt;\n    posterior::summarize_draws(\n      \"mean\", ~posterior::quantile2(.x, c(0.05, .5, .95)), \"rhat\", \"ess_bulk\",\n      \"ess_tail\"\n    )\n}\n\nbf4a |&gt;\n  mutate(\n    summary = list(my_summary(mod))\n  ) |&gt;\n  select(summary) |&gt;\n  unnest(summary) |&gt;\n  mutate(\n    variable = str_remove_all(variable, \"b_._|_a_\")\n  ) |&gt;\n  knitr::kable(digits = c(NA, NA, 2, 2, 2, 2, 2, 0, 0))\n\n\n\n\nTable 5.6: Summaries of parameters and dianostics. Rhat is a measure of model convergence, well mixed chains have an Rhat of 1, bulk and tail ESS are measures of effective sample size.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass\nvariable\nmean\nq5\nq50\nq95\nrhat\ness_bulk\ness_tail\n\n\n\n\nonehr\nIntercept\n-0.32\n-1.17\n-0.32\n0.53\n1.00\n1261\n1666\n\n\nonehr\ntreatmentgs\n-0.31\n-1.15\n-0.30\n0.52\n1.00\n1278\n1690\n\n\nonehr\ntreatmentha\n0.44\n-0.39\n0.44\n1.24\n1.00\n1311\n1640\n\n\nonehr\ntreatmenthd\n0.27\n-0.56\n0.27\n1.08\n1.00\n1363\n1569\n\n\nonehr\ntreatmentld\n-0.13\n-0.99\n-0.13\n0.72\n1.00\n1256\n1500\n\n\nonehr\nsd_site_Intercept\n0.38\n0.05\n0.32\n0.92\n1.00\n1131\n1232\n\n\nonehr\nsd_site:treatment_Intercept\n0.35\n0.14\n0.34\n0.60\n1.00\n1221\n1245\n\n\nonehr\nsd_site:treatment:corner_Intercept\n0.12\n0.01\n0.11\n0.28\n1.00\n1200\n1374\n\n\nonehr\nshape\n2.35\n1.90\n2.34\n2.86\n1.00\n3019\n2789\n\n\nonehr\nhu\n0.01\n0.00\n0.01\n0.02\n1.00\n3317\n1647\n\n\ntenhr\nIntercept\n1.06\n0.26\n1.07\n1.86\n1.00\n1384\n1902\n\n\ntenhr\ntreatmentgs\n0.28\n-0.53\n0.28\n1.07\n1.00\n1363\n1914\n\n\ntenhr\ntreatmentha\n0.07\n-0.78\n0.07\n0.88\n1.00\n1477\n2044\n\n\ntenhr\ntreatmenthd\n0.00\n-0.82\n-0.01\n0.81\n1.00\n1418\n2169\n\n\ntenhr\ntreatmentld\n0.10\n-0.72\n0.11\n0.88\n1.00\n1425\n1911\n\n\ntenhr\nsd_site_Intercept\n0.25\n0.02\n0.18\n0.71\n1.00\n1396\n1959\n\n\ntenhr\nsd_site:treatment_Intercept\n0.38\n0.17\n0.37\n0.63\n1.00\n912\n669\n\n\ntenhr\nsd_site:treatment:corner_Intercept\n0.11\n0.01\n0.10\n0.27\n1.00\n1302\n1596\n\n\ntenhr\nshape\n2.56\n2.01\n2.54\n3.18\n1.00\n3337\n3046\n\n\ntenhr\nhu\n0.06\n0.03\n0.06\n0.10\n1.00\n5628\n2452\n\n\nhundhr\nIntercept\n2.25\n1.40\n2.26\n3.06\n1.00\n2087\n2520\n\n\nhundhr\ntreatmentgs\n0.26\n-0.56\n0.26\n1.10\n1.00\n2094\n2651\n\n\nhundhr\ntreatmentha\n0.03\n-0.78\n0.03\n0.88\n1.00\n2195\n2537\n\n\nhundhr\ntreatmenthd\n0.02\n-0.79\n0.02\n0.84\n1.00\n2116\n2424\n\n\nhundhr\ntreatmentld\n0.15\n-0.66\n0.15\n1.01\n1.00\n2129\n2714\n\n\nhundhr\nsd_site_Intercept\n0.30\n0.03\n0.24\n0.80\n1.00\n1772\n2044\n\n\nhundhr\nsd_site:treatment_Intercept\n0.25\n0.05\n0.24\n0.47\n1.00\n1015\n1407\n\n\nhundhr\nsd_site:treatment:corner_Intercept\n0.15\n0.01\n0.13\n0.32\n1.00\n1408\n2164\n\n\nhundhr\nshape\n2.80\n2.18\n2.77\n3.52\n1.00\n3476\n2851\n\n\nhundhr\nhu\n0.12\n0.08\n0.12\n0.17\n1.00\n9182\n2704\n\n\ndufflitter\nIntercept\n3.74\n2.94\n3.74\n4.53\n1.00\n1027\n1411\n\n\ndufflitter\ntreatmentgs\n0.10\n-0.66\n0.11\n0.87\n1.00\n1025\n1469\n\n\ndufflitter\ntreatmentha\n-0.07\n-0.84\n-0.06\n0.68\n1.00\n1032\n1524\n\n\ndufflitter\ntreatmenthd\n0.23\n-0.54\n0.24\n0.99\n1.00\n1058\n1572\n\n\ndufflitter\ntreatmentld\n0.05\n-0.73\n0.05\n0.82\n1.00\n1031\n1734\n\n\ndufflitter\nsd_site_Intercept\n0.29\n0.06\n0.23\n0.74\n1.00\n1237\n1178\n\n\ndufflitter\nsd_site:treatment_Intercept\n0.10\n0.01\n0.08\n0.24\n1.00\n1539\n1640\n\n\ndufflitter\nsd_site:treatment:corner_Intercept\n0.10\n0.01\n0.09\n0.23\n1.00\n993\n1652\n\n\ndufflitter\nshape\n3.93\n3.15\n3.90\n4.85\n1.00\n2983\n2787\n\n\ndufflitter\nhu\n0.01\n0.00\n0.01\n0.02\n1.00\n3668\n1545\n\n\nthoushr\nIntercept\n3.61\n2.68\n3.62\n4.53\n1.00\n1965\n2456\n\n\nthoushr\ntreatmentgs\n0.34\n-0.61\n0.32\n1.29\n1.00\n2208\n2307\n\n\nthoushr\ntreatmentha\n-0.06\n-0.99\n-0.06\n0.88\n1.00\n2087\n2538\n\n\nthoushr\ntreatmenthd\n0.25\n-0.69\n0.26\n1.20\n1.00\n2007\n2766\n\n\nthoushr\ntreatmentld\n-0.11\n-1.07\n-0.11\n0.84\n1.00\n2165\n2549\n\n\nthoushr\nsd_site_Intercept\n0.41\n0.04\n0.34\n1.01\n1.00\n1592\n2281\n\n\nthoushr\nsd_site:treatment_Intercept\n0.57\n0.23\n0.56\n0.94\n1.00\n1123\n1167\n\n\nthoushr\nsd_site:treatment:corner_Intercept\n0.38\n0.07\n0.39\n0.67\n1.00\n824\n1021\n\n\nthoushr\nshape\n1.41\n1.06\n1.39\n1.83\n1.00\n1785\n2704\n\n\nthoushr\nhu\n0.25\n0.20\n0.25\n0.32\n1.00\n6466\n3172\n\n\nveg\nIntercept\n2.75\n1.84\n2.75\n3.66\n1.00\n1119\n2021\n\n\nveg\ntreatmentgs\n0.53\n-0.32\n0.52\n1.39\n1.01\n1293\n2170\n\n\nveg\ntreatmentha\n-0.39\n-1.28\n-0.37\n0.48\n1.00\n1274\n1827\n\n\nveg\ntreatmenthd\n0.00\n-0.90\n0.01\n0.88\n1.00\n1071\n2035\n\n\nveg\ntreatmentld\n0.21\n-0.70\n0.21\n1.09\n1.00\n1147\n1846\n\n\nveg\nsd_site_Intercept\n0.46\n0.07\n0.39\n1.07\n1.00\n1377\n1222\n\n\nveg\nsd_site:treatment_Intercept\n0.38\n0.06\n0.37\n0.73\n1.00\n716\n801\n\n\nveg\nsd_site:treatment:corner_Intercept\n0.51\n0.23\n0.52\n0.74\n1.00\n598\n552\n\n\nveg\nshape\n1.97\n1.47\n1.95\n2.56\n1.00\n1094\n1691\n\n\nveg\nhu\n0.02\n0.00\n0.01\n0.04\n1.00\n4763\n2070\n\n\n\n\n\n\n\n\n\n\n5.3.2.6 Prior check\nWhile it was not possible to sample from the prior using the MCMC sampler which was likely due to the extremely long tails implied by our exponentiated, independent priors, another way of describing priors is simply sampling random from random number generators. The results of these random samples are plotted against the posterior distributions for the variables that we set priors for.\n\n\nCode\nplot_pri_post(bf4a$mod[[1]]) + ggtitle(\"1-hr\")\nplot_pri_post(bf4a$mod[[2]]) + ggtitle(\"10-hr\")\nplot_pri_post(bf4a$mod[[3]]) + ggtitle(\"100-hr\")\nplot_pri_post(bf4a$mod[[4]]) + ggtitle(\"duff & litter\")\nplot_pri_post(bf4a$mod[[5]]) + ggtitle(\"1000-hr\")\nplot_pri_post(bf4a$mod[[6]]) + ggtitle(\"Vegetation\")\n\n\n\n\n\n\n\n\nFigure 5.9: Posterior and prior distributions for variables we set priors for, for one fuel class model.\n\n\n\n\n\n\n\n\n\n\n\nFigure 5.10: Posterior and prior distributions for variables we set priors for, for one fuel class model.\n\n\n\n\n\n\n\n\n\n\n\nFigure 5.11: Posterior and prior distributions for variables we set priors for, for one fuel class model.\n\n\n\n\n\n\n\n\n\n\n\nFigure 5.12: Posterior and prior distributions for variables we set priors for, for one fuel class model.\n\n\n\n\n\n\n\n\n\n\n\nFigure 5.13: Posterior and prior distributions for variables we set priors for, for one fuel class model.\n\n\n\n\n\n\n\n\n\n\n\nFigure 5.14: Posterior and prior distributions for variables we set priors for, for one fuel class model.\n\n\n\n\n\n\n\n5.3.2.7 Posterior predictive check\n\n\nAdding missing grouping variables: `class`\n\n\n\n\n\n\n\n\nFigure 5.15: Density of the observed data (y) plotted against 10 random draws from the posterior predictive distribution.\n\n\n\n\n\nThe gamma model fits the data better. There are no predictions below zero anymore. It does seem like the gamma distribution tends to predict higher densities of lower values than we observed, as seen in the plots for the tenhr, thoushr, and veg fuel classes. But generally, the predictions appear to agree with the observed data pretty well.\n\n\n5.3.2.8 Expected value of the posterior predictive\n\n\nCode\n# get posterior predictions for treatments for models for all fuel classes, \n# ignoring random effects. These are predictions for the expected value across\n# all sites.\npredict_posterior_expected &lt;- function(data, plot = TRUE, re_formula = NA) {\n  newdata &lt;- tidyr::expand(data$data[[1]], nesting(treatment))\n  data &lt;- mutate(data, .keep = \"none\",\n    pred = list(\n      tidybayes::epred_draws(mod, newdata, re_formula = re_formula,\n        value = \"pred\")\n    ),\n    lims = list(\n      tibble(xmin = 0, xmax = quantile(pred$pred, .995))\n    )\n  )\n  data\n}\n\nplot_posterior_predicted &lt;- function(data) {\n  p &lt;- data |&gt;\n    unnest(pred) |&gt;\n    ggplot(aes(pred, treatment)) +\n    tidybayes::stat_halfeye(normalize = \"panels\") +\n    facet_wrap(~class, scales = \"free_x\", labeller = fuel_class_labeller) +\n    coord_cartesian_panels(panel_limits = unnest(select(data, lims), lims)) +\n    scale_y_discrete(labels = toupper) +\n    labs(x = expression(Load~(Mg%.%ha^-1)), y = \"Treatment\")\n  p\n}\n\n\n\n\nAdding missing grouping variables: `class`\n\n\n\n\n\n\n\n\nFigure 5.16: Posterior expected predictions, with no random effects. This reprsents the expected average conditions across all sites. The point estimate is the mode. Units are mg ha-1. Upper and lower limits are the 95% credible intervals.\n\n\n\n\n\nThese are the expected predictions, or predictions for the mean. It only includes the uncertainty in the mean and not the variance in predictions estimated by the model.\nThere is quite a bit of uncertainty about the mean all around, but there is a notable difference in that uncertainty among treatments for the onehr and veg fuel classes.\nTable Table 5.7 shows these data in a tabular format. I’m using the highest density continuous interval because, while its hard to see in Figure 5.16, the highest desity region is actually slightly discontinuous.\n\n\nCode\nexpected_predictions |&gt;\n  mutate(\n    summary = list(tidybayes::mode_hdci(pred))\n  ) |&gt; select(summary) |&gt; unnest(summary) |&gt;\n  select(treatment, prediction = pred, lower = .lower, upper = .upper) |&gt;\n  knitr::kable(digits = 1)\n\n\nAdding missing grouping variables: `class`\nAdding missing grouping variables: `class`\n\n\n\n\nTable 5.7: Tabular data associated with Figure 5.16. Upper and lower pertain to the 95% highest density continuous interval.\n\n\n\n\n\n\nclass\ntreatment\nprediction\nlower\nupper\n\n\n\n\nonehr\ngs\n0.5\n0.2\n0.9\n\n\nonehr\nld\n0.6\n0.3\n1.1\n\n\nonehr\nha\n1.1\n0.5\n1.9\n\n\nonehr\nhd\n0.9\n0.4\n1.6\n\n\ntenhr\ngs\n3.5\n1.8\n5.8\n\n\ntenhr\nld\n2.8\n1.5\n4.9\n\n\ntenhr\nha\n2.7\n1.4\n4.7\n\n\ntenhr\nhd\n2.6\n1.3\n4.4\n\n\nhundhr\ngs\n10.5\n5.5\n16.7\n\n\nhundhr\nld\n9.4\n5.2\n15.6\n\n\nhundhr\nha\n8.6\n4.7\n13.9\n\n\nhundhr\nhd\n8.3\n4.2\n13.2\n\n\ndufflitter\ngs\n45.4\n26.8\n65.9\n\n\ndufflitter\nld\n43.3\n26.0\n64.4\n\n\ndufflitter\nha\n38.1\n23.9\n57.8\n\n\ndufflitter\nhd\n51.4\n30.4\n77.2\n\n\nthoushr\ngs\n34.3\n13.1\n81.9\n\n\nthoushr\nld\n22.2\n6.9\n51.4\n\n\nthoushr\nha\n22.4\n8.6\n54.3\n\n\nthoushr\nhd\n32.8\n10.4\n75.0\n\n\nveg\ngs\n25.1\n9.4\n49.9\n\n\nveg\nld\n17.9\n7.1\n35.8\n\n\nveg\nha\n9.3\n4.0\n20.1\n\n\nveg\nhd\n14.7\n5.4\n29.4\n\n\n\n\n\n\n\n\n\n\nCode\npredict_expected_contrasts &lt;- function(data, rope_size, plot = TRUE,\n                                       re_formula = NA) {\n  # Assume treatment levels are the same for all models: they are.\n  newdata &lt;- tidyr::expand(data$data[[1]], tidyr::nesting(treatment))\n  d &lt;- data |&gt;\n    mutate(\n      pred = list(\n        tidybayes::epred_draws(mod, newdata, re_formula = NA, value = \"pred\") |&gt;\n          tidybayes::compare_levels(pred, by = treatment) |&gt;\n          select(contrast = treatment, pred)\n      ),\n      rope = rope_size * sd(data$load),\n      lims = list(\n        tibble(xmin = quantile(pred$pred, .001), xmax = quantile(pred$pred, .999))\n      ),\n    .keep = \"none\"\n  )\n}\n\nplot_expected_contrasts &lt;- function(data){\n    p &lt;- data |&gt;\n      unnest(c(pred)) |&gt;\n      ggplot(aes(x = pred, y = contrast)) +\n      tidybayes::stat_halfeye(normalize = \"panels\") +\n      geom_vline(aes(xintercept = rope)) +\n      geom_vline(aes(xintercept = -rope)) +\n      facet_wrap(~class, scales = \"free_x\", labeller = fuel_class_labeller) +\n      coord_cartesian_panels(\n        panel_limits = unnest(dplyr::select(data, lims), lims)\n      ) +\n      scale_y_discrete(labels = toupper) +\n      labs(x = expression(Load ~ (Mg %.% ha^-1)), y = \"Treatment\")\n    p\n}\n\n\n\n\nAdding missing grouping variables: `class`\n\n\n\n\n\n\n\n\nFigure 5.17: Differences between expected values for each treatment, with 95% continuous interval shown.\n\n\n\n\n\n\n\nAdding missing grouping variables: `class`\nAdding missing grouping variables: `class`\n\n\n\n\nTable 5.8: Posterior expected predictions of pairwise differences in means, with no random effects. This reprsents the expected average conditions across all sites. Units are Mg ha-1. The point estimate is the mode. Upper and lower limits are the 95% credible intervals. Prob is the probability that the predicted difference matches the sign of its median–the probability that it is not zero.\n\n\n\n\n\n\nclass\ncontrast\nprediction\nlower\nupper\nprob\n\n\n\n\nonehr\nha - gs\n0.53\n0.05\n1.27\n0.99\n\n\nonehr\nha - ld\n0.47\n-0.07\n1.22\n0.96\n\n\nonehr\nhd - gs\n0.40\n-0.06\n1.02\n0.97\n\n\nonehr\nhd - ha\n-0.18\n-0.91\n0.53\n0.72\n\n\nonehr\nhd - ld\n0.24\n-0.20\n0.90\n0.91\n\n\nonehr\nld - gs\n0.07\n-0.27\n0.55\n0.74\n\n\ntenhr\nha - gs\n-0.58\n-2.90\n1.75\n0.75\n\n\ntenhr\nha - ld\n-0.01\n-2.15\n1.97\n0.54\n\n\ntenhr\nhd - gs\n-0.81\n-2.97\n1.32\n0.82\n\n\ntenhr\nhd - ha\n-0.28\n-2.25\n1.73\n0.59\n\n\ntenhr\nhd - ld\n-0.25\n-2.31\n1.69\n0.63\n\n\ntenhr\nld - gs\n-0.42\n-2.94\n1.68\n0.73\n\n\nhundhr\nha - gs\n-2.01\n-8.03\n2.94\n0.81\n\n\nhundhr\nha - ld\n-1.13\n-6.18\n4.34\n0.69\n\n\nhundhr\nhd - gs\n-1.81\n-7.59\n2.95\n0.83\n\n\nhundhr\nhd - ha\n-0.03\n-4.79\n4.68\n0.52\n\n\nhundhr\nhd - ld\n-1.15\n-6.14\n3.86\n0.71\n\n\nhundhr\nld - gs\n-0.92\n-6.91\n4.51\n0.66\n\n\ndufflitter\nha - gs\n-5.61\n-23.14\n6.25\n0.86\n\n\ndufflitter\nha - ld\n-4.15\n-18.16\n9.96\n0.78\n\n\ndufflitter\nhd - gs\n6.63\n-10.40\n23.21\n0.80\n\n\ndufflitter\nhd - ha\n13.96\n-2.39\n30.07\n0.97\n\n\ndufflitter\nhd - ld\n7.78\n-6.65\n26.21\n0.88\n\n\ndufflitter\nld - gs\n-2.38\n-17.13\n13.10\n0.63\n\n\nthoushr\nha - gs\n-8.68\n-53.34\n24.79\n0.79\n\n\nthoushr\nha - ld\n1.51\n-31.47\n30.66\n0.54\n\n\nthoushr\nhd - gs\n-3.59\n-47.19\n41.22\n0.58\n\n\nthoushr\nhd - ha\n7.86\n-26.40\n48.36\n0.75\n\n\nthoushr\nhd - ld\n8.97\n-21.37\n53.41\n0.77\n\n\nthoushr\nld - gs\n-10.32\n-55.80\n21.37\n0.82\n\n\nveg\nha - gs\n-14.06\n-36.94\n-0.29\n0.99\n\n\nveg\nha - ld\n-6.80\n-22.39\n4.75\n0.95\n\n\nveg\nhd - gs\n-8.37\n-32.01\n6.94\n0.92\n\n\nveg\nhd - ha\n4.25\n-5.81\n17.37\n0.86\n\n\nveg\nhd - ld\n-3.24\n-18.57\n11.20\n0.70\n\n\nveg\nld - gs\n-5.12\n-28.88\n11.62\n0.81\n\n\n\n\n\n\n\n\n\n\n5.3.2.9 R squared\n\n\nCode\nbf4a |&gt;\nmutate(\n  R_squared = list(as_tibble(bayes_R2(mod)))\n) |&gt;\nselect(R_squared) |&gt;\nunnest(R_squared) |&gt;\nknitr::kable(digits = 2)\n\n\nAdding missing grouping variables: `class`\n\n\n\n\nTable 5.9: This version of R2 is recommended by Gelman et al. (2019). It is defined as the variance in predictions divided by the variance in predictions plus the expected variance of the errors.\n\n\n\n\n\n\nclass\nEstimate\nEst.Error\nQ2.5\nQ97.5\n\n\n\n\nonehr\n0.36\n0.08\n0.21\n0.51\n\n\ntenhr\n0.23\n0.08\n0.09\n0.39\n\n\nhundhr\n0.18\n0.07\n0.07\n0.33\n\n\ndufflitter\n0.19\n0.07\n0.08\n0.34\n\n\nthoushr\n0.17\n0.08\n0.06\n0.35\n\n\nveg\n0.44\n0.10\n0.23\n0.63",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Fuel modeling</span>"
    ]
  },
  {
    "objectID": "analysis/fuel_data_modeling.html#final",
    "href": "analysis/fuel_data_modeling.html#final",
    "title": "4  Fuel modeling",
    "section": "5.4 Final",
    "text": "5.4 Final\n\n5.4.1 Model formula and prior explanation\nThe final model is described in Equation 5.1. The description of the meaning of the priors in the following list should probably be included for explanation.\n\n\n5.4.2 fiting and diagnostics\n\nThe actual code used to fit the model in brms should be included in an appendix.\n?fig-gamma-pri-post should be included as an example of the connection between our priors and posterior distributions.\nWe should summarize rhat and tail ess for all models as shown in Table 7.2\n\nR-hat values were all below 1.005\nBulk and tail effective sample sizes were generally above 1000, with the exception of plot and corner SD’s for 1000-hr and Live vegetation fuels, which were above 640.\nThese should be adequate effective sample sizes for robust inference.\n\nFigure 5.15 should be included to show model fit\nTable 5.9 gives an interpretation of R-squared for bayesian models for each of our models.\n\n\n\n5.4.3 Results\n\n5.4.3.1 Predicted means\n\nThe posterior effect of treatment is summarized in Figure 5.16.\nFor 1-hr fuels, treatments HD and HA show patterns of higher loading. This may have to do with more fine fuel inputs from higher retention. This could lead to increased fire behavior, which could be of benefit if attempting to burn under marginal conditions.\nThe HD treatment shows the potential for higher loading of duff and litter. This could be due to the same effect as for 1-hr fuels, but the HA treatement does not show a similar trend in this case. This could be explained by a higher probability of sampling near a trees base, where duff and litter load are known to be higher.\nAn obvious trend in live vegetation is revealed in the GS treatment, where tree sprouts and brush was able to regenerate without any competition. The potentially reduced live vegetation in the HA treatment is unexpected.\n\n\n\n5.4.3.2 Predicted contrasts\n\nPairwise comparison of treatment efffect is sumarized in Figure 5.17\nContrasts take into account how expected predictions co-vary and is a better indicato of potential differences between treatments.\nIf we take the 95% credible interval as the measure of “significant differences” between treatments, then the HA treatment would be considered to result in greater fuel load than the GS treatment, and the opposite trend would be true for live vegetation: HA is greater than GS.\nThe posterior distributions of contrasts reveal more potential differences with somewhat reduced certainty for 1-hr, Duff & litter, and Live vegetation.\n\nIt is also likely that the LD treatment has lower 1-hr fuel loading than HA.\nSimilar to the HA treatment, the HD treatment also appears to have greater loading than GS.\nFor Duff & litter, the HD treatment may have greater load than HA\nFor live vegetation, LD may have greater load than HA.\n\nFor 10, 100, and 1000-hr fuels, there is no real detectable differences between treatments.",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Fuel modeling</span>"
    ]
  },
  {
    "objectID": "analysis/fuel_data_modeling.html#todo",
    "href": "analysis/fuel_data_modeling.html#todo",
    "title": "4  Fuel modeling",
    "section": "5.5 TODO:",
    "text": "5.5 TODO:\n\nInter-class correlation: ICC\nmultivariate response to accont for correlations between fuel classes\nDirichlet, or similiar joint priors on random group SD’s to control exponential increase due to multiple independent priors\nInclude model for measurement error\nmodel stations along transects\n\nthis requires some fuel classes being modeled at an added heirarchical level (station) while the others only get modeled to the transect level\n\nInclude model for deriving biomass from counts, heights, and percent cover estiamtes\n\nvariability + uncertainty about particle density\nvariability + uncertainty about diameter distributions\nvariability + uncertainty about relationship between vegetation sampling cylinder observations and biomass.\n\nSample size calculations",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Fuel modeling</span>"
    ]
  },
  {
    "objectID": "analysis/fuel_data_modeling.html#saved-output",
    "href": "analysis/fuel_data_modeling.html#saved-output",
    "title": "4  Fuel modeling",
    "section": "5.6 Saved output",
    "text": "5.6 Saved output\n\n\nCode\nsave(\n  expected_predictions,\n  expected_contrasts,\n  fuel_class_labeller,\n  file = \"fuel_data_modeling.rda\"\n)",
    "crumbs": [
      "Fuels",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Fuel modeling</span>"
    ]
  },
  {
    "objectID": "analysis/sprouts_import_data.html",
    "href": "analysis/sprouts_import_data.html",
    "title": "5  Sprout height data description",
    "section": "",
    "text": "5.1 Getting started\nFirst, we’ll load some libraries and our data.\nCode\nlibrary(lme4)\nlibrary(modelsummary)\nlibrary(marginaleffects)\nlibrary(ggdist)\nlibrary(ggridges)\nlibrary(emmeans)\nlibrary(multcomp)\nlibrary(multcompView)\nlibrary(tidyverse)\nlibrary(mgcv)\nlibrary(patchwork)\nlibrary(DHARMa)\nlibrary(glmmTMB)\nlibrary(ggeffects)\nSite\nPlot\nTrtmt\nTree\nSpecies\nHT1yr_m\nHT5yr_m\nHT10yr_m\nHTI1-5yr\nHTI5-10yr\nDBH10yr_cm\nLCBH10yr\nCR10yr\nHD10yr\nSDIinit\nAggregatedYN\nResidRWonClumpYN\nHT10rank\n\n\n\n\nWaldo North\n2\nGS\n285\nLIDE\n1.72\n3.55\n6.30\n0.4575\n0.550\nNA\nNA\nNA\nNA\n0.00\n0\nNA\n4\n\n\nWaldo South\n4\nGS\n13\nSESE\n1.14\n3.11\n6.00\n0.4925\n0.578\n6.6\n0.60\n0.900000\n90.90909\n0.00\n0\n0\n21\n\n\nWhiskey Springs\n4\nHA\n1904\nLIDE\n0.29\n0.96\n1.94\n0.1675\n0.196\nNA\nNA\nNA\nNA\n536.33\n1\nNA\n24\n\n\nWhiskey Springs\n2\nHD\n1405\nSESE\n1.83\n5.21\n9.20\n0.8450\n0.798\n12.5\n0.01\n0.998913\n73.60000\n509.90\n0\n0\n6\nThe data is in a wide format, variables are as follows:\nTable 5.1: Descriptions of variables in dataset.\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nSite\nOne of four sites where treatments were replicated. Sites were located on similar slope positions, but across a range of aspects.\n\n\nPlot\nThere were 4 plots at each site and each was randomly assigned a treatment\n\n\nTrtmt\nTreatemnt type: GS = group selection, which is basically a small clearing, LD = low density--fewer trees remaining; HD = high density--more trees remain and they are dispersed; HA = high density aggregated--more trees remain and they are grouped into clumps.\n\n\nTree\nUnique sprout ID within Site, Plot, and Species\n\n\nSpecies\nSESE = coast redwood, and LIDE = tanoak.\n\n\nHT1yr_m\nSprout height one year after treatment.\n\n\nHT5yr_m\nSame as above, but for year 5\n\n\nHT10yr_m\nSame as above, but for year 10\n\n\nHTI1-5yr\nHeight growth between years 1 and 5, (4 growth periods)\n\n\nHTI5-10yr\nHeight growth between years 5 and 10 (5 growth periods)\n\n\nDBH10yr_cm\nDiameter at breast height in cm at year 10. Only collected for redwood\n\n\nLCBH10yr\nLive crown base height (height to first live branch) at year 10. Only collected for redwood.\n\n\nCR10yr\nCrown ratio (live crown length / total height) at year 10, only for redwood\n\n\nHD10yr\nUnknown.\n\n\nSDIinit\nStand density index of plot immediately after treatment.\n\n\nAggregatedYN\nIndicator for treatment HA.\n\n\nResidRWonClumpYN\nUnknown.\n\n\nHT10rank\nTrees species specific height ranking within plot.",
    "crumbs": [
      "Sprout height",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Sprout height data description</span>"
    ]
  },
  {
    "objectID": "analysis/sprouts_import_data.html#wrangle",
    "href": "analysis/sprouts_import_data.html#wrangle",
    "title": "5  Sprout height data description",
    "section": "5.2 Wrangle",
    "text": "5.2 Wrangle\nI’m going to change some variable names to make them more ergonomic\n\n\nCode\nnewnames &lt;- c(\n  site = \"Site\", plot = \"Plot\", treat = \"Trtmt\", tree = \"Tree\", spp = \"Species\",\n  ht1 = \"HT1yr_m\", ht5 = \"HT5yr_m\", ht10 = \"HT10yr_m\", ht_inc5 = \"HTI1-5yr\",\n  ht_inc10 = \"HTI5-10yr\", dbh10 = \"DBH10yr_cm\", lcbh10 = \"LCBH10yr\",\n  sdi_init = \"SDIinit\", agg = \"AggregatedYN\", ht_rnk10 = \"HT10rank\"\n)\n\ntibble(old = newnames, new = names(newnames)) |&gt; knitr::kable()\n\n\n\n\n\nold\nnew\n\n\n\n\nSite\nsite\n\n\nPlot\nplot\n\n\nTrtmt\ntreat\n\n\nTree\ntree\n\n\nSpecies\nspp\n\n\nHT1yr_m\nht1\n\n\nHT5yr_m\nht5\n\n\nHT10yr_m\nht10\n\n\nHTI1-5yr\nht_inc5\n\n\nHTI5-10yr\nht_inc10\n\n\nDBH10yr_cm\ndbh10\n\n\nLCBH10yr\nlcbh10\n\n\nSDIinit\nsdi_init\n\n\nAggregatedYN\nagg\n\n\nHT10rank\nht_rnk10\n\n\n\n\n\n\n\nOur data are nested. We have plots within sites, trees within plots, and observeations within trees (multiple observations per tree).\nSites\n└─ Plots\n   └─ Trees\n      └─ Observations\nEach Treatment is represented by one site/plot combination. Each site belongs to each treatment and vice versa. I think the terminology here is that Sites and treatments are crossed.\nCurrently, plot (integer) is only unique within site and tree is only unique within site, treat, and spp. It will be more convenient if plot and tree are globally unique identifiers. This makes the nesting structure implicit and we can simplify our model syntax.\n\n\nCode\nmake_site_plot_unique &lt;- function(data) {\n  data |&gt;\n    mutate(plot = cur_group_id(), .by = c(site, treat)) |&gt;\n    mutate(tree = row_number())\n}\n\n\nI’m also going to order the treatments acording to our expectations about the most to least productive. This will affect how they are plotted and reported.\n\n\nCode\ntreat_order &lt;- c(\"GS\", \"LD\", \"HA\", \"HD\")\n\nset_expected_treatment_order &lt;- function(data) {\n  data |&gt;\n    mutate(treat = fct_relevel(treat, treat_order))\n}\n\n\nFor modeling purposes, I will make sure that the data are of the correct type. Grouping variables and character data should be factors.\n\n\nCode\n# Assuming variable names have already been changed\nset_data_types &lt;- function(data) {\n  data |&gt;\n    mutate(\n      across(c(site, plot, treat, tree, spp), as.factor)\n    )\n}\n\n\nAnd I’ll apply all the above steps in one go.\n\n\nCode\nsprouts &lt;- sprouts_fresh |&gt;\n  dplyr::select(all_of(newnames)) |&gt;\n  make_site_plot_unique() |&gt;\n  set_expected_treatment_order() |&gt;\n  set_data_types()\n\n\nI will need a function to convert a variable in the data from wide to long format.\n\n\nCode\nlengthen_data &lt;- function(data, var) {\n  # I need regex for first part to handle ht and ht_inc and\n  pref &lt;- switch(var, ht = \"(ht)\", ht_inc = \"(ht_inc)\")\n  # and the year\n  suf &lt;- \"(\\\\d+)\"\n  str_to_match &lt;- paste0(pref, suf)\n  pivot_longer(data,\n    matches(str_to_match),\n    names_to = c(\".value\", \"year\"),\n    names_pattern = str_to_match,\n    names_transform = list(year = as.integer)\n  ) |&gt;\n  relocate(year, matches(paste0(pref, \"$\")), .after = spp)\n}\n\n\nSave the needed objects for the next script\n\n\nCode\nsave(sprouts, lengthen_data, treat_order, file = \"wrangled_sprouts.rda\")",
    "crumbs": [
      "Sprout height",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Sprout height data description</span>"
    ]
  },
  {
    "objectID": "analysis/sprout_data_exploration.html",
    "href": "analysis/sprout_data_exploration.html",
    "title": "6  Sprout data exploration",
    "section": "",
    "text": "6.1 Objectives",
    "crumbs": [
      "Sprout height",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Sprout data exploration</span>"
    ]
  },
  {
    "objectID": "analysis/sprout_data_exploration.html#objectives",
    "href": "analysis/sprout_data_exploration.html#objectives",
    "title": "6  Sprout data exploration",
    "section": "",
    "text": "For each species/treatment combination, is there a difference in height increment between the first and second periods?\nIs there a difference in redwood or tanoak sprout heights at year 10, if so, what is the magnitude of the difference?",
    "crumbs": [
      "Sprout height",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Sprout data exploration</span>"
    ]
  },
  {
    "objectID": "analysis/sprout_data_exploration.html#visualize-data",
    "href": "analysis/sprout_data_exploration.html#visualize-data",
    "title": "6  Sprout data exploration",
    "section": "6.2 Visualize data",
    "text": "6.2 Visualize data\n\n6.2.1 Tree heights\nThe following figures reveal possible trends in the raw data.\n\n6.2.1.1 Species/treatment/year\nFigure 6.1 reveals fine, species specific differences between treatments and general trends over time. It shows that over time, LD and GS treatments have more taller trees than the other treatments, with GS having the most. This is true for both redwood and tanoak. Additionally, for redwood it appears that HA may have taller trees than HD, at least in year 10.\nFigure 6.2 shows the same information as before, but is arguably easier to look at. There is a general increasing trend in heights with treatments as follows:\nHD &lt; HA &lt; LD &lt; GS\nRedwood is consistently taller than tanoak, and the GS treatment confers the greatest advantage to redwood.\nAcross all treatments, it is also interesting to note that over times, the height distributions, especially for redwood, seem to becoming more multi-modal and more widely distributed. This could be due to site or plot effects, or to microsite (within plot) effects, but it is not immediately clear why this diverging performance should be so apparent with redwood and not tanoak.\n\n\nCode\nsprouts |&gt;\n  lengthen_data(\"ht\") |&gt;\n  ggplot(aes(ht, treat, color = treat, fill = treat)) +\n  scale_y_discrete(expand = c(0, 0)) +\n  scale_x_continuous(expand = c(0, 0)) +\n  coord_cartesian(clip = \"off\") +\n  geom_dots(binwidth = unit(0.019, \"npc\")) +\n  facet_grid(vars(spp), vars(year), scales = \"free\", labeller = label_both) +\n  labs(x = \"Height (m)\", y = \"Treatment\") +\n  scale_color_brewer(palette = \"Set2\", aesthetics = c(\"color\", \"fill\")) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nFigure 6.1: Height distributions for tanoak and redwood over time for each of four treatments. Treatments GS and LD have higher proportions of taller trees. Years refers to number of years after treatment.\n\n\n\n\n\n\n\nCode\nsprouts |&gt;\n  lengthen_data(\"ht\") |&gt;\n  ggplot(aes(\n    x = ht,\n    y = fct_relevel(treat, treat_order),\n    color = factor(spp, levels = c(\"SESE\", \"LIDE\"))\n  )) +\n  scale_y_discrete(expand = c(0, 0)) +\n  scale_x_continuous(expand = c(0, 0)) +\n  coord_cartesian(clip = \"off\") +\n  geom_density_ridges(alpha = .3, size = 1) +\n  facet_grid(year ~ ., labeller = label_both) +\n  labs(x = \"Height (m)\", y = \"Treatment\") +\n  scale_color_brewer(palette = \"Set2\", name = \"Species\")\n\n\n\n\n\n\n\n\nFigure 6.2: Similar to Figure 6.1, but with an emphasis on differences between speceis responses across treatments. Comparisons are made for each year. The GS treatment appears to favor redwood response the most, but all treatments show redwoods are taller than tanoak. Years refers to number of years after treatment.\n\n\n\n\n\n\n\n6.2.1.2 Species/year/SDI\nFigure 6.3 shows that above around 400 SDI, tree heights level off. It also implies a steady decrease in height from 0 to around 400 SDI. The strength of the relationship appears to be increasing over time, particularly for redwood.\n\n\nCode\nsprouts |&gt;\n  lengthen_data(\"ht\") |&gt;\n  ggplot(aes(sdi_init, ht, color = factor(year))) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(span = 1.2) +\n  facet_wrap(~spp) +\n  scale_color_brewer(palette = \"Set2\")\n\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\nFigure 6.3: SDI vs HT for both species, across measurement years.\n\n\n\n\n\n\n\n6.2.1.3 Species/site/plots\nLets see what the variability among sites and plots looks like, I’ll focus on year 10 only.\nFigure 6.4 reveals some differences between sites, particularly for redwoods. Waldo North tends to have larger redwoods and Camp 6 has a large proportion of smaller redwoods.\nFigure 6.5 shows that much of the difference in sites has to do with one outlier plot within a site, and less about general site trends. We should expect plots to capture a portion of the variance. Most notable is the plot level difference between redwood and tanoak. For redwood, the large ammount of within plot variability combined with the between plot variability obscures the treatment (and site) effect. If you squint, there appears to be a similar overall pattern between redwood and tanoak repsonse to treatment, but it appears they respond differentially to certain plots.\n\n\nCode\nsprouts |&gt;\n  ggplot(aes(ht10, site, fill = spp)) +\n  stat_slab(aes(thickness = after_stat(pdf * n)), alpha = 0.6, scale = 0.7) +\n  stat_dotsinterval(side = \"bottom\", scale = 0.7, slab_color = NA) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(x = \"year 10 height (m)\", y = NULL, fill = \"species\")\n\n\n\n\n\n\n\n\nFigure 6.4: Distribution of heights at year 10 at each site for two species. Slabs are normalized by sample size to reflect the raw data, plotted as dots below.\n\n\n\n\n\n\n\nCode\nsprouts |&gt;\n  mutate(treat = fct_relevel(treat, treat_order)) |&gt;\n  ggplot(aes(\n    ht10,\n    site,\n    fill = treat,\n  )) +\n  stat_slab(aes(thickness = after_stat(pdf * n)), alpha = 0.5, scale = 0.7) +\n  stat_pointinterval(position = position_dodge(width = 0.5, preserve = \"single\")) +\n  scale_color_brewer(palette = \"Set2\") +\n  facet_wrap(~spp) +\n  theme(legend.position = \"bottom\") +\n  labs(y = NULL, x = \"year 10 height (m)\", fill = \"treatment\")\n\n\n\n\n\n\n\n\nFigure 6.5: Same as for Figure 6.4, but for each plot (Site/treatment interaction). Grouped by treatment.\n\n\n\n\n\n\n\n\n6.2.2 Height increments\nHeight increments contain similar information as heights, but allow us to compare directly between years.\nFigure 6.6 shows that across treatments and species, height growth slows down in the second period (years 5-10). This is more true for redwood but it starts with more rapid growth than tanoak. In the most crowded treatment (HD), redwoods height increment has become slower than tanoaks in the second period. Also, in the second period, the high density, aggregated treatment appears to have slightly higher (or equal) average growth increment, which is not completely expected.\n\n\nCode\nsprouts |&gt;\n  lengthen_data(\"ht_inc\") |&gt;\n  ggplot(\n    aes(\n      ht_inc,\n      fct_relevel(treat, treat_order),\n      fill = factor(year),\n      color = factor(year)\n    )\n  ) +\n  stat_slab(alpha = 0.5) +\n  stat_pointinterval(\n    position = position_dodge(width = 0.4, preserve = \"single\")\n  ) +\n  facet_wrap(~spp) +\n  theme(legend.position = \"bottom\") +\n  labs(\n    fill = \"Year\",\n    color = \"Year\",\n    y = \"Treatment\",\n    x = expression(Height~increment~(m~yr^-1))\n  ) +\n  scale_color_manual(\n    values = rnd_color_brewer(\"Set2\", c(1,4)),\n    aesthetics = c(\"color\", \"fill\")\n  )\n\n\n[1] 1 4\n\n\n\n\n\n\n\n\nFigure 6.6: Variations in annual height growth increment between the first and second measurement periods (years 1-5, and 5-10, respectively).",
    "crumbs": [
      "Sprout height",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Sprout data exploration</span>"
    ]
  },
  {
    "objectID": "analysis/sprout_modeling.html",
    "href": "analysis/sprout_modeling.html",
    "title": "7  Sprout data modeling",
    "section": "",
    "text": "7.1 Modeling\nWe have nested data where we have multiple observations within trees (over time), trees within plots and plots within sites. Any of these levels of nesting might result in correlations between observations, which violates the assumption of independence for OLS models, but can be accounted for using multi-level models.\nI may want to include a categorical variable (spp) as a random slope (on the LHS of the random parts) to allow random effects to be estimated for each species separately. Michael Clark explores this scenario, with some simpler data.\nMy approach will be to start with a simple model and build towards more complex models.",
    "crumbs": [
      "Sprout height",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Sprout data modeling</span>"
    ]
  },
  {
    "objectID": "analysis/sprout_modeling.html#modeling",
    "href": "analysis/sprout_modeling.html#modeling",
    "title": "7  Sprout data modeling",
    "section": "",
    "text": "7.1.1 Height increment\nBy starting with height increment modeling, I will be able to answer question 1 in the objectives. This conclusion may be helpful for informing total height modeling. I am curious whether height in the first 10 years increases linearly with age. Is there a growth slow down in year 5-10 compared to years 1-5?\nWe saw in Figure 6.6 that increment does slow down somewhat in the second measurement period (year 5-10), at least for redwoods, but we may be justified in overlooking this. Lets look at individual tree’s height trajectories.\n\n\nCode\ndht &lt;- lengthen_data(sprouts, \"ht\")\n\ndht |&gt; \n  ggplot(aes(year, ht, color = spp, group = tree)) +\n  geom_line(alpha = 0.6) +\n  facet_wrap(~treat * site) +\n  scale_color_brewer(palette = \"Set2\") +\n  theme(\n    legend.position = \"bottom\"\n  )\n\n\n\n\n\n\n\n\nFigure 7.1: Data plot showing trajectory of individual tree heights across the three measurements. Height increase appears fairly linear with year.\n\n\n\n\n\nFor the most part, it looks like height increases linearly with year. Lets test this with a model.\n\nht_inc ~ year\nIgnoring everything else, there is a 0.08 m / yr slow down in the second period.\nht_inc ~ year + spp + year:spp\nThat slow down has more to do with redwood than tanoak.\nht_inc ~ year + spp + treat + year:spp + year:treat + spp:treat + year:spp:treat\nThere are overall treatment effect on growth which varies by species (redwood is more affected) but there are no more significant interactions with year. Our data does not detect significant differences in slow down by treatment or species. j\nht_inc ~ year + spp + treat\nThis includes only additive effects and the effect of year is the same as model 1.\nht_inc ~ year + spp + treat + spp:treat\nAgain, the species by treatment interactions seem to be significant.\nht_inc ~ year + spp + treat + spp:treat + year:spp\nThe species year interaction remains important.\nht_inc ~ year + spp + treat + spp:treat + year:spp + year:treat\nAgain, the treatment by year interactions do not seem important/estimable.\nht_inc ~ treat + year + spp + treat:spp + spp:year + (1 | plot) + (1 | tree)\nNow I introduce random intercepts for plot and tree. These lead to much smaller AIC’s.\nht_inc ~ treat + year + spp + (1 | plot) + (1 | tree) + treat:spp + year:spp + treat:year\nBut treatment by year is still (mostly) not significant.\nht_inc ~ treat + year + spp + (1 | tree) + (0 + spp | plot) + treat:spp + year:spp\nAdding a random slope for species by plot results in another big jump in AIC, but also reduces confidence in the treatment*species interaction. It would seem that the potential differences in species by treatment growth rate are obscured by redwoods greater variability across plots.\nht_inc ~ treat + year + spp + (1 | tree) + (0 + spp | plot) + year:spp\nRemoving the treat * species interaction results in a solid AIC boost.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nminc1\nminc2\nminc3\nminc4\nminc5\nminc6\nminc7\nminc8\nminc9\nminc10\nminc11\n\n\n\n\n(Intercept)\n0.585***\n0.387***\n0.499***\n0.577***\n0.516***\n0.496***\n0.506***\n0.496***\n0.506***\n0.494***\n0.504***\n\n\n\n(0.012)\n(0.014)\n(0.025)\n(0.016)\n(0.019)\n(0.020)\n(0.022)\n(0.049)\n(0.049)\n(0.038)\n(0.037)\n\n\nyear10\n-0.082***\n-0.042*\n-0.048\n-0.082***\n-0.082***\n-0.042*\n-0.061*\n-0.042***\n-0.061***\n-0.042***\n-0.042***\n\n\n\n(0.018)\n(0.020)\n(0.035)\n(0.013)\n(0.013)\n(0.018)\n(0.028)\n(0.011)\n(0.017)\n(0.011)\n(0.011)\n\n\nsppSESE\n\n0.412***\n0.544***\n0.366***\n0.489***\n0.530***\n0.530***\n0.526***\n0.525***\n0.528***\n0.414***\n\n\n\n\n(0.020)\n(0.035)\n(0.013)\n(0.025)\n(0.028)\n(0.028)\n(0.031)\n(0.031)\n(0.086)\n(0.045)\n\n\nyear10 x sppSESE\n\n-0.083**\n-0.109*\n\n\n-0.083**\n-0.083**\n-0.083***\n-0.083***\n-0.083***\n-0.083***\n\n\n\n\n(0.029)\n(0.050)\n\n\n(0.026)\n(0.026)\n(0.015)\n(0.015)\n(0.015)\n(0.015)\n\n\ntreatLD\n\n\n-0.091*\n-0.132***\n-0.086***\n-0.086***\n-0.086**\n-0.090\n-0.091\n-0.092+\n-0.098+\n\n\n\n\n\n(0.037)\n(0.019)\n(0.026)\n(0.026)\n(0.032)\n(0.070)\n(0.071)\n(0.054)\n(0.052)\n\n\ntreatHA\n\n\n-0.171***\n-0.248***\n-0.169***\n-0.169***\n-0.193***\n-0.172*\n-0.195**\n-0.167**\n-0.181***\n\n\n\n\n\n(0.035)\n(0.018)\n(0.025)\n(0.025)\n(0.030)\n(0.069)\n(0.070)\n(0.053)\n(0.052)\n\n\ntreatHD\n\n\n-0.182***\n-0.290***\n-0.176***\n-0.176***\n-0.189***\n-0.175*\n-0.189**\n-0.174**\n-0.194***\n\n\n\n\n\n(0.035)\n(0.018)\n(0.025)\n(0.025)\n(0.030)\n(0.069)\n(0.070)\n(0.053)\n(0.052)\n\n\ntreatLD x year10\n\n\n0.010\n\n\n\n0.001\n\n0.001\n\n\n\n\n\n\n\n(0.052)\n\n\n\n(0.037)\n\n(0.022)\n\n\n\n\ntreatHA x year10\n\n\n0.004\n\n\n\n0.048\n\n0.048*\n\n\n\n\n\n\n\n(0.049)\n\n\n\n(0.035)\n\n(0.021)\n\n\n\n\ntreatHD x year10\n\n\n0.012\n\n\n\n0.026\n\n0.026\n\n\n\n\n\n\n\n(0.049)\n\n\n\n(0.035)\n\n(0.021)\n\n\n\n\ntreatLD x sppSESE\n\n\n-0.082\n\n-0.092*\n-0.092*\n-0.092*\n-0.080+\n-0.080+\n-0.070\n\n\n\n\n\n\n(0.052)\n\n(0.037)\n(0.037)\n(0.037)\n(0.045)\n(0.045)\n(0.122)\n\n\n\ntreatHA x sppSESE\n\n\n-0.206***\n\n-0.161***\n-0.161***\n-0.161***\n-0.154***\n-0.154***\n-0.158\n\n\n\n\n\n\n(0.050)\n\n(0.035)\n(0.035)\n(0.035)\n(0.043)\n(0.043)\n(0.121)\n\n\n\ntreatHD x sppSESE\n\n\n-0.250***\n\n-0.236***\n-0.236***\n-0.236***\n-0.232***\n-0.232***\n-0.230+\n\n\n\n\n\n\n(0.050)\n\n(0.036)\n(0.035)\n(0.035)\n(0.043)\n(0.043)\n(0.121)\n\n\n\ntreatLD x year10:sppSESE\n\n\n-0.019\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.074)\n\n\n\n\n\n\n\n\n\n\ntreatHA x year10:sppSESE\n\n\n0.090\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.070)\n\n\n\n\n\n\n\n\n\n\ntreatHD x year10:sppSESE\n\n\n0.029\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.071)\n\n\n\n\n\n\n\n\n\n\nSD (Intercept tree)\n\n\n\n\n\n\n\n0.176\n0.176\n0.162\n0.162\n\n\nSD (Observations)\n\n\n\n\n\n\n\n0.143\n0.143\n0.143\n0.143\n\n\nSD (Intercept plot)\n\n\n\n\n\n\n\n0.088\n0.088\n\n\n\n\nSD (sppLIDE plot)\n\n\n\n\n\n\n\n\n\n0.064\n0.063\n\n\nSD (sppSESE plot)\n\n\n\n\n\n\n\n\n\n0.167\n0.173\n\n\nCor (sppLIDE~sppSESE plot)\n\n\n\n\n\n\n\n\n\n0.283\n0.259\n\n\nNum.Obs.\n1384\n1384\n1384\n1384\n1384\n1384\n1384\n1384\n1384\n1384\n1384\n\n\nAIC\n827.1\n283.0\n-30.5\n12.4\n-28.9\n-37.5\n-33.9\n-438.9\n-439.6\n-488.6\n-490.4\n\n\nBIC\n842.8\n309.2\n58.5\n49.0\n23.5\n20.1\n39.4\n-370.9\n-355.9\n-410.1\n-427.6\n\n\nRMSE\n0.33\n0.27\n0.24\n0.24\n0.24\n0.24\n0.24\n0.11\n0.11\n0.11\n0.11\n\n\n\nNote: ^^ + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n7.1.2 Height increment results\nThe model selected based on AIC lacks a treatment x year interaction. This means that there was not enough evidence to suggest that any treatment results in a lesser or greater slow down in height growth. Across treatments, the effect of year was significant, and this varied significantly by species–redwood’s height growth rate reduction was about 3 times that of tanoak.\n\n\nCode\nminc11em &lt;- emmeans(minc[[11]], c(\"year\"), by = c(\"spp\"))\n\nminc11con &lt;- contrast(minc11em, \"consec\") |&gt; confint() |&gt; as_tibble()\n\nminc11cld &lt;- cld(minc11em, Letters = letters) |&gt;\n  as_tibble() |&gt;\n  mutate(.group = str_replace_all(.group, \" \", \"\"))\n\nminc11con |&gt;\n  ggplot(aes(spp, -estimate, color = spp)) +\n  geom_pointrange(\n    aes(ymin = -lower.CL, ymax = -upper.CL),\n    linewidth = 1, size = 1\n    ) +\n  scale_color_brewer(palette = \"Set2\", aesthetics = c(\"color\", \"fill\")) +\n  labs(\n    x = NULL,\n    y = expression(Height ~ increment ~ reduction ~ (-m %.% yr^-1)),\n    color = \"Species\"\n  )\n\n\n\n\n\n\n\n\nFigure 7.2: Growth period 1 is year 1-5, growth period 2 is year 5-10. Growth significantly decreased in the second period for both species.\n\n\n\n\n\n\n\nCode\nminc11con |&gt; knitr::kable(digits = 3)\n\n\n\n\nTable 7.1: Growth period 1 is year 1-5, growth period 2 is year 5-10. Growth significantly decreased in the second period for both species.\n\n\n\n\n\n\ncontrast\nspp\nestimate\nSE\ndf\nlower.CL\nupper.CL\n\n\n\n\nyear10 - year5\nLIDE\n-0.042\n0.011\n690\n-0.063\n-0.020\n\n\nyear10 - year5\nSESE\n-0.125\n0.011\n690\n-0.146\n-0.103\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nminc11cld |&gt;\n  ggplot(aes(year, emmean, fill = spp, color = spp)) +\n  geom_pointrange(\n    aes(ymin = lower.CL, ymax = upper.CL),\n    position = position_nudge(x = -0.15),\n    size = 0.9, linewidth = 1\n  ) +\n  geom_dots(data = dinc, aes(year, ht_inc), alpha = 0.4) +\n  facet_grid(~spp, switch = \"x\") +\n  theme(\n    panel.spacing = unit(0, \"lines\"),\n    strip.background = element_blank(),\n    strip.text = element_blank(),\n  ) +\n  geom_text(\n    aes(y = upper.CL, label = .group),\n    # color = \"black\",\n    position = position_nudge(x = -0.15, y = 0.1)\n  ) +\n  scale_color_brewer(palette = \"Set2\", aesthetics = c(\"color\", \"fill\")) +\n  labs(\n    x = \"Growth period\",\n    y = expression(Height ~ increment ~ (m %.% year^-1)),\n    color = \"Species\",\n    fill = \"Species\"\n  ) +\n  scale_x_discrete(labels = c(\"1\", \"2\"))\n\n\n\n\n\n\n\n\nFigure 7.3: There was a significant difference in height increment between period 1 and 2 for both species.\n\n\n\n\n\n\n\n7.1.3 Heights - year 10 only\nThe simplest model that I’m willing to look at includes a treatment/species interaction, and no random effects. It will serve as a baseline for comparison.\n\n# I'm calling the height data \"d\"\ndht10 &lt;- sprouts |&gt; lengthen_data(\"ht\") |&gt; filter(year == 10)\n\nmht101 &lt;- lm(ht ~ treat * spp, data = dht10)\nmht102 &lt;- lmer(ht ~ treat * spp + (1 | plot) + (1 | site), data = dht10)\n\nboundary (singular) fit: see help('isSingular')\n\nmht103 &lt;- lmer(ht ~ treat * spp + (1 | plot), data = dht10)\nmht104 &lt;- lmer(ht ~ treat * spp + (0 + spp | plot), data = dht10)\nmht105 &lt;- glmmTMB(\n  ht ~ treat * spp + (0 + spp | plot),\n  family = Gamma(link = \"log\"),\n  data = dht10\n)\nmht106 &lt;- glmmTMB(\n  ht ~ treat * spp + (0 + spp | plot),\n  family = Gamma(link = \"log\"),\n  data = dht10,\n  dispformula = ~ spp\n)\nmht107 &lt;- glmmTMB(\n  ht ~ treat + spp + (0 + spp | plot),\n  family = Gamma(link = \"log\"),\n  data = dht10,\n  dispformula = ~ spp\n)\nmht108 &lt;- glmmTMB(\n  ht ~ treat + spp + (0 + spp | plot),\n  family = Gamma(link = \"log\"),\n  data = dht10,\n  dispformula = ~ spp + treat\n)\nmht109 &lt;- glmmTMB(\n  ht ~ treat + spp + (0 + spp | plot),\n  family = gaussian(link = \"log\"),\n  data = dht10,\n  dispformula = ~ spp + treat\n)\n\nmht10_list &lt;- lst(\n  mht101, mht102, mht103, mht104, mht105, mht106, mht107, mht108, mht109\n)\n\nmodelsummary(\n  mht10_list,\n  stars = TRUE,\n  output = \"markdown\",\n  shape = term:component + statistic ~ model,\n  metrics = c(\"AIC\", \"BIC\", \"RMSE\"),\n  estimator = \"ML\",\n  gof_omit = \"F|Log.Lik\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmht101\nmht102\nmht103\nmht104\nmht105\nmht106\nmht107\nmht108\nmht109\n\n\n\n\n(Intercept)\n5.235***\n5.246***\n5.246***\n5.221***\n\n\n\n\n\n\n\n\n(0.228)\n(0.576)\n(0.576)\n(0.424)\n\n\n\n\n\n\n\ntreatLD\n-1.214***\n-1.290\n-1.290\n-1.306*\n\n\n\n\n\n\n\n\n(0.337)\n(0.820)\n(0.820)\n(0.607)\n\n\n\n\n\n\n\ntreatHA\n-2.055***\n-2.086*\n-2.086*\n-2.044***\n\n\n\n\n\n\n\n\n(0.320)\n(0.813)\n(0.813)\n(0.599)\n\n\n\n\n\n\n\ntreatHD\n-2.087***\n-2.088*\n-2.088*\n-2.076***\n\n\n\n\n\n\n\n\n(0.322)\n(0.814)\n(0.814)\n(0.600)\n\n\n\n\n\n\n\nsppSESE\n5.308***\n5.239***\n5.239***\n5.259***\n\n\n\n\n\n\n\n\n(0.324)\n(0.296)\n(0.296)\n(0.867)\n\n\n\n\n\n\n\ntreatLD × sppSESE\n-1.253**\n-1.102*\n-1.102*\n-1.016\n\n\n\n\n\n\n\n\n(0.483)\n(0.443)\n(0.443)\n(1.234)\n\n\n\n\n\n\n\ntreatHA × sppSESE\n-1.589***\n-1.494***\n-1.494***\n-1.527\n\n\n\n\n\n\n\n\n(0.459)\n(0.419)\n(0.419)\n(1.226)\n\n\n\n\n\n\n\ntreatHD × sppSESE\n-2.564***\n-2.508***\n-2.508***\n-2.479*\n\n\n\n\n\n\n\n\n(0.462)\n(0.422)\n(0.422)\n(1.227)\n\n\n\n\n\n\n\n(Intercept) conditional\n\n\n\n\n1.634***\n1.633***\n1.636***\n1.634***\n1.633***\n\n\n\n\n\n\n\n(0.085)\n(0.086)\n(0.080)\n(0.081)\n(0.079)\n\n\ntreatLD conditional\n\n\n\n\n-0.299*\n-0.302*\n-0.297**\n-0.298**\n-0.287**\n\n\n\n\n\n\n\n(0.121)\n(0.122)\n(0.111)\n(0.112)\n(0.111)\n\n\ntreatHA conditional\n\n\n\n\n-0.476***\n-0.475***\n-0.457***\n-0.453***\n-0.462***\n\n\n\n\n\n\n\n(0.120)\n(0.121)\n(0.110)\n(0.114)\n(0.112)\n\n\ntreatHD conditional\n\n\n\n\n-0.492***\n-0.492***\n-0.525***\n-0.526***\n-0.525***\n\n\n\n\n\n\n\n(0.120)\n(0.121)\n(0.111)\n(0.115)\n(0.112)\n\n\nsppSESE conditional\n\n\n\n\n0.710***\n0.711***\n0.705***\n0.706***\n0.707***\n\n\n\n\n\n\n\n(0.103)\n(0.103)\n(0.054)\n(0.055)\n(0.054)\n\n\ntreatLD × sppSESE conditional\n\n\n\n\n0.012\n0.016\n\n\n\n\n\n\n\n\n\n\n(0.148)\n(0.148)\n\n\n\n\n\ntreatHA × sppSESE conditional\n\n\n\n\n0.054\n0.053\n\n\n\n\n\n\n\n\n\n\n(0.146)\n(0.146)\n\n\n\n\n\ntreatHD × sppSESE conditional\n\n\n\n\n-0.096\n-0.096\n\n\n\n\n\n\n\n\n\n\n(0.146)\n(0.146)\n\n\n\n\n\n(Intercept) dispersion\n\n\n\n\n0.348\n2.356***\n2.356***\n2.938***\n0.232*\n\n\n\n\n\n\n\n\n(0.075)\n(0.075)\n(0.111)\n(0.113)\n\n\nsppSESE dispersion\n\n\n\n\n\n-0.452***\n-0.452***\n-0.293**\n1.609***\n\n\n\n\n\n\n\n\n(0.108)\n(0.108)\n(0.111)\n(0.112)\n\n\ntreatLD dispersion\n\n\n\n\n\n\n\n-0.308+\n-0.149\n\n\n\n\n\n\n\n\n\n\n(0.160)\n(0.161)\n\n\ntreatHA dispersion\n\n\n\n\n\n\n\n-0.956***\n0.006\n\n\n\n\n\n\n\n\n\n\n(0.150)\n(0.153)\n\n\ntreatHD dispersion\n\n\n\n\n\n\n\n-0.986***\n-0.057\n\n\n\n\n\n\n\n\n\n\n(0.153)\n(0.155)\n\n\nSD (Intercept plot)\n\n1.073\n1.073\n\n\n\n\n\n\n\n\nSD (sppLIDE plot)\n\n\n\n0.753\n\n\n\n\n\n\n\nSD (sppSESE plot)\n\n\n\n1.870\n\n\n\n\n\n\n\nCor (sppLIDE~sppSESE plot)\n\n\n\n0.486\n\n\n\n\n\n\n\nSD (sppLIDE plot) conditional\n\n\n\n\n0.153\n0.159\n0.160\n0.168\n0.162\n\n\nSD (sppSESE plot) conditional\n\n\n\n\n0.193\n0.188\n0.192\n0.195\n0.199\n\n\nCor (sppLIDE~sppSESE plot) conditional\n\n\n\n\n0.490\n0.484\n0.448\n0.444\n0.448\n\n\nSD (Intercept site)\n\n0.000\n\n\n\n\n\n\n\n\n\nSD (Observations)\n\n2.000\n2.000\n1.879\n\n\n\n\n\n\n\nNum.Obs.\n692\n692\n692\n692\n692\n692\n692\n692\n692\n\n\nAIC\n3059.2\n2978.5\n2976.5\n2923.0\n2825.0\n2809.6\n2804.7\n2753.6\n2722.1\n\n\nBIC\n3100.1\n3028.4\n3021.9\n2977.4\n2879.5\n2868.6\n2850.1\n2812.6\n2781.2\n\n\nRMSE\n2.18\n1.97\n1.97\n1.84\n1.85\n1.85\n1.85\n1.85\n1.84\n\n\n\nNote: ^^ + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\nThe best model according to AIC includes a random intercept for plot and a random slope for spp. Because spp is a factor, this effectively estimates a species specific intercept, but also takes into account the covariance of the species plot effect. The best model for dispersion included speceis and treatment.\n\n\nCode\nht10_sel &lt;- mht109\n\n\n\n\n7.1.4 Year 10 only Results\n\n\nCode\nht10_cld &lt;- emmeans(ht10_sel,\n  pairwise ~ treat,\n  by = c(\"spp\"),\n  type = \"response\"\n) |&gt;\n  cld(Letters = letters) |&gt;\n  as_tibble() |&gt;\n  rename(any_of(c(lower.CL = \"asymp.LCL\", upper.CL = \"asymp.UCL\"))) |&gt;\n  mutate( .group = str_replace_all(.group, \" \", \"\"))\n\nyear_10_only_plot &lt;- dht10 |&gt;\n  ggplot(aes(treat, ht, color = spp, fill = spp)) +\n  facet_grid(~spp, switch = \"x\") +\n  theme(panel.spacing = unit(0, \"lines\"),\n        strip.background = element_blank(),\n        strip.text = element_blank(),\n        ) +\n  geom_dots() +\n  scale_color_brewer(palette = \"Set2\", aesthetics = c(\"color\", \"fill\")) +\n  geom_pointrange(\n    data = ht10_cld,\n    aes(y = response, ymin = lower.CL, ymax = upper.CL),\n    color = \"gray50\",\n    position = position_nudge(x = -0.07),\n    size = 0.7,\n    linewidth = 1,\n    show.legend = FALSE\n  ) +\n  geom_text(\n    data = ht10_cld,\n    aes(y = upper.CL, label = .group),\n    color = \"black\",\n    position = position_nudge(x = -0.3, y = 0.2)\n  )\n\nyear_10_only_plot\n\n\n\n\n\n\n\n\nFigure 7.4: Mean and 95% confidence interval for the selected model, displayed with raw data. Shared letters between treatments (within species) indicates that there is not sufficient evidence to claim the estiamtes come from different distributions.\n\n\n\n\n\n\n\n7.1.5 Heights - multiple years\nBy including year as a numeric variable, we are assuming a liner relationship between year and height. This term (and it’s interactions) can than be interpreted as a modeled growth increment, and although we only have observations at years 1, 5, and 10, other years predictions will be linearly interpolated.\nThe following models were fit, and are summarized in Table 7.2.\n\nOLS linear model including year in a 3-way interaction.\nEliminate the 3-way interaction (spp:treat:year), keeping others. This results in a significantly lower AIC.\nFirst random-effects model including interactions and universal random slopes for site and plot, and time-series.\nAllow the random effects to (co-) vary by species.\nSame as 5, but attempt to remove the 3-way interaction again.\nSame as 6, but attempt to simplify the random effects by forcing them to be estimated independently, correlation between species is not estimated.\nRe-introduce the 3-way interaction again.\nOmit the random effect for site. This is supported by the interpretation of Figure 6.5.\nLike 9, but try simplified (independent) random effects.\n\nOne problem with this is that I’m comparing AIC for different random effects using ML, when I should be using REML. This may be a problem throughout my model selection.\n\ndht &lt;- lengthen_data(sprouts, \"ht\")\n\nmht2 &lt;- lm(ht ~ treat * spp * year, data = dht)\n\nmht3 &lt;- lm(ht ~ treat + spp + year + treat:year + spp:year + treat:spp, data = dht)\n\nmht4 &lt;- lmer(\n  ht ~ treat * spp * year + (1 | site) + (1 | plot) + (1 | tree),\n  data = dht\n)\n\nboundary (singular) fit: see help('isSingular')\n\nmht5 &lt;- lmer(\n  ht ~ treat * spp * year + (0 + spp | site) + (0 + spp | plot) + \n    (0 + spp | tree),\n  data = dht\n)\n\nboundary (singular) fit: see help('isSingular')\n\nmht6 &lt;- lmer(\n  ht ~ treat + spp + year + treat:spp + year:spp + treat:year +\n    (0 + spp | site) + (0 + spp | plot) + (0 + spp | tree),\n  data = dht\n)\n\nboundary (singular) fit: see help('isSingular')\n\nmht7 &lt;- lmer(\n  ht ~ treat + spp + year + treat:spp + year:spp + treat:year + (1 | site:spp) +\n    (1 | plot:spp) + (1 | tree:spp),\n  data = dht\n)\n\nmht8 &lt;- lmer(\n  ht ~ treat * spp * year + (1 | site:spp) + (1 | plot:spp) + (1 | tree:spp),\n  data = dht\n)\n\nmht9 &lt;- lmer(\n  ht ~ treat * spp * year + (0 + spp | plot) + (0 + spp | tree),\n  data = dht\n)\n\nboundary (singular) fit: see help('isSingular')\n\nmht10 &lt;- lmer(\n  ht ~ treat * spp * year + (1 | plot:spp) + (1 | tree:spp),\n  data = dht\n)\n\n# I tried fitting year as a factor, but then could not fit a model that included\n# the 3-way interaction and random slopes for species. The model without the\n# 3-way (and spp random slopes) was close, but about 12 AIC larger.\n\nmodelsummary(\n  list(\n    \"Model 2\" = mht2, \"Model 3\" = mht3, \"Model 4\" = mht4, \"Model 5\" = mht5,\n    \"Model 6\" = mht6, \"Model 7\" = mht7, \"Model 8\" = mht8, \"Model 9\" = mht9,\n    \"Model 10\" = mht10\n  ),\n  stars = TRUE,\n  output = \"markdown\",\n  metrics = c(\"AIC\", \"BIC\", \"RMSE\"),\n  estimator = \"ML\",\n  gof_omit = \"F|Log.Lik\"\n)\n\n\n\nTable 7.2: Summary table for models 2-10, described above. Standard error in parantheses.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel 2\nModel 3\nModel 4\nModel 5\nModel 6\nModel 7\nModel 8\nModel 9\nModel 10\n\n\n\n\n(Intercept)\n0.552***\n0.232+\n0.559\n0.546*\n0.226\n0.226\n0.546\n0.546*\n0.546\n\n\n\n(0.156)\n(0.136)\n(0.350)\n(0.261)\n(0.255)\n(0.425)\n(0.428)\n(0.260)\n(0.428)\n\n\ntreatLD\n-0.369\n-0.120\n-0.421\n-0.441\n-0.191\n-0.193\n-0.442\n-0.441\n-0.442\n\n\n\n(0.230)\n(0.190)\n(0.499)\n(0.364)\n(0.361)\n(0.593)\n(0.599)\n(0.371)\n(0.609)\n\n\ntreatHA\n-0.372+\n0.035\n-0.390\n-0.367\n0.040\n0.041\n-0.366\n-0.367\n-0.366\n\n\n\n(0.219)\n(0.180)\n(0.495)\n(0.361)\n(0.358)\n(0.589)\n(0.595)\n(0.368)\n(0.605)\n\n\ntreatHD\n-0.348\n0.258\n-0.350\n-0.345\n0.262\n0.262\n-0.345\n-0.345\n-0.345\n\n\n\n(0.220)\n(0.181)\n(0.495)\n(0.361)\n(0.358)\n(0.589)\n(0.596)\n(0.368)\n(0.605)\n\n\nsppSESE\n0.572**\n1.215***\n0.527*\n0.535\n1.178*\n1.182*\n0.539\n0.535\n0.539\n\n\n\n(0.221)\n(0.158)\n(0.205)\n(0.473)\n(0.474)\n(0.596)\n(0.606)\n(0.474)\n(0.606)\n\n\nyear\n0.471***\n0.531***\n0.471***\n0.471***\n0.531***\n0.531***\n0.471***\n0.471***\n0.471***\n\n\n\n(0.024)\n(0.019)\n(0.017)\n(0.017)\n(0.013)\n(0.013)\n(0.017)\n(0.017)\n(0.017)\n\n\ntreatLD × sppSESE\n-0.311\n-0.807***\n-0.224\n-0.181\n-0.677\n-0.669\n-0.173\n-0.175\n-0.173\n\n\n\n(0.330)\n(0.188)\n(0.307)\n(0.533)\n(0.500)\n(0.828)\n(0.849)\n(0.679)\n(0.862)\n\n\ntreatHA × sppSESE\n-0.100\n-0.925***\n-0.039\n-0.057\n-0.882+\n-0.885\n-0.060\n-0.055\n-0.059\n\n\n\n(0.314)\n(0.179)\n(0.291)\n(0.524)\n(0.493)\n(0.824)\n(0.843)\n(0.672)\n(0.857)\n\n\ntreatHD × sppSESE\n-0.245\n-1.492***\n-0.204\n-0.186\n-1.432**\n-1.434+\n-0.187\n-0.186\n-0.187\n\n\n\n(0.316)\n(0.180)\n(0.293)\n(0.525)\n(0.494)\n(0.825)\n(0.844)\n(0.673)\n(0.857)\n\n\ntreatLD × year\n-0.085*\n-0.132***\n-0.085***\n-0.085***\n-0.132***\n-0.132***\n-0.085***\n-0.085***\n-0.085***\n\n\n\n(0.036)\n(0.026)\n(0.025)\n(0.025)\n(0.018)\n(0.018)\n(0.025)\n(0.025)\n(0.025)\n\n\ntreatHA × year\n-0.169***\n-0.245***\n-0.169***\n-0.169***\n-0.245***\n-0.245***\n-0.169***\n-0.169***\n-0.169***\n\n\n\n(0.034)\n(0.024)\n(0.023)\n(0.023)\n(0.017)\n(0.017)\n(0.023)\n(0.023)\n(0.023)\n\n\ntreatHD × year\n-0.175***\n-0.288***\n-0.175***\n-0.175***\n-0.288***\n-0.288***\n-0.175***\n-0.175***\n-0.175***\n\n\n\n(0.034)\n(0.024)\n(0.023)\n(0.023)\n(0.017)\n(0.017)\n(0.023)\n(0.023)\n(0.023)\n\n\nsppSESE × year\n0.481***\n0.360***\n0.481***\n0.481***\n0.360***\n0.360***\n0.481***\n0.481***\n0.481***\n\n\n\n(0.034)\n(0.018)\n(0.024)\n(0.024)\n(0.012)\n(0.012)\n(0.024)\n(0.024)\n(0.024)\n\n\ntreatLD × sppSESE × year\n-0.093+\n\n-0.093**\n-0.093**\n\n\n-0.093**\n-0.093**\n-0.093**\n\n\n\n(0.051)\n\n(0.035)\n(0.035)\n\n\n(0.035)\n(0.035)\n(0.035)\n\n\ntreatHA × sppSESE × year\n-0.155**\n\n-0.155***\n-0.155***\n\n\n-0.155***\n-0.155***\n-0.155***\n\n\n\n(0.048)\n\n(0.033)\n(0.033)\n\n\n(0.033)\n(0.033)\n(0.033)\n\n\ntreatHD × sppSESE × year\n-0.234***\n\n-0.234***\n-0.234***\n\n\n-0.234***\n-0.234***\n-0.234***\n\n\n\n(0.049)\n\n(0.034)\n(0.034)\n\n\n(0.034)\n(0.034)\n(0.034)\n\n\nSD (Observations)\n\n\n1.016\n1.016\n1.031\n1.034\n1.016\n1.016\n1.016\n\n\nSD (Intercept treespp)\n\n\n\n\n\n0.844\n0.852\n\n0.852\n\n\nSD (Intercept plotspp)\n\n\n\n\n\n0.795\n0.795\n\n0.809\n\n\nSD (Intercept tree)\n\n\n0.925\n\n\n\n\n\n\n\n\nSD (sppLIDE tree)\n\n\n\n0.000\n0.000\n\n\n0.000\n\n\n\nSD (sppSESE tree)\n\n\n\n1.227\n1.223\n\n\n1.227\n\n\n\nCor (sppLIDE~sppSESE tree)\n\n\n\n\n\n\n\n0.284\n\n\n\nSD (Intercept plot)\n\n\n0.638\n\n\n\n\n\n\n\n\nSD (sppLIDE plot)\n\n\n\n0.463\n0.474\n\n\n0.474\n\n\n\nSD (sppSESE plot)\n\n\n\n0.913\n0.919\n\n\n1.037\n\n\n\nCor (sppLIDE~sppSESE plot)\n\n\n\n0.783\n0.782\n\n\n0.570\n\n\n\nSD (Intercept site)\n\n\n0.000\n\n\n\n\n\n\n\n\nSD (sppLIDE site)\n\n\n\n0.104\n0.000\n\n\n\n\n\n\nSD (sppSESE site)\n\n\n\n0.487\n0.629\n\n\n\n\n\n\nCor (sppLIDE~sppSESE site)\n\n\n\n-1.000\n\n\n\n\n\n\n\nSD (Intercept sitespp)\n\n\n\n\n\n0.153\n0.153\n\n\n\n\nNum.Obs.\n2076\n2076\n2076\n2076\n2076\n2076\n2076\n2076\n2076\n\n\nAIC\n7518.3\n7536.9\n6890.7\n6631.3\n6677.1\n6896.9\n6851.9\n6629.7\n6849.9\n\n\nBIC\n7614.1\n7615.9\n7003.5\n6777.9\n6806.8\n6992.7\n6964.7\n6759.4\n6957.1\n\n\nRMSE\n1.47\n1.48\n0.88\n0.94\n0.96\n0.91\n0.89\n0.94\n0.89\n\n\n\nNote: ^^ + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n7.1.6 Multi-year heights V2\nThe problem with all of the above models is (a) a normal distribution is not a good fit for the data because it results in negative height predictions for small trees (year 1) and (b) variance is not constant. Finally, we are fitting year as a linear effect because fitting it as a factor with 3 levels led to model convergence problems, but ideally, we would like to allow different relationships between height and year, because, as we saw in the previous section, height growth is not constant in the first 10 years.\nFor these reasons it makes sense to try another modeling framework, particularly, a gamma distributed model, with a modeled dispersion parameter. It allows only positive predictions, can right skewed distributions, and the dispersion can be modeled as a function of covariates.\n\nmht11 &lt;- glmmTMB(\n  ht ~ treat * spp * year + (1 | plot) + (1 | tree),\n  data = dht, family = Gamma(link = \"log\")\n)\n\nmht12 &lt;- glmmTMB(\n  ht ~ treat + spp + year + treat:spp + treat:year + spp:year + (1 | plot) + \n  (1 | tree),\n  data = dht, family = Gamma(link = \"log\")\n)\n\nmht13 &lt;- glmmTMB(\n  ht ~ treat + spp + year + treat:spp + treat:year + spp:year + \n  (0 + spp | plot) + (0 + spp | tree),\n  data = dht, family = Gamma(link = \"log\")\n)\n\nWarning in finalizeTMB(TMBStruc, obj, fit, h, data.tmb.old): Model convergence\nproblem; non-positive-definite Hessian matrix. See vignette('troubleshooting')\n\nmht14 &lt;- glmmTMB(\n  ht ~ treat + spp + year + treat:spp + treat:year + spp:year +\n  (1 | plot) + (1 | tree),\n  data = mutate(dht, year = factor(year)), family = Gamma(link = \"log\")\n)\n\nmht15 &lt;- glmmTMB(\n  ht ~ treat + spp + year + treat:spp + treat:year + spp:year +\n  (1 | plot) + (1 | tree),\n  dispformula = ~ year,\n  data = mutate(dht, year = factor(year)), family = Gamma(link = \"log\")\n)\n\nmht16 &lt;- glmmTMB(\n  ht ~ treat + spp + year + treat:spp + treat:year + spp:year +\n  (1 | plot) + (1 | tree),\n  dispformula = ~ year * spp,\n  data = mutate(dht, year = factor(year)),\n  family = Gamma(link = \"log\")\n)\n\nmht17 &lt;- glmmTMB(\n  ht ~ treat + spp + year + treat:spp + treat:year + spp:year +\n  (1 | plot) + (1 | tree),\n  dispformula = ~ year * spp + treat + treat:spp,\n  data = mutate(dht, year = factor(year)), family = Gamma(link = \"log\")\n)\n\nmht18 &lt;- glmmTMB(\n  ht ~ treat + spp + year + treat:year + spp:year +\n  (1 | plot) + (1 | tree),\n  dispformula = ~ year + spp + treat + treat:spp,\n  data = mutate(dht, year = factor(year)),\n  family = gaussian(link = \"log\")\n)\n\ndo_model_summary_table &lt;- function(model_list) {\n  modelsummary(\n    model_list,\n    output = \"markdown\",\n    shape = term:component + statistic ~ model,\n    metrics = c(\"AIC\", \"BIC\", \"RMSE\"),\n    estimator = \"ML\",\n    gof_omit = \"F|Log.Lik\",\n    stars = TRUE\n  )\n}\n\ndo_model_summary_table(list(\n    \"Model 11\" = mht11, \"Model 12\" = mht12, \"Model 13\" = mht13,\n    \"Model 14\" = mht14, \"Model 15\" = mht15, \"Model 16\" = mht16,\n    \"Model 17\" = mht17, \"Model 18\" = mht18\n))\n\n\n\nTable 7.3: Summary table for models 2-10, described above. Standard error in parantheses.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel 11\nModel 12\nModel 13\nModel 14\nModel 15\nModel 16\nModel 17\nModel 18\n\n\n\n\n(Intercept) conditional\n-0.096\n-0.118\n-0.114\n-0.104\n-0.101\n-0.095\n-0.101\n-0.107\n\n\n\n(0.101)\n(0.098)\n\n(0.101)\n(0.090)\n(0.089)\n(0.085)\n(0.079)\n\n\ntreatLD conditional\n-0.608***\n-0.612***\n-0.625\n-0.663***\n-0.628***\n-0.628***\n-0.614***\n-0.616***\n\n\n\n(0.145)\n(0.138)\n\n(0.143)\n(0.126)\n(0.126)\n(0.124)\n(0.112)\n\n\ntreatHA conditional\n-0.723***\n-0.659***\n-0.655\n-0.675***\n-0.621***\n-0.643***\n-0.629***\n-0.665***\n\n\n\n(0.142)\n(0.136)\n\n(0.141)\n(0.124)\n(0.124)\n(0.121)\n(0.110)\n\n\ntreatHD conditional\n-0.679***\n-0.656***\n-0.660\n-0.696***\n-0.669***\n-0.675***\n-0.663***\n-0.740***\n\n\n\n(0.143)\n(0.137)\n\n(0.141)\n(0.124)\n(0.124)\n(0.121)\n(0.110)\n\n\nsppSESE conditional\n0.710***\n0.754***\n0.751\n0.739***\n0.763***\n0.766***\n0.742***\n0.762***\n\n\n\n(0.076)\n(0.058)\n\n(0.056)\n(0.065)\n(0.065)\n(0.062)\n(0.038)\n\n\nyear conditional\n0.186***\n0.190***\n0.190\n\n\n\n\n\n\n\n\n(0.008)\n(0.006)\n\n\n\n\n\n\n\n\ntreatLD × sppSESE conditional\n-0.007\n0.002\n0.014\n-0.008\n0.000\n0.000\n0.003\n\n\n\n\n(0.115)\n(0.075)\n\n(0.078)\n(0.079)\n(0.079)\n(0.078)\n\n\n\ntreatHA × sppSESE conditional\n0.232*\n0.103\n0.082\n0.100\n0.026\n0.026\n0.028\n\n\n\n\n(0.108)\n(0.071)\n\n(0.074)\n(0.075)\n(0.074)\n(0.073)\n\n\n\ntreatHD × sppSESE conditional\n-0.053\n-0.100\n-0.116\n-0.126+\n-0.134+\n-0.134+\n-0.129+\n\n\n\n\n(0.110)\n(0.071)\n\n(0.074)\n(0.075)\n(0.075)\n(0.074)\n\n\n\ntreatLD × year conditional\n0.036**\n0.037***\n0.037\n\n\n\n\n\n\n\n\n(0.011)\n(0.008)\n\n\n\n\n\n\n\n\ntreatHA × year conditional\n0.027*\n0.015+\n0.016\n\n\n\n\n\n\n\n\n(0.011)\n(0.008)\n\n\n\n\n\n\n\n\ntreatHD × year conditional\n0.020+\n0.016*\n0.017\n\n\n\n\n\n\n\n\n(0.011)\n(0.008)\n\n\n\n\n\n\n\n\nsppSESE × year conditional\n0.000\n-0.008\n-0.008\n\n\n\n\n\n\n\n\n(0.011)\n(0.006)\n\n\n\n\n\n\n\n\ntreatLD × sppSESE × year conditional\n0.002\n\n\n\n\n\n\n\n\n\n\n(0.016)\n\n\n\n\n\n\n\n\n\ntreatHA × sppSESE × year conditional\n-0.024\n\n\n\n\n\n\n\n\n\n\n(0.015)\n\n\n\n\n\n\n\n\n\ntreatHD × sppSESE × year conditional\n-0.009\n\n\n\n\n\n\n\n\n\n\n(0.016)\n\n\n\n\n\n\n\n\n\n(Intercept) dispersion\n0.430\n0.431\n0.429\n0.330\n1.370***\n1.599***\n1.950***\n-2.295***\n\n\n\n\n\n\n\n(0.053)\n(0.075)\n(0.114)\n(0.110)\n\n\nyear5 conditional\n\n\n\n1.176***\n1.147***\n1.142***\n1.147***\n1.158***\n\n\n\n\n\n\n(0.039)\n(0.043)\n(0.041)\n(0.033)\n(0.028)\n\n\nyear10 conditional\n\n\n\n1.748***\n1.720***\n1.714***\n1.719***\n1.721***\n\n\n\n\n\n\n(0.039)\n(0.044)\n(0.041)\n(0.034)\n(0.030)\n\n\ntreatLD × year5 conditional\n\n\n\n0.326***\n0.286***\n0.286***\n0.275***\n0.279***\n\n\n\n\n\n\n(0.052)\n(0.057)\n(0.056)\n(0.053)\n(0.042)\n\n\ntreatHA × year5 conditional\n\n\n\n0.110*\n0.081\n0.103+\n0.091+\n0.155***\n\n\n\n\n\n\n(0.049)\n(0.054)\n(0.053)\n(0.047)\n(0.038)\n\n\ntreatHD × year5 conditional\n\n\n\n0.168***\n0.138*\n0.144**\n0.132**\n0.158***\n\n\n\n\n\n\n(0.050)\n(0.055)\n(0.054)\n(0.049)\n(0.038)\n\n\ntreatLD × year10 conditional\n\n\n\n0.367***\n0.330***\n0.329***\n0.315***\n0.318***\n\n\n\n\n\n\n(0.052)\n(0.058)\n(0.057)\n(0.054)\n(0.044)\n\n\ntreatHA × year10 conditional\n\n\n\n0.141**\n0.110*\n0.133*\n0.117*\n0.178***\n\n\n\n\n\n\n(0.049)\n(0.055)\n(0.054)\n(0.048)\n(0.040)\n\n\ntreatHD × year10 conditional\n\n\n\n0.172***\n0.143*\n0.149**\n0.137**\n0.178***\n\n\n\n\n\n\n(0.050)\n(0.056)\n(0.055)\n(0.050)\n(0.040)\n\n\nsppSESE × year5 conditional\n\n\n\n-0.028\n-0.031\n-0.035\n-0.016\n-0.049+\n\n\n\n\n\n\n(0.036)\n(0.039)\n(0.040)\n(0.036)\n(0.029)\n\n\nsppSESE × year10 conditional\n\n\n\n-0.062+\n-0.069+\n-0.071+\n-0.043\n-0.073*\n\n\n\n\n\n\n(0.036)\n(0.040)\n(0.041)\n(0.037)\n(0.030)\n\n\nyear5 dispersion\n\n\n\n\n2.957***\n2.650***\n2.716***\n-0.678**\n\n\n\n\n\n\n\n(0.146)\n(0.193)\n(0.202)\n(0.230)\n\n\nyear10 dispersion\n\n\n\n\n2.409***\n2.200***\n2.188***\n1.725***\n\n\n\n\n\n\n\n(0.116)\n(0.164)\n(0.160)\n(0.100)\n\n\nsppSESE dispersion\n\n\n\n\n\n-0.422***\n0.610***\n0.603***\n\n\n\n\n\n\n\n\n(0.107)\n(0.166)\n(0.149)\n\n\nyear5 × sppSESE dispersion\n\n\n\n\n\n0.568*\n0.460\n\n\n\n\n\n\n\n\n\n(0.286)\n(0.297)\n\n\n\nyear10 × sppSESE dispersion\n\n\n\n\n\n0.389+\n0.291\n\n\n\n\n\n\n\n\n\n(0.231)\n(0.225)\n\n\n\ntreatLD dispersion\n\n\n\n\n\n\n-0.571***\n-0.338*\n\n\n\n\n\n\n\n\n\n(0.151)\n(0.154)\n\n\ntreatHA dispersion\n\n\n\n\n\n\n-0.441**\n-0.867***\n\n\n\n\n\n\n\n\n\n(0.144)\n(0.148)\n\n\ntreatHD dispersion\n\n\n\n\n\n\n-0.379**\n-0.821***\n\n\n\n\n\n\n\n\n\n(0.145)\n(0.148)\n\n\nsppSESE × treatLD dispersion\n\n\n\n\n\n\n-1.054***\n0.598**\n\n\n\n\n\n\n\n\n\n(0.216)\n(0.221)\n\n\nsppSESE × treatHA dispersion\n\n\n\n\n\n\n-1.024***\n1.092***\n\n\n\n\n\n\n\n\n\n(0.208)\n(0.216)\n\n\nsppSESE × treatHD dispersion\n\n\n\n\n\n\n-1.312***\n0.848***\n\n\n\n\n\n\n\n\n\n(0.211)\n(0.215)\n\n\nSD (Intercept tree) conditional\n0.225\n0.225\n\n0.294\n0.344\n0.344\n0.341\n0.330\n\n\nSD (sppLIDE tree) conditional\n\n\n0.101\n\n\n\n\n\n\n\nSD (sppSESE tree) conditional\n\n\n0.291\n\n\n\n\n\n\n\nCor (sppLIDE~sppSESE tree) conditional\n\n\n0.000\n\n\n\n\n\n\n\nSD (Intercept plot) conditional\n0.170\n0.170\n\n0.182\n0.141\n0.141\n0.141\n0.138\n\n\nSD (sppLIDE plot) conditional\n\n\n0.180\n\n\n\n\n\n\n\nSD (sppSESE plot) conditional\n\n\n0.214\n\n\n\n\n\n\n\nCor (sppLIDE~sppSESE plot) conditional\n\n\n0.637\n\n\n\n\n\n\n\nNum.Obs.\n2076\n2076\n2076\n2076\n2076\n2076\n2076\n2076\n\n\nAIC\n6173.1\n6170.5\n\n5448.4\n4544.8\n4534.7\n4398.6\n4278.4\n\n\nBIC\n6280.2\n6260.7\n\n5566.8\n4674.5\n4681.3\n4579.0\n4430.6\n\n\nRMSE\n1.16\n1.15\n1.12\n0.73\n0.45\n0.45\n0.46\n0.50\n\n\n\nNote: ^^ + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\nThe model with the lowest AIC is model 18.\n\n\n7.1.7 Multi-year model checking\n\n\nCode\nres &lt;- simulateResiduals(mht18)\nplot(res)\n\n\n\n\n\n\n\n\nFigure 7.5: Residual vs fitted plot for the selected multi-year linear regression model for heights.\n\n\n\n\n\n\n\n7.1.8 Multi-year results\nUsing model 18, we can now answer the questions we posed in the Objectives section.\n\n\nCode\nmht18emmeans &lt;- emmeans(\n  mht18,\n  c(\"spp\", \"treat\", \"year\"),\n  type = \"response\"\n)\n\nmht18emmeans |&gt;\n  as_tibble() |&gt;\n  mutate(\n    year = as.numeric(levels(year))[year]\n  ) |&gt;\n  rename(any_of(c(lower.CL = \"asymp.LCL\", upper.CL = \"asymp.UCL\"))) |&gt;\n  ggplot(aes(year, response, color = spp, fill = spp, group = spp)) +\n    geom_line() +\n    facet_wrap(~ treat) +\n    geom_ribbon(\n      aes(ymin = lower.CL, ymax = upper.CL, color = NULL),\n      alpha = .2\n    ) +\n    stat_slab(data = dht, aes(year, ht), alpha = 0.4) +\n    stat_smooth(\n      data = dht,\n      aes(year, ht),\n      method = lm,\n      color = \"gray60\",\n      se = FALSE,\n      linewidth = 0.7\n    ) +\n    scale_color_brewer(palette = \"Set2\", aesthetics = c(\"color\", \"fill\")) +\n    theme(legend.position = \"bottom\") +\n    labs(x = \"Year\", y = \"Height (m)\", color = \"Species\", fill = \"Species\")\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nFigure 7.6: Average species and treatment specific height as a linear function of year. Density distributions represent the raw data associated with the estimate at that point. The grey line is the OLS fit for reference.\n\n\n\n\n\n\n\nCode\nmht18_compare &lt;- emmeans(\n  mht18,\n  spec = \"treat\",\n  by = c(\"spp\"),\n  at = list(year = \"10\"),\n  type = \"response\"\n) |&gt;\n  cld(Letters = letters) |&gt;\n  as_tibble() |&gt;\n  mutate(\n    # year = as.numeric(levels(year))[year],\n    .group = str_replace_all(.group, \" \", \"\")\n  ) |&gt;\n  rename(any_of(c(lower.CL = \"asymp.LCL\", upper.CL = \"asymp.UCL\")))\n\nmultiple_years_plot &lt;- filter(dht, year == 10) |&gt;\n  ggplot(aes(treat, ht, color = spp, fill = spp)) +\n  facet_grid(~spp, switch = \"x\") +\n  theme(panel.spacing = unit(0, \"lines\"),\n        strip.background = element_blank(),\n        strip.text = element_blank(),\n        ) +\n  geom_dots() +\n  scale_color_brewer(palette = \"Set2\", aesthetics = c(\"color\", \"fill\")) +\n  geom_pointrange(\n    aes(y = response, ymin = lower.CL, ymax = upper.CL),\n    data = mht18_compare,\n    color = \"gray50\", position = position_nudge(x = -0.07),\n    size = 0.7,\n    linewidth = 1,\n    show.legend = FALSE\n  ) +\n  geom_text(\n    aes(y = upper.CL, label = .group),\n    data = mht18_compare,\n    color = \"black\",\n    position = position_nudge(x = -0.3, y = 0.2)\n  ) +\n  labs(x = \"Treatment\", y = \"Height (m)\", color = \"Species\", fill = \"Species\") +\n  theme(legend.position = \"bottom\")\n\nmultiple_years_plot\n\n\n\n\n\n\n\n\nFigure 7.7: Marginal means at year 10 based on height data collected three times over 10 years. The same letter within a species indicates that there was not enough evidence to differentiate those treatments.\n\n\n\n\n\n\n\n7.1.9 Multi-year vs. year 10 only\n\n\nCode\nstandard_model_col_names &lt;- c(\n  LCL = \"lower.CL\",  UCL = \"upper.CL\",  LCL = \"asymp.LCL\", UCL = \"asymp.UCL\",\n  emmean = \"response\"\n)\n\nlist(\"year 10 only\" = ht10_cld, \"multi-year\" = mht18_compare) |&gt;\n  map(\\(x) rename(x, any_of(standard_model_col_names))) |&gt;\n  bind_rows(.id = \"model\") |&gt;\n  ggplot(aes(treat, ht, color = model, fill = model)) +\n  facet_grid(~spp) +\n  geom_pointrange(\n    aes(y = emmean, ymin = LCL, ymax = UCL),\n    position = position_dodge(width = 0.4),\n    size = 0.7,\n    linewidth = 1\n  ) +\n  geom_dots(\n    data = dht10, color = \"gray50\", fill = \"gray70\",\n    position = position_nudge(x = 0.2), scale = 0.7, binwidth = 0.18\n  ) +\n  geom_text(\n    aes(y = UCL + 0.6, label = .group, color = model,),\n    position = position_dodge(width = 0.4),\n  ) +\n  theme(legend.position = \"bottom\") + \n  scale_color_manual(\n    values = rnd_color_brewer(\"Set2\", c(1,4)),\n    aesthetics = c(\"color\", \"fill\")\n  )\n\n\n[1] 1 4\n\n\n\n\n\n\n\n\n\nThis plot attempts to demonstrate the model fit by showing observed and predictied height distributions for our observed dataset.\n\n\nCode\nsprouts |&gt;\n  lengthen_data(\"ht\") |&gt;\n  mutate(\n    Predicted = predict(mht18,\n      lst(site, plot, tree, treat, spp, year),\n      type = \"response\"\n    ),\n    Observed = ht\n  ) |&gt;\n  pivot_longer(c(Observed, Predicted)) |&gt;\n  ggplot(aes(value, treat, color = name, fill = name)) +\n  stat_slab(alpha = 0.4, normalize = \"xy\") +\n  facet_grid(vars(spp), vars(year), scales = \"free\", labeller = label_both) +\n  labs(x = \"Height (m)\", y = \"Treatment\") +\n  scale_color_brewer(palette = \"Set2\", aesthetics = c(\"color\", \"fill\")) +\n  theme(legend.position = \"bottom\", legend.title = element_blank())\n\n\n\n\n\n\n\n\nFigure 7.8: Oberved and predicted height distribution of our observed dataset using the final, chosen, multi-year model. Predictions were made using all random effects.\n\n\n\n\n\n\n\nCode\n#| label: fig-height-pred-fit-10-only\n#| fig-cap: &gt;\n#|   Oberved and predicted height distribution of our observed dataset using the\n#|   selected year-10-only model.\n#|   Predictions were made using all random effects.\n\nsprouts |&gt;\n  lengthen_data(\"ht\") |&gt;\n  filter(year == \"10\") |&gt;\n  mutate(\n    Predicted = predict(ht10_sel,\n      lst(site, plot, tree, treat, spp, year),\n      type = \"response\"\n    ),\n    Observed = ht\n  ) |&gt;\n  pivot_longer(c(Observed, Predicted)) |&gt;\n  ggplot(aes(value, treat, color = name, fill = name)) +\n  stat_slab(alpha = 0.4, normalize = \"xy\") +\n  facet_grid(vars(spp), scales = \"free\", labeller = label_both) +\n  labs(x = \"Height (m)\", y = \"Treatment\") +\n  scale_color_brewer(palette = \"Set2\", aesthetics = c(\"color\", \"fill\")) +\n  theme(legend.position = \"bottom\", legend.title = element_blank())",
    "crumbs": [
      "Sprout height",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Sprout data modeling</span>"
    ]
  },
  {
    "objectID": "analysis/sprout_modeling.html#output",
    "href": "analysis/sprout_modeling.html#output",
    "title": "7  Sprout data modeling",
    "section": "7.2 Output",
    "text": "7.2 Output\nsaved data for later use\n\n\nCode\nsave(dht, mht18, file = \"sprout_modeling.rda\")",
    "crumbs": [
      "Sprout height",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Sprout data modeling</span>"
    ]
  },
  {
    "objectID": "analysis/regen_data_import.html",
    "href": "analysis/regen_data_import.html",
    "title": "8  Import and wrangle regeneration data",
    "section": "",
    "text": "8.1 Clean labels\nFirst, I’ll take a look at the character type columns.\nCode\nselect(regen_0, where(is.character)) |&gt;\n  map(unique)\n\n\n$site\n[1] \"Waldo South\"     \"Waldo North\"     \"CAMP 6\"          \"WHISKEY SPRINGS\"\n\n$treat\n[1] \"GS\"      \"LD\"      \"HA\"      \"HD\"      \"HD - 2B\" \"HD -2A\" \n\n$plot\n[1] \"NE\" \"SE\" \"SW\" \"NW\" \"W\"  \"S\"  \"E\"  \"N\" \n\n$spp\n[1] \"TO\"               \"RW\"               \"DF\"               \"GF\"              \n[5] \"MD\"               \"WM\"               \"CA NETTLE\"        \"QUMU (chinkapin)\"\nI’ll take the following steps to clean up this data:\nCode\nregen_1 &lt;- regen_0 |&gt;\n  mutate(across(where(is.character), tolower)) |&gt;\n  mutate(spp = if_else(str_detect(spp, \"qumu\"), \"gc\", spp)) |&gt;\n  filter(treat != \"hd -2a\", spp != \"ca nettle\") |&gt;\n  mutate(treat = str_extract(treat, \"gs|ld|ha|hd\"))\nThis resulted in the removal of 14 rows.",
    "crumbs": [
      "Regeneration",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Import and wrangle regeneration data</span>"
    ]
  },
  {
    "objectID": "analysis/regen_data_import.html#clean-labels",
    "href": "analysis/regen_data_import.html#clean-labels",
    "title": "8  Import and wrangle regeneration data",
    "section": "",
    "text": "I’ll make them all lowercase for convenience.\nThe decision was made earlier to omit the plot HD - 2A, AKA “MD” (Section 2.1).\nRemove observations of “CA NETTLE”\nChange “QUMU …” to “GC”",
    "crumbs": [
      "Regeneration",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Import and wrangle regeneration data</span>"
    ]
  },
  {
    "objectID": "analysis/regen_data_import.html#stretch-data",
    "href": "analysis/regen_data_import.html#stretch-data",
    "title": "8  Import and wrangle regeneration data",
    "section": "8.2 Stretch data",
    "text": "8.2 Stretch data\nNext, data is in an “unlimited-wide” format, and of a few different types. There are counts for diameter classes (0-1 inch and 1 - 2 inch), and actual diameters (in centimeters) for all trees over 2 inches.\nI’ll make the simplying assumption that individuals in the 0-1 and 1-2 inch size classes are on average at their midpoint in diameter. So each individual is 0.5 and 1.5 inches DBH for the first and second size classes, respectively.\nI’ll put live crown base heights in a separate table. For stems, I’ll get one long list of each regenerating stem. Finally, I’ll convert inches to centimeters.\n\n\nCode\nregen_lcbh &lt;- select(regen_1, site, treat, plot, spp, lcbh_gte2)\n\nregen_2 &lt;- local({\n  regen_lt2 &lt;- select(regen_1, site, treat, plot, spp, dbh_lt1, dbh_lt2)\n  regen_gt2 &lt;- select(regen_1, site, treat, plot, spp, matches(\"dbh\\\\d\"))\n\n  regen_gt2_long &lt;- regen_gt2 |&gt;\n    pivot_longer(matches(\"^dbh\\\\d+$\"), values_to = \"dbh\", names_to = NULL) |&gt;\n    filter(!is.na(dbh))\n\n  regen_lt2_long &lt;- regen_lt2 |&gt;\n    pivot_longer(\n      matches(\"^dbh_\"),\n      names_to = \"dbh\",\n      names_pattern = \".*_(lt1|lt2)\",\n      values_to = \"count\",\n      names_transform = \\(x) case_match(x, \"lt1\" ~ 1.27, \"lt2\" ~ 3.81)\n    ) |&gt;\n    uncount(count)\n\n  bind_rows(regen_lt2_long, regen_gt2_long) |&gt;\n    arrange(site, treat, plot, spp, dbh) |&gt;\n    mutate(treat = factor(treat, c(\"gs\", \"ld\", \"ha\", \"hd\")))\n})\n\nregen &lt;- regen_2\n\n\nWe decided that the minor species are not that interesting here, we are grouping them into “other.” I’ll also order them they their prevelance which will aid in plotting.\n\n\nCode\n# Reduce number of species\nregen &lt;- mutate(regen,\n  spp = if_else(spp %in% c(\"rw\", \"to\", \"df\"), spp, \"other\"),\n  spp = forcats::fct_reorder(spp, spp, length),\n)\n\n\nSave this data for summary, visualization, and potentially, modeling.\n\n\nCode\nsave(regen, regen_lcbh, file = \"regen_wrangled.rda\")",
    "crumbs": [
      "Regeneration",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Import and wrangle regeneration data</span>"
    ]
  },
  {
    "objectID": "analysis/regen_visualize.html",
    "href": "analysis/regen_visualize.html",
    "title": "9  Reneration data summary",
    "section": "",
    "text": "9.1 Objectives\nThis objective is somewhat vaugue because I am not familiar with the statistical techniques used for the weighted (diameter), multi-variate (species) distribution data that we have.\nFor starters, I will look at summaries of size class distributions by species. I will report densities in terms of trees per hectare (tph). Our plots were fixed area, 4-m-radius plots, or 50.27 m2. Each stem in a veg. plot represents 198.94 stems/ha. As shown in Figure 1.2, there are:\nThis plot is a little difficult to interpret beccause of the large difference in counts from the smallest to largest stems. It might make more sense to look at regen smaller than 5 cm separately.\nCode\n# expansion factors at different aggregation levels\nper_ha &lt;- c(\n  all = 1/64, treat = 1/16, plot = 1/4, corner = 1) * (10000 / (16 * pi)\n)\n\np &lt;- regen |&gt;\n  ggplot(aes(dbh, fill = spp)) +\n  stat_bin(aes(y = after_stat(count) * per_ha[\"treat\"]), bins = 10) +\n  facet_wrap(vars(treat), nrow = 1) +\n  labs(y = expr(trees%.%ha^-1))\np\n\n\n\n\n\n\n\n\nFigure 9.1: Histogram of regen by species and size class for each treatment.\nSplitting the analysis at 5-cm-diameter stems shows a clear trend in treatments from most to least available light. Over this gradient, the number of 1.3-cm stems increases, and the 3.8-cm stems decrease, almost proportionally — and most of this is due to tanoak. For &gt;= 5-cm stems, the effect is a fairly homogenous decrease in the number of stems. There are few tanoak, Douglas-fir are only in the brightest areas. Mostly redwood (number of stems) shows a strong correlation with available light.\nCode\nraw_hist2 &lt;- function(group, bin_breaks, scale_breaks, text_pos) {\n  generate_facet_totals &lt;- function(data) {\n    summarize(data,\n      .by = treat,\n      n = paste(\"Total: \", round(n() * per_ha[\"treat\"])),\n    )\n  }\n  colors &lt;- spp_col(regen, scales::brewer_pal, palette = \"Set2\")\n  regen |&gt;\n    filter({{ group }}) |&gt;\n    ggplot(aes(dbh, fill = forcats::fct_reorder(spp, spp, length))) +\n    stat_bin(aes(y = after_stat(count) * per_ha[\"treat\"]), breaks = bin_breaks) +\n    ggpp::geom_text_npc(\n      data = generate_facet_totals,\n      aes(npcx = \"center\", npcy = \"top\", label = n, fill = NULL)\n    ) +\n    facet_wrap(vars(treat), nrow = 1) +\n    labs(y = expression(trees %.% ha^-1), x = \"dbh (cm)\", fill = \"spp\") +\n    scale_x_continuous(breaks = scale_breaks) +\n    scale_y_continuous(expand = expansion(c(0.05, 0.2))) +\n    scale_fill_manual(values = colors) +\n    theme_bw()\n}\n\nraw_hist2(dbh &lt; 5, seq(0, 17.5, 2.5), seq(0, 15, 5), c(2.5, 6000)) /\nraw_hist2(dbh &gt;= 5, seq(0, 17.5, 2.5), seq(0, 15, 5), c(27, 600))\n\n\nRegistered S3 methods overwritten by 'ggpp':\n  method                  from   \n  heightDetails.titleGrob ggplot2\n  widthDetails.titleGrob  ggplot2\n\n\n\n\n\n\n\n\nFigure 9.2: Histograms of regen by species and size class. On top are stems less than five centimeters in diameter, and stems greater than five centimeters are on the bottom.\nThis is interesting, but I wonder what this would look like in terms of basal area, which is more biologically relevant than number of stems.\nCode\nlocal({\n  bin_breaks &lt;- seq(0, 17.5, 2.5)\n  scale_breaks &lt;- seq(0, 15, 5)\n  facet_total_label &lt;- function(data) {\n    summarize(data,\n      .by = treat,\n      ba_ha = round(sum(per_ha[\"treat\"] * for_const(dbh)), 1)\n    )\n  }\n  regen |&gt;\n    ggplot(aes(dbh, fill = forcats::fct_reorder(spp, dbh, .fun = ~sum(.x^2)))) +\n    stat_bin(aes(weight = per_ha[\"treat\"] * for_const(dbh)), breaks = bin_breaks) +\n    ggpp::geom_text_npc(\n      data = facet_total_label,\n      mapping = aes(npcx = \"center\", npcy = \"top\", label = ba_ha, fill = NULL)\n    ) +\n    facet_wrap(vars(treat), nrow = 1) +\n    labs(y = expr(m^2 %.% ha^-1), x = \"dbh (cm)\", fill = \"spp\") +\n    scale_y_continuous(expand = expansion(c(0.05, 0.2))) +\n    scale_x_continuous(breaks = scale_breaks) +\n    scale_fill_manual(\n      values = spp_col(regen, scales::brewer_pal, palette = \"Set2\")\n    ) +\n    theme_bw()\n})",
    "crumbs": [
      "Regeneration",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Reneration data summary</span>"
    ]
  },
  {
    "objectID": "analysis/regen_visualize.html#objectives",
    "href": "analysis/regen_visualize.html#objectives",
    "title": "9  Reneration data summary",
    "section": "",
    "text": "Determine if there are significant differences in species composition, or size class distirbution between treatments\n\n\n\n\n64 veg. plots in the experiment\n16 in a treatment\n4 in a macro plot",
    "crumbs": [
      "Regeneration",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Reneration data summary</span>"
    ]
  },
  {
    "objectID": "analysis/regen_visualize.html#permanova",
    "href": "analysis/regen_visualize.html#permanova",
    "title": "9  Reneration data summary",
    "section": "10.1 Permanova",
    "text": "10.1 Permanova\nWhile it’s not possible to include fully nested random effects using the adonis2 function, it seems important to try to include at least some accounting for grouping. I think site might be the most beneficial grouping level to capture because it captures differences in aspect, and also contains more observations than lower grouping levels.\nI will start out by visualizing the differences associated with sites.\nThis first plot shows that the whiskey spring site has generally higher basal area and that the waldo n site has an especially high basal area for the just the ld treatment.\n\n\nCode\ntotal_ba_ha &lt;- regen |&gt;\n  summarize(.by = c(site, treat, plot),\n    ba_ha = round(sum(per_ha[\"corner\"] * for_const(dbh)), 2)\n  )\n\ndotplot(\n  ba_ha ~ treat,\n  total_ba_ha,\n  groups = site,\n  type = c(\"p\", \"a\"),\n  xlab = \"Treatment\",\n  ylab = expression(m^2%.%ha^-1),\n  auto.key = list(columns = 2, lines = TRUE),\n  jitter.x = TRUE\n)\n\n\n\n\n\n\n\n\n\nThis figure shows that the site:treatment interaction is likely significant. There are similar trends across sites, but their magnitude is different depending on treatment.\n\n\nCode\ndotplot(\n  ba_ha ~ site,\n  total_ba_ha,\n  groups = treat,\n  type = c(\"p\", \"a\"),\n  xlab = \"Site\",\n  ylab = expression(m^2%.%ha^-1),\n  auto.key = list(columns = 2, lines = TRUE),\n  jitter.x = TRUE\n)\n\n\n\n\n\n\n\n\n\nNext, I’ll prepare the species data for analysis\n\n\nCode\nba_ha &lt;- regen |&gt;\n  summarise(\n    .by = c(site, treat, plot, spp),\n    ba_ha = round(sum(per_ha[\"corner\"] * for_const(dbh)), 2)\n  ) |&gt;\n  pivot_wider(names_from = spp, values_from = ba_ha) |&gt;\n  mutate(across(where(is.double), ~ replace_na(.x, 0)))\n\n\nI took these from the help for adonis2, I’m not quite sure what aspect of the data they are showing yet.\n\n\nCode\nmod &lt;- metaMDS(ba_ha[c(\"rw\", \"to\", \"df\", \"other\")], trace = FALSE)\nplot(mod)\n\nordiellipse(mod, ba_ha$site, kind = \"ehull\", label = TRUE)\nordispider(mod, ba_ha$site, lty = 3, col = \"red\")\n\n\n\n\n\n\n\n\n\nIn the following models, the strata argument is used to: “Constrain perumtations within groups.” The first two models don’t include the site as strata.\nWhen I include site as a fixed effect, p-values increase slightly.\n\n\nCode\nperms &lt;- 500\n\nadonis2(\n  ba_ha[c(\"rw\", \"to\", \"df\", \"other\")] ~ treat,\n  data = ba_ha,\n  permutations = perms\n)\n\n\nPermutation test for adonis under reduced model\nTerms added sequentially (first to last)\nPermutation: free\nNumber of permutations: 500\n\nadonis2(formula = ba_ha[c(\"rw\", \"to\", \"df\", \"other\")] ~ treat, data = ba_ha, permutations = perms)\n         Df SumOfSqs      R2      F   Pr(&gt;F)   \ntreat     3   2.1777 0.13288 3.0649 0.003992 **\nResidual 60  14.2104 0.86712                   \nTotal    63  16.3881 1.00000                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nadonis2(\n  ba_ha[c(\"rw\", \"to\", \"df\", \"other\")] ~ site + treat,\n  data = ba_ha,\n  permutations = perms\n)\n\n\nPermutation test for adonis under reduced model\nTerms added sequentially (first to last)\nPermutation: free\nNumber of permutations: 500\n\nadonis2(formula = ba_ha[c(\"rw\", \"to\", \"df\", \"other\")] ~ site + treat, data = ba_ha, permutations = perms)\n         Df SumOfSqs      R2      F   Pr(&gt;F)   \nsite      3   2.0502 0.12510 3.2034 0.003992 **\ntreat     3   2.1777 0.13288 3.4026 0.001996 **\nResidual 57  12.1602 0.74201                   \nTotal    63  16.3881 1.00000                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIf I put site in strata, I get similar results.\n\n\nCode\nadonis2(\n  ba_ha[c(\"rw\", \"to\", \"df\", \"other\")] ~ treat,\n  data = ba_ha,\n  strata = ba_ha$site,\n  permutations = perms\n)\n\n\nPermutation test for adonis under reduced model\nTerms added sequentially (first to last)\nBlocks:  strata \nPermutation: free\nNumber of permutations: 500\n\nadonis2(formula = ba_ha[c(\"rw\", \"to\", \"df\", \"other\")] ~ treat, data = ba_ha, permutations = perms, strata = ba_ha$site)\n         Df SumOfSqs      R2      F   Pr(&gt;F)   \ntreat     3   2.1777 0.13288 3.0649 0.001996 **\nResidual 60  14.2104 0.86712                   \nTotal    63  16.3881 1.00000                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIf I include the interaction of site:treatment as a fixed effect, it is not significant.\n\n\nCode\nwith(ba_ha, adonis2(\n  cbind(rw, to, df, other) ~ site + site:treat + treat,\n  permutations = perms\n))\n\n\nPermutation test for adonis under reduced model\nTerms added sequentially (first to last)\nPermutation: free\nNumber of permutations: 500\n\nadonis2(formula = cbind(rw, to, df, other) ~ site + site:treat + treat, permutations = perms)\n           Df SumOfSqs      R2      F   Pr(&gt;F)   \nsite        3   2.0502 0.12510 3.1966 0.003992 **\ntreat       3   2.1777 0.13288 3.3953 0.001996 **\nsite:treat  9   1.8982 0.11583 0.9865 0.487026   \nResidual   48  10.2620 0.62619                   \nTotal      63  16.3881 1.00000                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nI think we can safely conclude that ther are some significant differences in basal are composition (I assume at the alpha = 0.05 level) between treatments.\nNext, we might consider where these differences (in abundance defined as basal area) are. We could ask about:\n\nDifferences between species within a treatment or\nDifferences between treatment within a species.\n\nI will be focussing on the latter which is in keeping with the theme of the rest of my analysis. These differences have already been visualized above.\nAgain, I’m making zero observations explicit, effectively making our data presence-absence, rather than presence only.\n\n\nCode\nregen_pa &lt;- regen |&gt;\n  summarize(.by = c(site, treat, plot, spp),\n    ba_ha = round(sum(per_ha[\"corner\"] * for_const(dbh)), 2)\n  ) |&gt;\n  complete(nesting(site, treat, plot), spp, fill = list(ba_ha = 0))\n\nregen_po &lt;- regen |&gt;\n  summarize(.by = c(site, treat, plot, spp),\n    ba_ha = round(sum(per_ha[\"corner\"] * for_const(dbh)), 2)\n  )\n\n\nSo, perhaps with our 16 observations per species/treatment, we can detect some differences in basal area with a multi-level model that accounts for non-independence of our sampling design.\n\n\nCode\nlibrary(emmeans)\nm1 &lt;- glmmTMB(ba_ha ~ treat * spp + (1 | site/treat/plot), regen_pa)\nres1 &lt;- simulateResiduals(m1)\nplot(res1)\n\n\n\n\n\n\n\n\n\nCode\nm3 &lt;- glmmTMB(\n  ba_ha ~ treat * spp + (1 | site/treat),\n  regen_pa,\n  dispformula = ~ spp\n)\nres3 &lt;- simulateResiduals(m3)\nplot(res3)\n\n\n\n\n\n\n\n\n\nCode\nm4 &lt;- glmmTMB(\n  ba_ha ~ treat * spp + (1 | site/treat),\n  regen_pa,\n  family = ziGamma(link = \"log\"),\n  dispformula = ~ spp,\n  ziformula = ~ spp\n)\nplot(simulateResiduals(m4))\n\n\n\n\n\n\n\n\n\nCode\nm4 &lt;- glmmTMB(\n  ba_ha ~ treat * spp + (1 | site/treat),\n  regen_pa,\n  family = ziGamma(link = \"log\"),\n  dispformula = ~ spp + treat,\n  ziformula = ~ spp\n)\nres4 &lt;- simulateResiduals(m4)\nplot(res4)\n\n\n\n\n\n\n\n\n\nCode\nplotResiduals(res4, form = regen_pa$spp)\n\n\n\n\n\n\n\n\n\nCode\nplotResiduals(res4, form = regen_pa$treat)\n\n\n\n\n\n\n\n\n\nCode\nplotResiduals(res4, form = interaction(regen_pa$treat, regen_pa$spp))\n\n\n\n\n\n\n\n\n\nHere I plot some simulations from this model to see if it generates plausible data.\n\n\nCode\nregen_pa |&gt;\n  mutate(simulate(m4, nsim = 5)) |&gt;\n  rename(obs = ba_ha) |&gt;\n  pivot_longer(where(is.double), names_to = \"type\", values_to = \"ba_ha\") |&gt;\n  ggplot(aes(\n    treat, ba_ha, # fill = type\n    group = interaction(type, treat),\n    fill = forcats::fct_collapse(type, sim = paste0(\"sim_\", 1:5))\n  )) +\n  geom_boxplot() +\n  facet_wrap(~ spp, scales = \"free_y\") +\n  labs(fill = \"obs/sim\")\n\n\n\n\n\n\n\n\n\nFinally, significant differences?\nWe’d expect 5 times as much basal area of other species in LD compared to HA, and interestingly, 6 times more other species basal area in HD compared to HA.\nWe expect 5 times more redwood regen basal area in GS compared to HA, and 7 times compared to HD.\nFor tanoak, we expect about twice as much regen basal area in GS compared to HA.\n\n\nCode\nemmeans(m4, c(\"spp\", \"treat\"), by = \"spp\", type = \"response\") |&gt;\ncontrast(\"pairwise\") |&gt;\nas_tibble() |&gt;\nfilter(p.value &lt; 0.05) |&gt;\nrelocate(spp)\n\n\n# A tibble: 5 × 8\n  spp   contrast ratio     SE    df  null z.ratio p.value\n  &lt;fct&gt; &lt;fct&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 other ld / ha  5.56  3.37     Inf     1    2.83 0.0240 \n2 other ha / hd  0.165 0.0904   Inf     1   -3.29 0.00557\n3 rw    gs / ha  4.97  2.91     Inf     1    2.74 0.0309 \n4 rw    gs / hd  6.67  4.42     Inf     1    2.86 0.0222 \n5 to    gs / ha  2.39  0.758    Inf     1    2.75 0.0307 \n\n\nFor Douglas-fir in particular, we are interested in the counts of stems more than the basal area. This, requires another model. A counts model.\nHeres the raw counts, It looks like site plays the largest role.\n\n\nCode\nregen_df &lt;- regen |&gt;\n  count(site, treat, plot, spp) |&gt;\n  complete(nesting(site, treat, plot), spp, fill = list(n = 0)) |&gt;\n  filter(spp == \"df\")\n\nregen_df |&gt;\n  ggplot(aes(site, n, fill = treat)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nCode\nregen_df |&gt; summarize(.by = c(site, treat), mean(n), sd(n))\n\n\n# A tibble: 16 × 4\n   site            treat `mean(n)` `sd(n)`\n   &lt;chr&gt;           &lt;fct&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n 1 camp 6          gs         5.75   7.54 \n 2 camp 6          ld         3.25   3.30 \n 3 camp 6          ha         5      5.42 \n 4 camp 6          hd         7.5    0.577\n 5 waldo north     gs         1.5    0.577\n 6 waldo north     ld         0.5    0.577\n 7 waldo north     ha         0.75   1.5  \n 8 waldo north     hd         1.5    1    \n 9 waldo south     gs         0.25   0.5  \n10 waldo south     ld         1.5    1.29 \n11 waldo south     ha         5.5    7.55 \n12 waldo south     hd         1      0.816\n13 whiskey springs gs         2.75   4.86 \n14 whiskey springs ld         1      1.41 \n15 whiskey springs ha         0.75   1.5  \n16 whiskey springs hd         0.5    1    \n\n\nA negative binomial model seems to fit acceptably. I was not able to achive model convergence with the specification of zero inflation or dispersion formulae.\n\n\nCode\nm1 &lt;- glmmTMB(\n  n ~ treat + (1 | site/treat),\n  regen_df,\n  family = nbinom1()\n)\n\nres1 &lt;- simulateResiduals(m1)\nplot(res1)\n\n\n\n\n\n\n\n\n\nThere are no statistically detectable differences\n\n\nCode\nemmeans(m1, \"treat\") |&gt;\n  contrast(\"pairwise\")\n\n\n contrast estimate    SE  df z.ratio p.value\n gs - ld    0.1955 0.400 Inf   0.488  0.9618\n gs - ha    0.0961 0.413 Inf   0.233  0.9956\n gs - hd   -0.2780 0.368 Inf  -0.755  0.8744\n ld - ha   -0.0993 0.426 Inf  -0.233  0.9955\n ld - hd   -0.4735 0.384 Inf  -1.232  0.6063\n ha - hd   -0.3742 0.395 Inf  -0.947  0.7792\n\nResults are given on the log (not the response) scale. \nP value adjustment: tukey method for comparing a family of 4 estimates \n\n\nTODO: pairwise adonis may be available: https://github.com/pmartinezarbizu/pairwiseAdonis\nSave data from this page for future use\n\n\nCode\nsave(regen, spp_col, per_ha, for_const, file = \"regen_visualize.rda\")",
    "crumbs": [
      "Regeneration",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Reneration data summary</span>"
    ]
  }
]